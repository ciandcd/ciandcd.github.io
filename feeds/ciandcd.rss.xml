<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>news.ciandcd.com</title><link>http://ciandcd.github.io/</link><description>软件持续集成和发布</description><lastBuildDate>Sat, 23 Jul 2016 05:52:06 +0800</lastBuildDate><item><title>Building GitHub Pull Requests with Continua CI</title><link>http://ciandcd.github.io/building-github-pull-requests-with-continua-ci.html</link><description>From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/700/building-github-pull-requests-with-continua-ci"&gt;https://www.finalbuilder.com/resources/blogs/postid/700/building-github-pull-requests-with-continua-ci&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;GitHub makes it relatively simple to contribute to open source projects, just fork the repository, make your changes, submit a pull request. Couldn't be simpler.&amp;#160;&lt;/p&gt;
&lt;p&gt;Accepting those Pull requests, is dead simple too, most of the time. But what if you want to build and test the pull request first, before accepting the request. Fortunately the nature of GitHub Pull requests (or more to the point, Git itself) makes this possible.&amp;#160;&lt;/p&gt;
&lt;h4&gt;Git References&lt;br&gt;
&lt;br&gt;
&lt;/h4&gt;
&lt;p&gt;Git References are a complex topic all on it's own, but lets take a quick look at a typical cloned repository. In the .git folder, open config file in notepad and take a look at the [remote "origin"] section, here's what mine looks like :&lt;/p&gt;
&lt;pre class="brush:plain"&gt;[remote "origin"]
url = https://github.com/VSoftTechnologies/playground.git
fetch = +refs/heads/*:refs/remotes/origin/*
&lt;/pre&gt;
&lt;p&gt;The key entry here is the fetch. Quoting from the &lt;a href="http://git-scm.com/book/ch9-5.html" title="Git Internals - The Refspec"&gt;git documentation&lt;/a&gt;&amp;#160;:&lt;/p&gt;
&lt;p&gt;"The format of the refspec is an optional&amp;#160;&lt;code&gt;+&lt;/code&gt;, followed by&amp;#160;&lt;code&gt;&amp;lt;src&amp;gt;:&amp;lt;dst&amp;gt;&lt;/code&gt;, where&amp;#160;&lt;code&gt;&amp;lt;src&amp;gt;&lt;/code&gt;&amp;#160;is the pattern for references on the remote side and&amp;#160;&lt;code&gt;&amp;lt;dst&amp;gt;&lt;/code&gt;&amp;#160;is where those references will be written locally. The&amp;#160;&lt;code&gt;+&lt;/code&gt;&amp;#160;tells Git to update the reference even if it isn&amp;#8217;t a fast-forward."&lt;br&gt;
&lt;br&gt;
The default fetch refspec will pull any branches from the original repository to our clone. But where are our pull requests?&lt;/p&gt;
&lt;h4&gt;Anatomy of a pull request&lt;br&gt;
&lt;br&gt;
&lt;/h4&gt;
&lt;p&gt;When a pull request is submitted,&amp;#160;GitHub &amp;#160;make use of Git References to essentially "attach" your pull request to the original repository. But in my local clone, I won't see them because the default fetch refspec doesn't include them. You can see the pull requests by using the git ls-remote command on the origin :&lt;/p&gt;
&lt;pre class="brush:bash"&gt;$ git ls-remote origin
$ git ls-remote origin
27dfaaf83f60ac26a6fe465042f2ddb515667ff1        HEAD
654b98d6eb862e247e5c043460e9f9a64b2f0972        refs/heads/Test
27dfaaf83f60ac26a6fe465042f2ddb515667ff1        refs/heads/master
b333438310a56823f1938071af8c697b202bf855        refs/pull/1/head
95cb80af1330e73188ea32659d7744dcfe37ab43        refs/pull/2/head
90ba13b8edaab04505396dbcb1853f6f9bdaed64        refs/pull/2/merge
&lt;/pre&gt;
&lt;br&gt;
&lt;p&gt;Notice something odd there. There are two pull requests, but pull request 2 has two entries in the list, whilst pull request 1 has only 1 entry. &amp;#160;refs/pull/2/head is a reference to the head commit of your pull request, whilst refs/pull/2/merge is a reference to the result of the automatic merge that GitHub does. On pull request 1, there was a merge conflict, so the the /merge reference was not created, on pull request 2, the merge succeeded. On the pull request page, you would typically see something like this if the merge succeeded :&amp;#160;&lt;/p&gt;
&lt;img alt="" src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/vincent/GitHubPull/MergeResult.png"&gt;&lt;h4&gt;Getting Continua CI to see the Pull Requests&lt;br&gt;
&lt;br&gt;
&lt;/h4&gt;
&lt;p&gt;The main reason for building pull requests on your CI server is to see if they build, and to run your unit tests against that build. You can chose to build the original pull request, or the result of the automatic merge, or both. In reality, if the automatic merge failed, then the person who submitted the pull request has some more work to do, so there's really no point building/testing the original pull request. What you really want to know, is "if I accept this request, will it build and the tests pass", so it's generally best to only build the automatic merge version of the pull request. Continua CI makes this quite simple. On the Git Repository settings, check the "Fetch other Remote Refs" option. This will show the Other Refs text area, which already has a default RefSpec that will fetch the pull requests (the merged versions), and create local (to Continua CI) branches with the name pr/#number - so pull request 1 becomes branch pr/1.&amp;#160;&lt;/p&gt;
&lt;img alt="" src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/vincent/GitHubPull/GitRepository.png"&gt;&lt;p&gt;You can modify this to taste, for example if you are fetching both the merge and the head versions of the &amp;#160;pull requests, you might use a refespec like this :&lt;/p&gt;
&lt;pre class="brush:plain"&gt;+refs/pull/*/merge:refs/remotes/origin/pr-merge/*
+refs/pull/*/merge:refs/remotes/origin/pr-head/*
&lt;/pre&gt;
&lt;br&gt;
&lt;p&gt;Building the pull Requests&lt;/p&gt;
&lt;p&gt;Now we have gotten this far (which is to say, you enabled one option and clicked on save!) we can build the pull requests (it may take a few minutes to fetch the pull requests). If you manually start a build, you can select the pull request from the branch field for the github repository using the intellsense, just start typing pr/ and you will see a list :&lt;/p&gt;
&lt;p&gt;&amp;#160;&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/vincent/GitHubPull/SelectPR.png"&gt;&lt;/p&gt;
&lt;p&gt;Now we can add a trigger to build pull requests (we are talking continuous integration after all). Using the Pattern Matched Branch feature on &lt;a href="http://wiki.finalbuilder.com/display/continua/Repository+Trigger" title="Pattern Matched Branch"&gt;Continua CI Triggers&lt;/a&gt;&amp;#160;you can make your trigger start builds when a pull request changeset is fetched from Github. The pattern is a regular expression, so ^pr/.* would match our pull request branches (assuming you we use the default refspec)&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/vincent/GitHubPull/PRTrigger.png"&gt;&lt;/p&gt;
&lt;p&gt;
Adding a trigger specific to the pull requests allows you to set variables differently from other branches, and you will then be able to tailor your stages according to whether you are building a pull request or not. For example, you probably don't want to run your deploy stage when building a pull request).&lt;/p&gt;
&lt;h4&gt;Updating GitHup Pull Request Status&lt;/h4&gt;
&lt;br&gt;
&lt;p&gt;One last thing you might like to add, is to update the &lt;a href="https://github.com/blog/1227-commit-status-api"&gt;Pull Request Status&lt;/a&gt;. This can be done using the Update GitHub Status Action in Continua CI (In a future update this will done via build event handlers, a new feature currently in development). This is what the pull request might look like after the status is updated by Continua CI :&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/vincent/GitHubPull/PRStatus.png"&gt;&lt;/p&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:building-github-pull-requests-with-continua-ci.html</guid></item><item><title>Continua 1.5 released</title><link>http://ciandcd.github.io/continua-15-released.html</link><description>From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/721/continua-15-released"&gt;https://www.finalbuilder.com/resources/blogs/postid/721/continua-15-released&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;br&gt;
&lt;br&gt;
&lt;h2&gt;Continua Version 1.5 is now &lt;a target="_blank" href="https://www.finalbuilder.com/downloads/continuaci"&gt;available for download&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Today marks a milestone in Continua CI as we release version 1.5 of the product.  Its been many months in the making, we hope you enjoy the update as much as we enjoyed making it.&lt;/p&gt;
&lt;p&gt;There are many features that we think you'll benefit from by updating to v1.5, some of these include: &lt;/p&gt;
&lt;h3&gt;Reworked UI:&lt;/h3&gt;
&lt;ul&gt;
    &lt;li&gt;Now using bootstrap framework for styling&lt;/li&gt;
    &lt;li&gt;Redesigned &lt;a target="_blank" href="http://wiki.finalbuilder.com/display/continua/dashboards"&gt;dashboards&lt;/a&gt; that show more information including graphs.&lt;/li&gt;
    &lt;li&gt;Added stages information to the Project tile and list views&lt;/li&gt;
    &lt;li&gt;Disabled configurations are now displayed as faded&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;h3&gt;Cloning:&lt;/h3&gt;
&lt;ul&gt;
    &lt;li&gt;Can now clone whole projects and clone configurations between projects.&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;h3&gt;Stage Conditions:&lt;/h3&gt;
&lt;ul&gt;
    &lt;li&gt;Auto Promote conditions - stages can now use conditions to control whether to auto-promote to the next stage.&lt;/li&gt;
    &lt;li&gt;Skip conditions - you can now provide conditions for skipping stages or disable a stage completely.&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;h3&gt;New Actions:&lt;/h3&gt;
&lt;ul&gt;
    &lt;li&gt;Update GitHub Status Action is now deprecated (use event handler instead - see below).&lt;/li&gt;
    &lt;li&gt;&lt;a target="_blank" href="http://wiki.finalbuilder.com/display/continua/NuGet+Restore+Action"&gt;NuGet restore action&lt;/a&gt;.&lt;/li&gt;
    &lt;li&gt;&lt;a target="_blank" href="http://wiki.finalbuilder.com/display/continua/Fake+Action"&gt;Fake (F#) build runner.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;h3&gt;Repository Tags: (Git, Mercurial and Subversion repositories only)&lt;/h3&gt;
&lt;ul&gt;
    &lt;li&gt;Continua CI can now detect and list repository tags.&lt;/li&gt;
    &lt;li&gt;Tags are now displayed in changeset tabs on configuration and build views.&lt;/li&gt;
    &lt;li&gt;Repository trigger can now be set to trigger on tag changes (new tags, edits and deletions) changes).&lt;/li&gt;
    &lt;li&gt;You can now run a build on a &lt;a target="_blank" href="http://wiki.finalbuilder.com/display/continua/Builds#Builds-RepositoryBranch/Tag"&gt;tagged changeset&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
 
&lt;ul&gt;
    &lt;li&gt; Octopus Deploy: Create/Deploy/Promote Octopus Deploy releases. &lt;/li&gt;
    &lt;li&gt; Tag Repository Changesets: Apply tags to a repository changeset (Git, Mercurial and Subversion repositories only) &lt;/li&gt;
    &lt;li&gt; &lt;a target="_blank" href="http://wiki.finalbuilder.com/display/continua/Update+GitHub+Status"&gt;Update GitHub Status: replaces the Update GitHub Status action&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;h3&gt;and many more changes including:&lt;/h3&gt;
&lt;ul&gt;
    &lt;li&gt; Styling changes for improved handling on small screen sizes&lt;/li&gt;
    &lt;li&gt; Report ordering: you can choose which one is displayed first on the build view.&lt;/li&gt;
    &lt;li&gt; New expression functions: Utils.NewGuid() and Utils.RandomNumber() can be used for generation of temporary paths for example&lt;/li&gt;
    &lt;li&gt; Additional LatestChangeset object within the repository object with Branch, BranchName, Comment, CommitterUserName, CommitterFullName, Created, FileCount, Id and RepositoryUsername properties to use in expressions&lt;/li&gt;
    &lt;li&gt; Continua now supports DUnitX enhanced Command Line Options&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Updating&lt;/h2&gt;
&lt;p&gt;Updating to this new release is the same regardless if you are using v1.0.X or a recent build from the beta or release candidate.  Simply download the installer and run it, the setup will guide you through the install process.  As usual we are available on &lt;a href="mailto:support@finalbuilder.com"&gt;support@finalbuilder.com&lt;/a&gt; if you run into any troubles.&lt;/p&gt;
&lt;p&gt;For this release you will need to update both the server and agents.&lt;/p&gt;
&lt;h2&gt;A word of thanks&lt;/h2&gt;
&lt;p&gt;The team wishes to thank everyone who has participated in the beta and release candidate stages for this release.  Your positive feedback has been invaluable in shaping the features and functionality of the product.  Thank you for your continued support.&lt;/p&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:continua-15-released.html</guid></item><item><title>Continua CI and the OpenSSL Heartbleed Vulnerability</title><link>http://ciandcd.github.io/continua-ci-and-the-openssl-heartbleed-vulnerability.html</link><description>From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/706/continua-ci-and-the-openssl-heartbleed-vulnerability"&gt;https://www.finalbuilder.com/resources/blogs/postid/706/continua-ci-and-the-openssl-heartbleed-vulnerability&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;a&gt;&lt;/a&gt;&lt;br&gt;
&lt;br&gt;
The short answer is &lt;strong&gt;No&lt;/strong&gt;.&amp;#160;&lt;br&gt;
&lt;br&gt;
Continua CI itself does not use Open SSL directly, but the default database engine, PostgreSQL, does. The version of PostgreSQL we ship with Continua CI is 9.1.3 .1254 and it does include a version of OpenSSL with the vulnerability, however ssl support is turned off by default and is not used by Continua CI. &amp;#160;&lt;br&gt;
&lt;br&gt;
We also update the pg_hba.conf during install to only allow connections from localhost, however it turns out that if ssl is enabled, the ssl negotiation happens before the rules in pb_hba.conf are matched and this alone does not protect the server.&amp;#160;&lt;br&gt;
&lt;br&gt;
If you are using your own install of PostgreSQL (or you want to be sure that what I say is correct) then I suggest you check your PostgreSQL server. You and easily check if ssl is enabled by running the following query &amp;#160;in PGAdmin:&amp;#160;&lt;br&gt;
&lt;br&gt;
&lt;p&gt;
show ssl&lt;/p&gt;&lt;br&gt;
&lt;br&gt;
Another option is to try the testing tool here :&lt;br&gt;
&lt;br&gt;
&lt;a href="https://github.com/titanous/heartbleeder"&gt;https://github.com/titanous/heartbleeder&lt;/a&gt;&lt;br&gt;
&lt;br&gt;
&lt;p&gt;heartbleeder -pg yourciserver:9001&lt;/p&gt;&lt;br&gt;
&lt;br&gt;
here's the output from testing one of our CI servers :&lt;br&gt;
&lt;br&gt;
&lt;p&gt;
heartbleeder.exe -pg pilatus:9001&lt;br&gt;
Error connecting to pilatus:9001: dial tcp 10.0.0.80:9001: ConnectEx tcp: No connection could be made because the target machine actively refused it.&lt;/p&gt;&lt;br&gt;
&lt;br&gt;
If you are using SQLServer, then you (for once) are ok, SQL Server doesn's use OpenSSL.&lt;br&gt;
&lt;br&gt;
We will issue an update in the next few days with an updated PostgreSQL version once we have completed testing&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;p&gt;By now you have probably heard or read about the &lt;a href="https://www.openssl.org/news/secadv_20140407.txt"&gt;OpenSSL Heartbleed Vulnerability&lt;/a&gt; (unless you have been living under a rock for the last week)! We have had a few customers ask us whether Continua CI is vulnerable to this exploit.The short answer isContinua CI itself does not use Open SSL directly, but the default database engine, PostgreSQL, does. The version of PostgreSQL we ship with Continua CI is 9.1.3 .1254 and it does include a version of OpenSSL with the vulnerability, however ssl support is turned off by default and is not used by Continua CI.We also update the pg_hba.conf during install to only allow connections from localhost, however it turns out that if ssl is enabled, the ssl negotiation happens before the rules in pb_hba.conf are matched and this alone does not protect the server.If you are using your own install of PostgreSQL (or you want to be sure that what I say is correct) then I suggest you check your PostgreSQL server. You and easily check if ssl is enabled by running the following query in PGAdmin:Another option is to try the testing tool here :here's the output from testing one of our CI servers :If you are using SQLServer, then you (for once) are ok, SQL Server doesn's use OpenSSL.We will issue an update in the next few days with an updated PostgreSQL version once we have completed testing&lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:continua-ci-and-the-openssl-heartbleed-vulnerability.html</guid></item><item><title>ContinuaCI Version 1.5</title><link>http://ciandcd.github.io/continuaci-version-15.html</link><description>From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/711/continua-15-new-dashboards"&gt;https://www.finalbuilder.com/resources/blogs/postid/711/continua-15-new-dashboards&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
With the upcoming 1.5 release of ContinuaCI &amp;#160;we have made a number of enhancements to the dashboards, we think you'll love them! &amp;#160;Here is a peek at what's coming soon.&lt;br&gt;
&lt;br&gt;
&lt;h4&gt;The New List View&lt;/h4&gt;
&lt;img src="/portals/0/articleimages/blogimages/peter/dashboards/all-projects.png" alt="all-projects-listview"&gt;&lt;br&gt;
&lt;br&gt;
&lt;strong&gt;Improvements:&lt;/strong&gt;&lt;br&gt;
&lt;ul&gt;
    &lt;li&gt;-  Stage indicator blocks provide quick drill-down into the build log.&lt;/li&gt;
    &lt;li&gt;-  Improved viability and responsiveness of build actions buttons.&lt;/li&gt;
    &lt;li&gt;-  Build action buttons moved to the left for easier access.&lt;/li&gt;
    &lt;li&gt;-  Viability enhancements around projects.&lt;/li&gt;
    &lt;li&gt;-  Improved Responsiveness and performance tweeks.&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;h4&gt;List View: With Builds Completed&lt;/h4&gt;
&lt;img src="/portals/0/articleimages/blogimages/peter/dashboards/all-projects-completed-build.png" alt="all-projects-listview-completed-builds"&gt;&lt;br&gt;
&lt;br&gt;
&lt;h4&gt;List View: With Builds Running&lt;/h4&gt;
&lt;img src="/portals/0/articleimages/blogimages/peter/dashboards/all-projects-multibuild.png" alt="all-projects-listview-completed-multibuilds"&gt;&lt;br&gt;
&lt;br&gt;
&lt;h4&gt;The New Details View&lt;/h4&gt;
&lt;img src="/portals/0/articleimages/blogimages/peter/dashboards/detail-view.png" alt="details-view"&gt;&lt;br&gt;
&lt;br&gt;
&lt;strong&gt;Improvements:&lt;/strong&gt;&lt;br&gt;
&lt;ul&gt;
    &lt;li&gt;-  Build and Queue times now have graphs!&lt;/li&gt;
    &lt;li&gt;-  Build status card on the left hand side displays the status of the build as it progresses.&lt;/li&gt;
    &lt;li&gt;-  Build action buttons are more obvious and responsive.&lt;/li&gt;
    &lt;li&gt;-  Stage indicator blocks (present on the build status cards) provide quick drill-down into the build log.&lt;/li&gt;
    &lt;li&gt;-  Improved Responsiveness and performance tweeks.&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;h4&gt;Details View: with Builds Queued&lt;/h4&gt;
&lt;img src="/portals/0/articleimages/blogimages/peter/dashboards/detail-view-queued.png" alt="details-view-queued"&gt;&lt;br&gt;
&lt;br&gt;
&lt;h4&gt;Details View: with Builds Executing&lt;/h4&gt;
&lt;img src="/portals/0/articleimages/blogimages/peter/dashboards/detail-view-building.png" alt="details-view-building"&gt;&lt;br&gt;
&lt;br&gt;
&lt;h4&gt;Details View: with Builds Finished&lt;/h4&gt;
&lt;img src="/portals/0/articleimages/blogimages/peter/dashboards/detail-view-finished.png" alt="details-view-finished"&gt;&lt;br&gt;
&lt;br&gt;
Stay tuned for more exciting details regarding the version 1.5 release!&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;p&gt;With the upcoming 1.5 release of ContinuaCI we have made a number of enhancements to the dashboards, we think you'll love them! Here is a peek at what's coming soon.Stay tuned for more exciting details regarding the version 1.5 release!&lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:continuaci-version-15.html</guid></item><item><title>Continuous Delivery with Go</title><link>http://ciandcd.github.io/continuous-delivery-with-go.html</link><description>From:&lt;a href="http://www.go.cd/2014/08/07/go-webinar-recording.html"&gt;http://www.go.cd/2014/08/07/go-webinar-recording.html&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Every couple weeks ThoughtWorks hosts learning sessions for people who want more information about continuous delivery with Go. This is a recording of the session from 7 August, 2014&lt;/p&gt;



&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:continuous-delivery-with-go.html</guid></item><item><title>Continuous integration and deployment solution!</title><link>http://ciandcd.github.io/continuous-integration-and-deployment-solution.html</link><description>From:&lt;a href="http://www.pmease.com/hotnews?id=1"&gt;http://www.pmease.com/hotnews?id=1&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;
	
		
			&lt;h3&gt;QuickBuild 6.0 is now available&lt;/h3&gt;&lt;br&gt;&lt;br&gt;

Feature highlights in this release:&lt;br&gt;

&lt;ul class="square"&gt;
&lt;li&gt;Find repository/step/variable overrides and usages for configuration refactoring.&lt;/li&gt;
&lt;li&gt;Optionally trust authenticated user in specified http header to support single sign-on.&lt;/li&gt;
&lt;li&gt;Permission set definition to facilitate assigning same set of permissions repeatedly.&lt;/li&gt;
&lt;li&gt; Administrator can select to run as arbitrary user to facilitate checking user profile.&lt;/li&gt;
&lt;li&gt;Aggregate SCM changes to display change summary and statistics in high level configuration.&lt;/li&gt;
&lt;li&gt;Gerrit integration to verify open changes and score specified Gerrit label accordingly.&lt;/li&gt;
&lt;li&gt;JFrog Artifactory integration to publish and use artifacts during build.&lt;/li&gt;
&lt;li&gt;Persist unprocessed build requests after server shutdown and resume processing after startup.&lt;/li&gt;
&lt;li&gt;Accurev proof build to test active changes on QuickBuild before getting them promoted.&lt;/li&gt;
&lt;li&gt;Optionally run scripts after deletion of configuration and build.&lt;/li&gt;
&lt;li&gt;Able to view live log by step, and view log of finished steps before build finishes.&lt;/li&gt;
&lt;li&gt;Step to record SCM changes without checking out the repository.&lt;/li&gt;
&lt;li&gt;Able to display custom banner in QuickBuild page.&lt;/li&gt;
&lt;/ul&gt;

For detailed explanation of all features added in this release, please visit &lt;a&gt;&lt;/a&gt;&lt;br&gt;&lt;p&gt;We are proud to annouce QuickBuild 6.0.Feature highlights in this release:For detailed explanation of all features added in this release, please visit &lt;a href="http://www.pmease.com/features/whats-new/"&gt;http://www.pmease.com/features/whats-new&lt;/a&gt; &lt;/p&gt;
	
		
			&lt;h3&gt;QuickBuild 5.1 is now available&lt;/h3&gt;&lt;br&gt;&lt;br&gt;

Feature highlights in this release:&lt;br&gt;

&lt;ul class="square"&gt;
&lt;li&gt;Verify GitHub pull requests and update pull request status based on build result.&lt;/li&gt;
&lt;li&gt;GitHub issue tracker integration to parse issues in commit messages.&lt;/li&gt;
&lt;li&gt;Leverage perforce shelve/unshelve feature to run pre-commit builds without using user agent.&lt;/li&gt;
&lt;li&gt;Retrieve changes of Subversion externals for source view and diff.&lt;/li&gt;
&lt;li&gt;Custom columns to display custom build and request info.&lt;/li&gt;
&lt;li&gt;Display reasons for waiting builds and steps.&lt;/li&gt;
&lt;li&gt;Define environment variables in composite steps for inheritance and overriding.&lt;/li&gt;
&lt;li&gt;Detect broken communication links to agents to fail build fast.&lt;/li&gt;
&lt;li&gt;Drag&amp;amp;drop to organize favorite dashboards.&lt;/li&gt;
&lt;li&gt;Dashboard list to display all dasbhoards in system.&lt;/li&gt;
&lt;li&gt;Resource access information to know about resource usage status.&lt;/li&gt;
&lt;li&gt;Coverity report rendering&lt;/li&gt;
&lt;/ul&gt;

For detailed explanation of all features added in this release, please visit &lt;a&gt;&lt;/a&gt;&lt;br&gt;&lt;p&gt;We are proud to annouce the formal release of QuickBuild 5.1Feature highlights in this release:For detailed explanation of all features added in this release, please visit &lt;a href="http://www.pmease.com/features/whats-new/"&gt;http://www.pmease.com/features/whats-new&lt;/a&gt; &lt;/p&gt;
	
		
			&lt;h3&gt;QuickBuild 5.0 is now available&lt;/h3&gt;&lt;br&gt;&lt;br&gt;

Feature highlights in this release:&lt;br&gt;

&lt;ul class="square"&gt;
&lt;li&gt;Launch build agent on demand in cloud environment including Amazon EC2.&lt;/li&gt;
&lt;li&gt;Build pipeline to visualize commits life cycle across different build and deployment stages.&lt;/li&gt;
&lt;li&gt;Optionally store artifacts of configuration sub tree to specified build agents to reduce server load.&lt;/li&gt;
&lt;li&gt;Grid and server metrics collecting and trending.&lt;/li&gt;
&lt;li&gt;Alert definition and notification for key performance indicators.&lt;/li&gt;
&lt;li&gt;Enhanced tray monitor and refined message window.&lt;/li&gt;
&lt;li&gt;Toggle node and step information in build log.&lt;/li&gt;
&lt;li&gt;Share dashboards with specified users besides groups.&lt;/li&gt;
&lt;li&gt;Headless plugin build.&lt;/li&gt;
&lt;li&gt;New dashboard gadgets to display build pipeline, grid performance measurements and system alerts.&lt;/li&gt;
&lt;/ul&gt;

For detailed explanation of all features added in this release, please visit &lt;a&gt;&lt;/a&gt;&lt;br&gt;&lt;p&gt;We are proud to annouce the formal release of QuickBuild 5.Feature highlights in this release:For detailed explanation of all features added in this release, please visit &lt;a href="http://www.pmease.com/features/whats-new/"&gt;http://www.pmease.com/features/whats-new&lt;/a&gt; &lt;/p&gt;
	
		
			&lt;h3&gt;QuickBuild 4.0 formal release is now available&lt;/h3&gt;&lt;br&gt;&lt;br&gt;

Feature highlights in this release:&lt;br&gt;

&lt;ul class="square"&gt;
&lt;li&gt;Customizable dashboard for users and groups to organize build information via gadgets.&lt;/li&gt;
&lt;li&gt;Report aggregation to provide build metrics summary of descendant configurations.&lt;/li&gt;
&lt;li&gt;Resource management for better control of build distribution and agent load.&lt;/li&gt;
&lt;li&gt;Grid partition to divide grid nodes between different configuration trees.&lt;/li&gt;
&lt;li&gt;User activity audit to track and review every modification to the system.&lt;/li&gt;
&lt;li&gt;CollabNet TeamForge integration for user authentication, file uploading, release creation, issue linking. and issue updating.&lt;/li&gt;
&lt;li&gt;Redmine integration to link QuickBuild builds with Redmine issues.&lt;/li&gt;
&lt;li&gt;Google Repo integration to detect changes, check out source, and create tags against Repo.&lt;/li&gt;
&lt;li&gt;Boost test integration to render test reports and display test trends.&lt;/li&gt;
&lt;li&gt;Redesigned report system for improved user experience and performance.&lt;/li&gt;
&lt;li&gt;RESTful API for changes, issues, and various reports.&lt;/li&gt;
&lt;li&gt;Plugin API for third party issue tracker and unit test framework integration.&lt;/li&gt;
&lt;li&gt;Searchable users and groups.&lt;/li&gt;
&lt;/ul&gt;

For detailed explanation of all features added in this release, please visit &lt;a&gt;&lt;/a&gt;&lt;br&gt;&lt;p&gt;We are proud to annouce the formal release of QuickBuild 4.Feature highlights in this release:For detailed explanation of all features added in this release, please visit &lt;a href="http://www.pmease.com/features/whats-new/"&gt;http://www.pmease.com/features/whats-new&lt;/a&gt; &lt;/p&gt;
	
		
			&lt;h3&gt;QuickBuild 3.1 - distributed version control system integration and enhanced .NET support&lt;/h3&gt;&lt;p&gt;QuickBuild 3.1 is released to integrate with Git, Mercurial, Bazaar and Team Foundation Server. This integration makes possible below actions in a continuous integration or release management environment when dealing with these SCMs:&lt;/p&gt;
&lt;ul class="square"&gt;&lt;li&gt;Retrieve source code for build and test from tip or specified revision.&lt;/li&gt;
&lt;li&gt;Create tags for retrieved source code if necessary.&lt;/li&gt;
&lt;li&gt;Detect source changes between builds and notify committers under specified condition.&lt;/li&gt;
&lt;li&gt;Promote SCM revisions to higher stage, for example from qa to release.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
Git, Mercurial and Bazaar integration also includes the gated push feature, with which you can submit ready-for-push commits to QuickBuild for build/test, and have QuickBuild to push them to the official repository automatically after building/testing successfully.&lt;/p&gt;

&lt;p&gt;This release also supports to build .NET projects through MSBuild and Visual Studio solution builder.&lt;/p&gt;

&lt;p&gt;Refer to &lt;a href="http://www.pmease.com/features/whats-new/"&gt;http://www.pmease.com/features/whats-new/&lt;/a&gt; for details.&lt;/p&gt;
	
		
			&lt;h3&gt;QuickBuild 3.1 beta1 released to support Git, Mercurial, TFS and Bazaar&lt;/h3&gt;&lt;br&gt;&lt;br&gt;
You may visit &lt;a&gt;&lt;/a&gt;&lt;p&gt;Git, Mercurial, Team Foundation Server and Bazaar support is now in beta. In this beta, QuickBuild can checkout code, create tags, detect changes, view/diff source files from these version control systems. Proof build support is not yet included but will be delivered in future betas.You may visit &lt;a href="http://www.pmease.com/downloads/eap/"&gt;this link&lt;/a&gt; to download the beta. Any feedbacks or suggestions are very welcomed!&lt;/p&gt;
	
		
			&lt;h3&gt;The formal release of QuickBuild 3 is now available&lt;/h3&gt;&lt;br&gt;&lt;br&gt;

This release works tightly with issue tracking systems to provide an integrated view of issues, builds and SCM changes. No longer worry about which issues are fixed in a particular build, or which build a particular issue is fixed in. QuickBuild tracks these information for you automatically! The release management functionality is improved considerably with the ability to use next unreleased version in issue tracker as next build version, and push built versions into issue tracker as released versions. Currently JIRA, Trac and Bugzilla are supported.&lt;br&gt;&lt;br&gt;

Other feature highlights in this release:&lt;br&gt;&lt;br&gt;

&lt;ul class="square"&gt;
&lt;li&gt;Step can be repeated for different set of parameters, either parallelly, or sequentially. For example, you may create a singe test step to have it execute for each combination of possible databases and OS platforms, or have it run on all applicable build agents. This can greatly reduce number of steps needed in a complex build workflow.&lt;/li&gt;
&lt;li&gt;QuickBuild can now terminate spawned build processes immediately and reliably when a build is canceled or timed out. You no longer need to manually kill relevant processes to release workspace mutexes. This works on Windows, Linux and Unix platforms.&lt;/li&gt;
&lt;li&gt;A non-admin account can now be authorized to administer a configuration subtree.&lt;/li&gt;
&lt;li&gt;Multiple promote actions can be defined with the ability to customize the condition of each action. For example, you may define a release action and have it appear only when build is recommended and current user belongs to release manager group.&lt;/li&gt;
&lt;li&gt;Inherited settings such as steps, repositories and variables will be displayed directly in descendant configurations. This makes examination and modification of inherited settings much easier.&lt;/li&gt;
&lt;li&gt;Build workflow can now be created/rearranged by dragging and dropping steps.&lt;/li&gt;
&lt;li&gt;Trends of duration and success rate of each executed steps are now available in statistics tab of a configuration. You can even compare these trends between different steps to find out which step fails the most and which step costs the most time.&lt;/li&gt;
&lt;li&gt;SCM changes screen is reworked to support text search in changes between two arbitrary builds.&lt;/li&gt;
&lt;li&gt;The same step can now be reused in different composition steps.&lt;/li&gt;
&lt;li&gt;Add the option of auto-detecting user time zone from browser to display local date/time.&lt;/li&gt;
&lt;/ul&gt;

For detailed explanation of all features added in this release, please visit &lt;a&gt;&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;We are pround to annouce the formal release of QuickBuild 3.This release works tightly with issue tracking systems to provide an integrated view of issues, builds and SCM changes. No longer worry about which issues are fixed in a particular build, or which build a particular issue is fixed in. QuickBuild tracks these information for you automatically! The release management functionality is improved considerably with the ability to use next unreleased version in issue tracker as next build version, and push built versions into issue tracker as released versions. Currently JIRA, Trac and Bugzilla are supported.Other feature highlights in this release:For detailed explanation of all features added in this release, please visit &lt;a href="http://www.pmease.com/features/whats-new/"&gt;http://www.pmease.com/features/whats-new&lt;/a&gt; &lt;/p&gt;
	
		
			&lt;h3&gt;QuickBuild 3.0 beta1 is now available&lt;/h3&gt;&lt;a&gt;&lt;/a&gt;&lt;p&gt;The first beta of QuickBuild 3.0 is now available. This release integrates tightly with JIRA, Trac and Bugzilla to streamline the development process. Other improvements include reusable and repeatable steps, inheritance visibility, process tree killing, build engine optimization, UI polishments. Refer to &lt;a href="http://wiki.pmease.com/display/qb30/3.0.0-beta1"&gt;release notes&lt;/a&gt; for details.&lt;/p&gt;
	
		
			&lt;h3&gt;QuickBuild 2.1 is available now&lt;/h3&gt;&lt;a&gt;&lt;/a&gt;&lt;p&gt;QuickBuild 2.1 is just released with plugin and RESTful API, a cross-platform tray monitor, FxCop, NCover and CPD support, custom statistics, Oracle and SSL support, and much more. Refer to &lt;a href="http://www.pmease.com/features/whats-new/"&gt;what's new&lt;/a&gt; for a complete list of new features added to this release.&lt;/p&gt;
	
		
			&lt;h3&gt;The brand new QuickBuild 2.0 is released&lt;/h3&gt;&lt;br&gt;
Please refer to &lt;a&gt;&lt;/a&gt;&lt;p&gt;After years of development and test, QuickBuild 2.0 is finally released to embrace latest innovations in continuous integration and build management area. Most important features introduced in this version are pre-commit test, advanced build grid, versatile build reports, graphical build workflow design, visual build promotion, source code view/diff, and build comparison. QuickBuild 2.0 also includes enormous improvments such as intuitive user interface, fine-grained permission control, real time build progress and log monitoring, variable prompting.Please refer to &lt;a http: www.pmease.com features&gt;the feature page&lt;/a&gt; for the complete list of achievements in this version.&lt;/p&gt;
	
&lt;/div&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:continuous-integration-and-deployment-solution.html</guid></item><item><title>Deployment with Continua CI 1.5 and Octopus Deploy</title><link>http://ciandcd.github.io/deployment-with-continua-ci-15-and-octopus-deploy.html</link><description>From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/712/deployment-with-continua-ci-and-octopus-deploy"&gt;https://www.finalbuilder.com/resources/blogs/postid/712/deployment-with-continua-ci-and-octopus-deploy&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;h2&gt;&lt;/h2&gt;
&lt;h2&gt;&lt;/h2&gt;
So you've got your Continua CI server set up to automatically build, run unit tests and produce reports for your awesome new web application. Now you're ready to try out your project in its natural environment and then eventually release it to the wild for well-deserved public applause.&lt;br&gt;
&lt;br&gt;
Up until now, your options were either to use a Copy action to push the files up to test server and a PowerShell action to set up web services, or preferably run a FinalBuilder script utilising the plethora of actions available for transferring files and interacting with web servers.&lt;br&gt;
&lt;br&gt;
As of version 1.5, Continua CI can also work together with &lt;a&gt;&lt;/a&gt;&lt;br&gt;
&lt;br&gt;
This post will walk through the steps required to push a .Net web application built in Continua to Octopus Deploy and trigger a deployment process to effortlessly get your application running on your test and production servers.&lt;br&gt;
&lt;br&gt;
&lt;h3&gt;Preparing your solution&lt;/h3&gt;
&lt;br&gt;
Octopus Deploy requires that you provide your applications as &lt;a&gt;&lt;/a&gt;&lt;a&gt;&lt;/a&gt;&lt;br&gt;
&lt;br&gt;
Lets go with the recommended OctoPack option. First prepare your Visual Studio solution - use the NuGet package manager to install the OctoPack package into the projects you want to deploy. This will include web application projects, console application projects and Windows service projects but not class libraries and unit test projects.&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/octopack.png"&gt;
&lt;br&gt;
&lt;br&gt;
You can now optionally add a &lt;a&gt;&lt;/a&gt;&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/nuspec.png"&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h3&gt;Setting up the deployment process&lt;/h3&gt;
&lt;br&gt;
Next head over to your Octopus server and set up a deployment project. This should include a &amp;#8220;Deploy a NuGet package&amp;#8221; process step as below.
&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/DeploymentStep.png"&gt;
&lt;br&gt;
&lt;br&gt;
We will set this to retrieve the application package from the built-in NuGet feed. Note that the NuGet package id should match the id element in your .nuspec file - this will default to the name of your assembly.&lt;br&gt;
&lt;br&gt;
We added a few more steps:&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/DeploymentProcess.png"&gt;
&lt;br&gt;
&lt;br&gt;
And some variables:&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/DeploymentVariables.png"&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h3&gt;Setting up the build process&lt;/h3&gt;
&lt;br&gt;
You can now get back to Continua and set up a configuration for building your project. Once you have entered the configuration details and linked up the repository containing your project, move on over to the Stages page:&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/BuildStage.png"&gt;
&lt;br&gt;
&lt;br&gt;
For this simple example you'll need two actions: a NuGet Restore action to ensure that the OctoPack package is available for the build and an MSBuild action to build and push the application to your Octopus Deploy server.&lt;br&gt;
Just enter the path to your solution for the NuGet Restore action (the other fields can be left as is) and complete the main tab of the MSBuild action as required for your project.&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/MSBuildAction.png"&gt;
&lt;br&gt;
&lt;br&gt;
You then need to enter some additional properties to tell MSBuild to run OctoPack and tell it where to send your package.&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/MSBuildProperties.png"&gt;
&lt;br&gt;
&lt;br&gt;
Set the RunOctoPack property to true and the OctoPackPublishPackageToHttp property to the URL for the NuGet feed on the Octopus Deploy server e.g. &lt;a&gt;&lt;/a&gt;&lt;br&gt;
&lt;br&gt;
You will also need to provide an OctoPackPublishAPIKey property &amp;#8211; you can generate an API key on your profile page on the Octopus Deploy server. &lt;br&gt;
&lt;br&gt;
&lt;p&gt;Optionally, y&lt;/p&gt;ou can &amp;#160;use the OctoPackPackageVersion to specify up the package version. Here we use Continua expressions to set this based on the build version. If you leave this out then OctoPack will get this value from the AssemblyVersion property&amp;#160;in your AssemblyInfo.cs file.&lt;br&gt;
&lt;br&gt;
Once the actions are set up and saved, run a build and check that your package gets uploaded to the Octopus Deploy server. Then create a release for your deployment project and test that it deploys ok. Now we are ready to look into how to run this process automatically from Continua CI.&lt;br&gt;
&lt;br&gt;
&lt;h3&gt;Build event handler&lt;/h3&gt;
&lt;br&gt;
On the Continua CI configuration wizard after Stages, we have a new area titled Events. Here you can add &lt;a&gt;&lt;/a&gt;&lt;br&gt;
&lt;br&gt;
Create a new build event handler, give it a name and select the Octopus Deploy as the Type.&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/NewEventHandler.png"&gt;
&lt;br&gt;
&lt;br&gt;
You can now provide general project details under the Octopus Deploy tab.
&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/OctopusDeployDetails.png"&gt;
&lt;br&gt;
&lt;br&gt;
The Octopus Deploy URL should end with '/api' e.g.  http://octopusserver/api. Enter the API key generated under your Octopus Deploy profile and the name of your deployment project.&lt;br&gt;
&amp;#160;&amp;#160;&lt;br&gt;
You can then choose one or more actions to run. The available options are &lt;strong&gt;Create&lt;/strong&gt;, &lt;strong&gt;Deploy&lt;/strong&gt; and &lt;strong&gt;Promote&lt;/strong&gt; and are used to create a new deployment release, deploy a release to an environment and promote a release from one environment to another. As you select each action, new tabs open so you can provide further details and hook the action to a build event.
&lt;br&gt;
&lt;br&gt;
&lt;h3&gt;Creating a release&lt;/h3&gt;
&lt;br&gt;
Before you can deploy an application you need to create a Octopus Deploy release&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/CreateRelease.png"&gt;
&lt;br&gt;
&lt;br&gt;
When creating a release you can specify the Release Version or leave this blank to automatically create a number based on the highest package version. You must provide either a Default Package Version or Step Package Versions for each step which requires one e.g.&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/StepPackageVersions.png"&gt;
&lt;br&gt;
&lt;br&gt;
Flip over to the Create Options tab to tell Continua when to create the release.&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/CreateOptions.png"&gt;
&lt;br&gt;
&lt;br&gt;
There are six &lt;a&gt;&lt;/a&gt;&lt;br&gt;
&lt;br&gt;
&lt;ul&gt;
    &lt;li&gt; On Before Stage Start&lt;/li&gt;
    &lt;li&gt;    On Sending Stage To Agent&lt;/li&gt;
    &lt;li&gt;    On Stage Completed&lt;/li&gt;
    &lt;li&gt;    On Build Pending Promotion&lt;/li&gt;
    &lt;li&gt;    On After Build Continued&lt;/li&gt;
    &lt;li&gt;    On Build Completed&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
Generally we want to create the release at the start of the build before the first stage starts.&lt;br&gt;
&lt;br&gt;
&lt;h3&gt;    Deploying to an environment&lt;/h3&gt;
&lt;br&gt;
Now on to the crux of this whole process - deploying your application. We generally deploy to a Test environment first and then, once we are happy with the outcome, promote to a User Acceptance environment or directly to Production. Continua CI allows you to deploy a release previously created by a Create action in the same build event handler, the highest release version in the project or a specific release version. It's up to you to ensure that the release version exists before the deploy action is run. An environment can consist of multiple machines - you can specify which machines you want to deploy to. If no machines are specified then the release will be deployed to all machines in the environment.&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/DeployRelease.png"&gt;
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
When selecting the Build Event for deployment, ensure that it is triggerred after the package has been built and pushed to the Octopus Deploy server. Here we have set this to be run once the Build stage has completed successfully.
&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/DeployOptions.png"&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h3&gt;Promoting a release&lt;/h3&gt;
&lt;br&gt;
You can promote the latest release from one environment to another. Ideally this would be linked to the promotion of a stage e.g. a testing stage, so that the application can be promoted from a test environment to production environment.
&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/PromoteRelease.png"&gt;
&lt;br&gt;
&lt;br&gt;
We have set our test stage to require manual promotion;
&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/StagePromoteOptions.png"&gt;
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
and set our promote action to run when a build is continued after waiting for promotion.
&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/PromoteOptions.png"&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h3&gt;&lt;/h3&gt;
&lt;h3&gt;Variables&lt;/h3&gt;
&lt;br&gt;
You can also pass variables from Continua CI to your deployment, these will be sent to the Octopus Deploy server before each action is run, updating the variables for the deployment project. We have used expressions is this example to send the build versions number and branch name. These variables can then be used to update project files with details for display or configure services differently depending on the source of the project.
&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/Variables.png"&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h3&gt;Running the configuration&lt;/h3&gt;
&lt;br&gt;
Once your build event handler dialog has been completed and saved, its time to start running the configuration. As the build processes Continua CI will display status information mirroring the process running on Octopus Deploy.
&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/Status.png"&gt;
&lt;br&gt;
&lt;br&gt;
You can also see full details of the deployment process in the build log.
&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/BuildLog.png"&gt;
&lt;br&gt;
&lt;br&gt;
And all going well you will now see a successful deployment on your Octopus Deploy server!
&lt;br&gt;
&lt;br&gt;
&lt;img alt="" src="/portals/0/articleimages/blogimages/dave/Success.png"&gt;
&lt;br&gt;
&lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;p&gt;So you've got your Continua CI server set up to automatically build, run unit tests and produce reports for your awesome new web application. Now you're ready to try out your project in its natural environment and then eventually release it to the wild for well-deserved public applause.Up until now, your options were either to use a Copy action to push the files up to test server and a PowerShell action to set up web services, or preferably run a FinalBuilder script utilising the plethora of actions available for transferring files and interacting with web servers.As of version 1.5, Continua CI can also work together with &lt;a href="https://octopusdeploy.com"&gt;Octopus Deploy&lt;/a&gt; server to provide an end-to-end continuous delivery mechanism. Using the new build event handlers feature, Continua CI builds can now be set up to create Octopus Deploy releases and initiate deployment to test and production environments, at key points in the build process.This post will walk through the steps required to push a .Net web application built in Continua to Octopus Deploy and trigger a deployment process to effortlessly get your application running on your test and production servers.Octopus Deploy requires that you provide your applications as &lt;a href="https://www.nuget.org"&gt;NuGet packages&lt;/a&gt; . You can create and push the package to the Octopus Deploy server using Nuget Pack and Push actions, or create and push an &lt;a href="http://docs.octopusdeploy.com/display/OD/Using+OctoPack"&gt;OctoPack&lt;/a&gt; from MSBuild or VisualStudio build runner actions.Lets go with the recommended OctoPack option. First prepare your Visual Studio solution - use the NuGet package manager to install the OctoPack package into the projects you want to deploy. This will include web application projects, console application projects and Windows service projects but not class libraries and unit test projects.You can now optionally add a &lt;a href="http://docs.nuget.org/docs/reference/nuspec-reference"&gt;.nuspec file&lt;/a&gt; to the root folder of your project to describe the contents of your package. If you don't provide a .nuspec file, OctoPack will automatically create one based on your project settings.Next head over to your Octopus server and set up a deployment project. This should include a &amp;#8220;Deploy a NuGet package&amp;#8221; process step as below.We will set this to retrieve the application package from the built-in NuGet feed. Note that the NuGet package id should match the id element in your .nuspec file - this will default to the name of your assembly.We added a few more steps:And some variables:You can now get back to Continua and set up a configuration for building your project. Once you have entered the configuration details and linked up the repository containing your project, move on over to the Stages page:For this simple example you'll need two actions: a NuGet Restore action to ensure that the OctoPack package is available for the build and an MSBuild action to build and push the application to your Octopus Deploy server.Just enter the path to your solution for the NuGet Restore action (the other fields can be left as is) and complete the main tab of the MSBuild action as required for your project.You then need to enter some additional properties to tell MSBuild to run OctoPack and tell it where to send your package.Set the RunOctoPack property to true and the OctoPackPublishPackageToHttp property to the URL for the NuGet feed on the Octopus Deploy server e.g. &lt;a href="http://octopusserver/nuget/packages"&gt;http://octopusserver/nuget/packages&lt;/a&gt; You will also need to provide an OctoPackPublishAPIKey property &amp;#8211; you can generate an API key on your profile page on the Octopus Deploy server.ou can use the OctoPackPackageVersion to specify up the package version. Here we use Continua expressions to set this based on the build version. If you leave this out then OctoPack will get this value from the AssemblyVersion property in your AssemblyInfo.cs file.Once the actions are set up and saved, run a build and check that your package gets uploaded to the Octopus Deploy server. Then create a release for your deployment project and test that it deploys ok. Now we are ready to look into how to run this process automatically from Continua CI.On the Continua CI configuration wizard after Stages, we have a new area titled Events. Here you can add &lt;a href="http://wiki.finalbuilder.com/x/BgB4"&gt;Build Event Handlers&lt;/a&gt; for tagging repository changesets, updating the GitHub status and interacting with Octopus Deploy.Create a new build event handler, give it a name and select the Octopus Deploy as the Type.You can now provide general project details under the Octopus Deploy tab.The Octopus Deploy URL should end with '/api' e.g. http://octopusserver/api. Enter the API key generated under your Octopus Deploy profile and the name of your deployment project.You can then choose one or more actions to run. The available options areandand are used to create a new deployment release, deploy a release to an environment and promote a release from one environment to another. As you select each action, new tabs open so you can provide further details and hook the action to a build event.Before you can deploy an application you need to create a Octopus Deploy releaseWhen creating a release you can specify the Release Version or leave this blank to automatically create a number based on the highest package version. You must provide either a Default Package Version or Step Package Versions for each step which requires one e.g.Flip over to the Create Options tab to tell Continua when to create the release.There are six &lt;a href="http://wiki.finalbuilder.com/x/GQB4"&gt;Build Events&lt;/a&gt; available to choose from. Some allow you to select a Stage and some allow you to select a successful or failed Build StatusGenerally we want to create the release at the start of the build before the first stage starts.Now on to the crux of this whole process - deploying your application. We generally deploy to a Test environment first and then, once we are happy with the outcome, promote to a User Acceptance environment or directly to Production. Continua CI allows you to deploy a release previously created by a Create action in the same build event handler, the highest release version in the project or a specific release version. It's up to you to ensure that the release version exists before the deploy action is run. An environment can consist of multiple machines - you can specify which machines you want to deploy to. If no machines are specified then the release will be deployed to all machines in the environment.When selecting the Build Event for deployment, ensure that it is triggerred after the package has been built and pushed to the Octopus Deploy server. Here we have set this to be run once the Build stage has completed successfully.You can promote the latest release from one environment to another. Ideally this would be linked to the promotion of a stage e.g. a testing stage, so that the application can be promoted from a test environment to production environment.We have set our test stage to require manual promotion;and set our promote action to run when a build is continued after waiting for promotion.You can also pass variables from Continua CI to your deployment, these will be sent to the Octopus Deploy server before each action is run, updating the variables for the deployment project. We have used expressions is this example to send the build versions number and branch name. These variables can then be used to update project files with details for display or configure services differently depending on the source of the project.Once your build event handler dialog has been completed and saved, its time to start running the configuration. As the build processes Continua CI will display status information mirroring the process running on Octopus Deploy.You can also see full details of the deployment process in the build log.And all going well you will now see a successful deployment on your Octopus Deploy server!&lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:deployment-with-continua-ci-15-and-octopus-deploy.html</guid></item><item><title>Distributed Test Execution with Go + TLB</title><link>http://ciandcd.github.io/distributed-test-execution-with-go-tlb.html</link><description>From:&lt;a href="http://www.go.cd/2014/10/09/Distrubuted-Test-Execution.html"&gt;http://www.go.cd/2014/10/09/Distrubuted-Test-Execution.html&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Writing tests has finally become the norm. Consequently, running tests for every commit is central to &amp;amp; the most time consuming activity in any CI/CD setup. In a decent-sized production quality project you tend to have thousands of tests. That means the cycle time, i.e. the time it takes for a commit to reach deployable state (after running all unit, integration &amp;amp; functional tests), keeps growing.&lt;/p&gt;

&lt;p&gt;It gets harder when teams follow XP related practices like "small commits, frequent commits" since it causes parallel builds &amp;amp; resource starvation.&lt;/p&gt;

&lt;p&gt;One such example is Go's codebase. Just the "Common" &amp;amp; "Server" components of Go which comprises of unit &amp;amp; integration tests, together has ~6000 tests which will take about ~5 hours if run serially! The functional test suite is about 260+ tests with combined runtime of ~15 hours. That's close to a day &amp;amp; we haven't even run everything for a single commit!&lt;/p&gt;

&lt;p&gt;Note that the number of tests is so huge that just putting in a powerful box &amp;amp; running test in parallel will not bring it down to acceptable limits. Also, a large number of other problems surface if you start running tests in parallel on same box (without sandboxed environment) like concurrency issues etc.&lt;/p&gt;

&lt;h2&gt;Solution [Go + TLB]&lt;/h2&gt;

&lt;p&gt;Go improves the cycle time of its own build by making test execution faster, distributing it across many agents (machines). After this "Common" + "Server" takes 20 minutes. All functional tests run in 45 minutes. Thats close to an hour! Still not ideal (a few minutes - constrained by resource availability), but better. :)&lt;/p&gt;

&lt;h3&gt;Test Load Balancer (TLB)&lt;/h3&gt;

&lt;p&gt;&lt;a href="http://test-load-balancer.github.io"&gt;TLB&lt;/a&gt; is an open-source library which provides the ability to break up a test suite into pieces and run a part. It guarantees 'Mutual Exclusion' &amp;amp; 'Collective Exhaustion' properties that are essential to reliably running tests in distributed fashion.&lt;/p&gt;

&lt;p&gt;TLB's strength lies in intelligent test distribution which is based on time, i.e. the tests will be distributed based on time they take to execute, making the jobs close to equal runs which leads to better resource utilization. It falls back on count based splitting if test times are not available. It also runs tests in 'Failed First' order, so if a test has failed in previous run it will be run before other tests which means faster feedback.&lt;/p&gt;

&lt;p&gt;Note: As of this writing, TLB integrates with JUnit (through Ant, Maven &amp;amp; Buildr), RSpec (through Rake), Cucumber (through Rake), Twist (through Ant &amp;amp; Buildr).&lt;/p&gt;

&lt;h4&gt;Quick Setup&lt;/h4&gt;

&lt;p&gt;&lt;a href="https://code.google.com/p/tlb/downloads/detail?name=tlb-complete-0.3.2.tar.gz&amp;amp;can=2&amp;amp;q="&gt;Download&lt;/a&gt; TLB&lt;/p&gt;

&lt;p&gt;Unzip &lt;code&gt;tlb-complete-0.3.2.tar.gz&lt;/code&gt; to &lt;code&gt;tlb-complete-0.3.2&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-sh"&gt;&lt;p class="nv"&gt;$ &lt;/p&gt;&lt;p class="nb"&gt;cd &lt;/p&gt;tlb-complete-0.3.2/server
&lt;p class="nv"&gt;$ &lt;/p&gt;chmod +x server.sh
&lt;p class="nv"&gt;$ &lt;/p&gt;./server.sh start
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This should start server at &lt;code&gt;http://host-ip-address:7019&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Resources:&lt;/p&gt;

 

&lt;h3&gt;Go&lt;/h3&gt;

&lt;p&gt;&lt;a href="http://www.go.cd/"&gt;Go&lt;/a&gt; is an open-source CI/CD tool. Its well known for its powerful modelling, tracing &amp;amp; visualization capabilities.&lt;/p&gt;

&lt;p&gt;While TLB is doing all the distribution, Go does what it does best - orchestrate the parallel execution. &lt;/p&gt;

&lt;h4&gt;Run 'X' instances&lt;/h4&gt;

&lt;p&gt;Starting release 14.3 you can spawn 'x' instances of a job. So if you want to distribute your tests across 10 machines you just need to set &lt;code&gt;run instance count&lt;/code&gt; to 10 &amp;amp; Go will spawn 10 instances of the job when scheduling.&lt;/p&gt;

&lt;h4&gt;Sample Configuration&lt;/h4&gt;

&lt;p&gt;Setup a pipeline with material (SCM) that contains your tests.&lt;/p&gt;

&lt;p&gt;&lt;img src="/images/blog/run-x-instance/1.png"&gt;&lt;/p&gt;

&lt;p&gt;Setup Job to spawn required number of instances (run instance count).&lt;/p&gt;

&lt;p&gt;&lt;img src="/images/blog/run-x-instance/3.png"&gt;&lt;/p&gt;

&lt;p&gt;Setup TLB related environment variables at Environment / Pipeline / Stage / Job level.&lt;/p&gt;

&lt;p&gt;&lt;img src="/images/blog/run-x-instance/2.png"&gt;&lt;/p&gt;

&lt;p&gt;Setup the task to consume &lt;code&gt;GO_PIPELINE_NAME&lt;/code&gt;, &lt;code&gt;GO_STAGE_NAME&lt;/code&gt;, &lt;code&gt;GO_PIPELINE_COUNTER&lt;/code&gt;, &lt;code&gt;GO_STAGE_COUNTER&lt;/code&gt;, &lt;code&gt;GO_JOB_RUN_INDEX&lt;/code&gt; &amp;amp; &lt;code&gt;GO_JOB_RUN_COUNT&lt;/code&gt; environment variables that Go exposes.&lt;/p&gt;

&lt;p&gt;&lt;img src="/images/blog/run-x-instance/4.png"&gt;&lt;/p&gt;

&lt;p&gt;Upload junit xmls as test artifacts.&lt;/p&gt;

&lt;p&gt;&lt;img src="/images/blog/run-x-instance/4-2.png"&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Sample Pipeline Configuration&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-xml"&gt;    &lt;p class="nt"&gt;&amp;lt;pipeline&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"maven-project"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;materials&amp;gt;&lt;/p&gt;
        &lt;p class="nt"&gt;&amp;lt;git&lt;/p&gt; &lt;p class="na"&gt;url=&lt;/p&gt;&lt;p class="s"&gt;"https://github.com/test-load-balancer/sample_projects.git"&lt;/p&gt; &lt;p class="na"&gt;dest=&lt;/p&gt;&lt;p class="s"&gt;"sample_projects"&lt;/p&gt; &lt;p class="nt"&gt;/&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;/materials&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;stage&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"unit-tests"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
        &lt;p class="nt"&gt;&amp;lt;jobs&amp;gt;&lt;/p&gt;
          &lt;p class="nt"&gt;&amp;lt;job&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"test-split"&lt;/p&gt; &lt;p class="na"&gt;runInstanceCount=&lt;/p&gt;&lt;p class="s"&gt;"3"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
            &lt;p class="nt"&gt;&amp;lt;environmentvariables&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;variable&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"TLB_BASE_URL"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
                &lt;p class="nt"&gt;&amp;lt;value&amp;gt;&lt;/p&gt;http://localhost:7019&lt;p class="nt"&gt;&amp;lt;/value&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;/variable&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;variable&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"TLB_TMP_DIR"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
                &lt;p class="nt"&gt;&amp;lt;value&amp;gt;&lt;/p&gt;/tmp&lt;p class="nt"&gt;&amp;lt;/value&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;/variable&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;variable&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"TLB_JOB_NAME"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
                &lt;p class="nt"&gt;&amp;lt;value&amp;gt;&lt;/p&gt;${GO_PIPELINE_NAME}-${GO_STAGE_NAME}-test-split&lt;p class="nt"&gt;&amp;lt;/value&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;/variable&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;variable&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"TLB_JOB_VERSION"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
                &lt;p class="nt"&gt;&amp;lt;value&amp;gt;&lt;/p&gt;${GO_PIPELINE_COUNTER}-${GO_STAGE_COUNTER}&lt;p class="nt"&gt;&amp;lt;/value&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;/variable&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;variable&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"TLB_PARTITION_NUMBER"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
                &lt;p class="nt"&gt;&amp;lt;value&amp;gt;&lt;/p&gt;${GO_JOB_RUN_INDEX}&lt;p class="nt"&gt;&amp;lt;/value&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;/variable&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;variable&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"TLB_TOTAL_PARTITIONS"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
                &lt;p class="nt"&gt;&amp;lt;value&amp;gt;&lt;/p&gt;${GO_JOB_RUN_COUNT}&lt;p class="nt"&gt;&amp;lt;/value&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;/variable&amp;gt;&lt;/p&gt;
            &lt;p class="nt"&gt;&amp;lt;/environmentvariables&amp;gt;&lt;/p&gt;
            &lt;p class="nt"&gt;&amp;lt;tasks&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;exec&lt;/p&gt; &lt;p class="na"&gt;command=&lt;/p&gt;&lt;p class="s"&gt;"mvn"&lt;/p&gt; &lt;p class="na"&gt;workingdir=&lt;/p&gt;&lt;p class="s"&gt;"sample_projects/maven_junit"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
                &lt;p class="nt"&gt;&amp;lt;arg&amp;gt;&lt;/p&gt;clean&lt;p class="nt"&gt;&amp;lt;/arg&amp;gt;&lt;/p&gt;
                &lt;p class="nt"&gt;&amp;lt;arg&amp;gt;&lt;/p&gt;install&lt;p class="nt"&gt;&amp;lt;/arg&amp;gt;&lt;/p&gt;
                &lt;p class="nt"&gt;&amp;lt;arg&amp;gt;&lt;/p&gt;-DskipTests&lt;p class="nt"&gt;&amp;lt;/arg&amp;gt;&lt;/p&gt;
                &lt;p class="nt"&gt;&amp;lt;runif&lt;/p&gt; &lt;p class="na"&gt;status=&lt;/p&gt;&lt;p class="s"&gt;"passed"&lt;/p&gt; &lt;p class="nt"&gt;/&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;/exec&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;exec&lt;/p&gt; &lt;p class="na"&gt;command=&lt;/p&gt;&lt;p class="s"&gt;"mvn"&lt;/p&gt; &lt;p class="na"&gt;workingdir=&lt;/p&gt;&lt;p class="s"&gt;"sample_projects/maven_junit"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
                &lt;p class="nt"&gt;&amp;lt;arg&amp;gt;&lt;/p&gt;clean&lt;p class="nt"&gt;&amp;lt;/arg&amp;gt;&lt;/p&gt;
                &lt;p class="nt"&gt;&amp;lt;arg&amp;gt;&lt;/p&gt;test&lt;p class="nt"&gt;&amp;lt;/arg&amp;gt;&lt;/p&gt;
                &lt;p class="nt"&gt;&amp;lt;arg&amp;gt;&lt;/p&gt;-DskipTests&lt;p class="nt"&gt;&amp;lt;/arg&amp;gt;&lt;/p&gt;
                &lt;p class="nt"&gt;&amp;lt;arg&amp;gt;&lt;/p&gt;-Drun.tests.using.tlb=true&lt;p class="nt"&gt;&amp;lt;/arg&amp;gt;&lt;/p&gt;
                &lt;p class="nt"&gt;&amp;lt;runif&lt;/p&gt; &lt;p class="na"&gt;status=&lt;/p&gt;&lt;p class="s"&gt;"passed"&lt;/p&gt; &lt;p class="nt"&gt;/&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;/exec&amp;gt;&lt;/p&gt;
            &lt;p class="nt"&gt;&amp;lt;/tasks&amp;gt;&lt;/p&gt;
            &lt;p class="nt"&gt;&amp;lt;artifacts&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;test&lt;/p&gt; &lt;p class="na"&gt;src=&lt;/p&gt;&lt;p class="s"&gt;"sample_projects/maven_junit/target/reports/*.xml"&lt;/p&gt; &lt;p class="na"&gt;dest=&lt;/p&gt;&lt;p class="s"&gt;"test-reports"&lt;/p&gt; &lt;p class="nt"&gt;/&amp;gt;&lt;/p&gt;
            &lt;p class="nt"&gt;&amp;lt;/artifacts&amp;gt;&lt;/p&gt;
          &lt;p class="nt"&gt;&amp;lt;/job&amp;gt;&lt;/p&gt;
        &lt;p class="nt"&gt;&amp;lt;/jobs&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;/stage&amp;gt;&lt;/p&gt;
    &lt;p class="nt"&gt;&amp;lt;/pipeline&amp;gt;&lt;/p&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;Other features that helps with Test Parallelization&lt;/h3&gt;

&lt;h4&gt;Wait for all jobs to finish&lt;/h4&gt;

&lt;p&gt;Go's modelling capability gives it the ability to run jobs in parallel but wait for all of them to finish before the next Stage / downstream Pipelines are triggered.&lt;/p&gt;

&lt;p&gt;&lt;img src="/images/blog/run-x-instance/6.png"&gt;&lt;/p&gt;

&lt;h4&gt;Stop the downstream flow&lt;/h4&gt;

&lt;p&gt;If any of the tests (and as a result the Job running the test) fails, the Stage is considered as failed. This causes the flow to stop as expected.&lt;/p&gt;

&lt;p&gt;&lt;img src="/images/blog/run-x-instance/5.png"&gt;&lt;/p&gt;

&lt;h4&gt;Consolidated Test Report&lt;/h4&gt;

&lt;p&gt;Once all the Jobs are done running, Go consolidates test reports &amp;amp; shows the result at stage level for easy consumption.&lt;/p&gt;

&lt;p&gt;&lt;img src="/images/blog/run-x-instance/7.png"&gt;&lt;/p&gt;

&lt;h4&gt;Drill down&lt;/h4&gt;

&lt;p&gt;You can drill down at job level to know more information like 'test count', 'console output' for the Job (test) etc.&lt;/p&gt;

&lt;p&gt;&lt;img src="/images/blog/run-x-instance/8.png"&gt;
&lt;img src="/images/blog/run-x-instance/10.png"&gt;
&lt;img src="/images/blog/run-x-instance/9.png"&gt;&lt;/p&gt;

&lt;h4&gt;Partition re-run&lt;/h4&gt;

&lt;p&gt;Go also provides ability to re-run a Job of a stage. This provides ability to run the partition that could have failed due to flaky test etc. The best part is, TLB runs the exact tests that it ran the last time making sure no test is missed out!&lt;/p&gt;

&lt;p&gt;&lt;img src="/images/blog/run-x-instance/11-1.png"&gt;
&lt;img src="/images/blog/run-x-instance/11-2.png"&gt;&lt;/p&gt;

&lt;h4&gt;TLB Correctness Check&lt;/h4&gt;

&lt;p&gt;TLB provides an ability to check correctness, i.e. it will make sure all tests were run. You can configure to run this correctness check once all partitions are done executing, may be in next stage / pipeline.&lt;/p&gt;

&lt;h3&gt;Power of dynamic splitting&lt;/h3&gt;

&lt;p&gt;Go's one knob control to amount of parallelization means that when the number of tests increase/decrease all you will need to do is change the &lt;code&gt;run instance count&lt;/code&gt; based on number of tests &amp;amp; resource availability &amp;amp; you are done!&lt;/p&gt;

&lt;p&gt;--&lt;/p&gt;

&lt;p&gt;As always, Go questions can be asked at &lt;a href="https://groups.google.com/forum/#!forum/go-cd"&gt;go-cd&lt;/a&gt;.&lt;/p&gt;

&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:distributed-test-execution-with-go-tlb.html</guid></item><item><title>DUnitX has a Wizard!</title><link>http://ciandcd.github.io/dunitx-has-a-wizard.html</link><description>From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/702/dunitx-has-a-wizard"&gt;https://www.finalbuilder.com/resources/blogs/postid/702/dunitx-has-a-wizard&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Thanks to a contribution from Robert Love, DUnitX now sports a shiny new IDE Wizard for creating Test projects and Test Units.&amp;#160;&lt;/p&gt;
&lt;p&gt;Before you install and use the wizard, there is one thing I recommend you do. In your Delphi IDE, add and Environment variable DUNITX and point it at your copy of the DUnitX source. The reason for doing this, is that when the wizard creates a project, it adds $(DUNITX) to the project search path. This avoids hard coding the DUnitX folder in yhe project search path, and also avoids installing it in your global library path (I have nothing other than the defaults installed there, I always use the project search path, makes it easier to share projects with other devs).&amp;#160;&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/vincent/DUnitX-Wizard/dunitx-environ.png"&gt;&lt;/p&gt;
&lt;p&gt;
&lt;/p&gt;
&lt;p&gt;Once you have that done (I'm assuming you have pulled down the latest source from GitHub), open the project group (.grouproj) for your IDE version and build the project group. Then right click on the wizard project and click on install :&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/vincent/DUnitX-Wizard/dunitx-install-wizard.png"&gt;&lt;/p&gt;
&lt;p&gt;If the package installs successfully then we are ready to use the wizard. Close the project group, and invoke the File\New\Other dialog, you will see the DUnitX Project listed&amp;#160;&lt;/p&gt;
&lt;p&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/vincent/DUnitX-Wizard/dunitx-project.png"&gt;&lt;img alt="" src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/vincent/DUnitX-Wizard/dunitx-unit.png"&gt;&lt;/p&gt;
&lt;p&gt;
&lt;/p&gt;
&lt;p&gt;You might like to Customize your File\New menu, I made DUnitX prominent on mine (in part to remind myself to create unit tests first!) :&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/vincent/DUnitX-Wizard/dunitx-filenew.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;
&lt;/p&gt;
&lt;p&gt;Invoking the wizard will show a simple dialog :&lt;/p&gt;
&lt;p&gt;&lt;br&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/vincent/DUnitX-Wizard/dunitx-project-wizard.png"&gt;&lt;/p&gt;
&lt;p&gt;The options are pretty self explainatory, so I won't go into them here. The wizard generates a console application, once we have a gui runner (being worked on) we'll update the wizard to add options for that.&lt;/p&gt;
&lt;p&gt;DUnitX is open source, get it from &lt;a href="https://github.com/VSoftTechnologies/DUnitX" target="_blank"&gt;GitHub&lt;/a&gt;&amp;#160;- contributions are welcome. We also have a &lt;a href="https://plus.google.com/communities/110602661860791972403" target="_blank"&gt;Google Plus Community&lt;/a&gt;&amp;#160;for DUnitX.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;
&lt;/p&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:dunitx-has-a-wizard.html</guid></item><item><title>Feature Branch Support</title><link>http://ciandcd.github.io/feature-branch-support.html</link><description>From:&lt;a href="http://www.go.cd/2015/04/27/Feature-Branch-Support.html"&gt;http://www.go.cd/2015/04/27/Feature-Branch-Support.html&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Go 15.1 introduced support for writing material repository plugins, to extend the kind of source code material
repositories that Go works with. This resulted in community-driven plugins developed for Go, to implement support for
feature branches, with help from members of Go's core contributors. This blog posts has information specifically about
GitHub Pull Request support.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; In this post, the terms Branch and Pull Request are used interchangeably, since a Pull Request is
essentially just a branch.&lt;/p&gt;

&lt;p&gt;As codebases grow and teams start writing more tests, they often hit upon a challenging problem. If they have setup
their build, test and deploy pipelines as a normal team or teams working with trunk-based development would have, then
increasing the number of tests they have results in a longer time to certify a build and deploy to production.&lt;/p&gt;

&lt;p&gt;Here is an example of a Value Stream Map from &lt;a href="https://build.go.cd"&gt;Go CD&lt;/a&gt; (Username: view, Password: password) itself,
where running all the tests and generating installers can take hours:&lt;/p&gt;


  &lt;img src="/images/blog/feature-branch/mature-ci-cd-setup.png" class="has_border full_size" alt="Figure 1: GoCD - Value Stream Map" id="mature_ci_cd_setup" title="GoCD - Value Stream Map"&gt;
  Figure 1: GoCD - Value Stream Map &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;


&lt;p&gt;Due to this, it becomes critical to keep the main Value Stream green all the time. A failed build would mean all other
commits ready to go in have to wait until the failed build is fixed:&lt;/p&gt;


  &lt;img src="/images/blog/feature-branch/failed-build.png" class="has_border full_size" alt="Figure 2: Failed build stops everything" id="failed_build" title="Failed build stops everything"&gt;
  Figure 2: Failed build stops everything &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;




&lt;p&gt;The root of this problem is a slow build, and sometimes that can be tackled directly. However, with the advent of
short-lived feature branches (aka, Pull Requests in GitHub land), this problem can become worse. Since feature
branches are not regularly verified before merging, merging them could itself be a little risky, and could cause the
build to fail un-necessarily.&lt;/p&gt;

&lt;p&gt;In general, development workflows in organizations has moved to something which looks like:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-text"&gt;Pull Request (GitHub, Gerrit etc.) / Feature Branch =&amp;gt; Code Review =&amp;gt; Merge =&amp;gt; Build
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now, whether a feature branch based workflow is the best approach or not is hotly debated (see Martin Fowler's
&lt;a href="http://martinfowler.com/bliki/FeatureBranch.html"&gt;article&lt;/a&gt; on this). Organizations who follow a feature branch based
workflow have been wanting support for it in Go.  Historically, &lt;a href="http://support.thoughtworks.com/entries/22037619-Support-for-feature-branches#view-post-21612654"&gt;Go has advocated against feature
branches&lt;/a&gt; and support
for it has been limited. Go users have come up with some innovative work arounds, like this one from &lt;a href="https://groups.google.com/d/topic/go-cd/veZ5QyySR8k/discussion"&gt;Vision
Critical&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Though the Go core contribution team continues to be wary of long-lived feature branches, short-lived feature branches
create a window for validating changes before they are merged into the main branch. Since the majority of time spent in
a CI/CD setup tends to be in running tests, and failed builds are typically due to test failures, you could run tests on
a proposed change in a feature branch, get feedback about it and fix tests if needed, before merging it into the trunk.
Though this does not always catch integration issues (that depends on what else was merged before this one was), it
allows you to increase the chances of your main Value Stream staying green and in a deployable state for longer.&lt;/p&gt;

&lt;p&gt;A problem with this approach though, is that every change will be tested twice (once on the feature branch and once on
the main branch after the merge) which means the effective time for a commit to reach production could be more, unless
you have more hardware (agents) to run branch builds.&lt;/p&gt;

&lt;h3&gt;The way forward&lt;/h3&gt;

&lt;p&gt;Assuming you have chosen the approach mentioned above, you can now use Go 15.1, with its two new extension points - &lt;a href="http://www.go.cd/documentation/user/15.1.0/extension_points/scm_extension.html"&gt;SCM
end-point&lt;/a&gt; and the &lt;a href="http://www.go.cd/documentation/user/15.1.0/extension_points/notification_extension.html"&gt;Notification
end-point&lt;/a&gt;, to test feature
branches before they are merged.&lt;/p&gt;

&lt;p&gt;To use this with GitHub requires the use of two community-driven and community-supported plugins: &lt;a href="https://github.com/ashwanthkumar/gocd-build-github-pull-requests"&gt;Git Branch Poller
Plugin&lt;/a&gt; and the &lt;a href="https://github.com/srinivasupadhya/gocd-build-status-notifier"&gt;Build Status Notification
Plugin&lt;/a&gt;. The first one is an SCM Material plugin, and is
responsible for polling a configured repository for changes, while the second one is a Notification plugin, which is
responsible for notifying GitHub about the suitability of a Pull Request for merging.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Even though this post specifically mentions GitHub only, plugins have been written to work with plain Git,
Atlassian Stash, Gerrit and more! See the &lt;a href="http://www.go.cd/community/plugins.html#notification-plugins"&gt;Go community plugins
page&lt;/a&gt; for more information.&lt;/p&gt;

&lt;h3&gt;Quick Setup&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Download the &lt;a href="https://github.com/ashwanthkumar/gocd-build-github-pull-requests#user-content-get-started"&gt;Git Branch Poller Plugin&lt;/a&gt; and the &lt;a href="https://github.com/srinivasupadhya/gocd-build-status-notifier#user-content-get-started"&gt;Build Status Notification Plugin&lt;/a&gt;. Place them under &lt;code&gt;&amp;lt;go-server&amp;gt;/plugins/external&lt;/code&gt;. Restart the Go Server.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Verify that the plugins are loaded correctly.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


  &lt;img src="/images/blog/feature-branch/plugins-loaded.png" class="has_border full_size" alt="Figure 3: Verify Plugins" id="verify_plugins" title="Verify Plugins"&gt;
  Figure 3: Verify Plugins &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Decide which parts of the value stream you want the Pull Requests to run till, and extract a template for those
pipelines, so that you can have a parallel set of pipelines to run against Pull Requests. The need to create a
separate set of pipelines is to make sure that the main build and the branch build never get interleaved, and a branch
build never gets deployed into production, by mistake.&lt;/p&gt;

&lt;p&gt;Your decision should be based on how much of your tests can reasonably be run for every Pull Request, and how far down
the Value Stream can a build containing those changes Go. For some, every test in the system needs to run before it is
deemed merge-able and for some, only unit and integration tests might be enough. It depends.&lt;/p&gt;

&lt;p&gt;Suppose you have a setup of three pipelines like this:&lt;/p&gt;


  &lt;img src="/images/blog/feature-branch/setup.png" class="full_size" alt="Figure 4: Example setup" id="example_setup" title="Example setup"&gt;
  Figure 4: Example setup &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;


&lt;p&gt;and you decide that you want the first two pipelines to run for every Pull Request, you need to change your pipelines
to look like this:&lt;/p&gt;


  &lt;img src="/images/blog/feature-branch/with_prs.png" class="full_size" alt="Figure 5: Extract templates, create pipelines for PR" id="create_pipelines" title="Extract templates, create pipelines for PR"&gt;
  Figure 5: Extract templates, create pipelines for PR &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;


&lt;p&gt;Based on your decision, extract templates and create the new pipelines:&lt;/p&gt;


  &lt;img src="/images/blog/feature-branch/extract-template.png" class="has_border full_size" alt="Figure 6: Extract template" id="extract_template" title="Extract template"&gt;
  Figure 6: Extract template &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In the new pipeline or pipelines that have been setup to run for every Pull Request, change the Git material to use
the GitHub material (this material is provided by the GitHub poller plugin installed earlier):&lt;/p&gt;


  &lt;img src="/images/blog/feature-branch/replace-material-1.png" class="has_border full_size" alt="Figure 7: Add GitHub material" id="add_github_material" title="Add GitHub material"&gt;
  Figure 7: Add GitHub material &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;



  &lt;img src="/images/blog/feature-branch/replace-material-2.png" class="has_border full_size" alt="Figure 8: Add GitHub material - Details" id="add_github_material_details" title="Add GitHub material - Details"&gt;
  Figure 8: Add GitHub material - Details &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;


&lt;p&gt;Once you have setup the GitHub material for the pipeline, you can remove the Git material from that pipeline.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;That's it.&lt;/p&gt;

&lt;h3&gt;Results&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Go will trigger builds for every new Pull Request and for new commits to existing Pull Requests:&lt;/p&gt;


  &lt;img src="/images/blog/feature-branch/trigger-build.png" class="has_border full_size" alt="Figure 9: PR triggers build" id="pr_triggers_build" title="PR triggers build"&gt;
  Figure 9: PR triggers build &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Go will update Pull Request in GitHub with the build status:&lt;/p&gt;


   
  Figure 10: GitHub PR page gets updated &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;



   
  Figure 11: GitHub PR listing page gets updated &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Fan-in and Value Stream Map work as expected:&lt;/p&gt;


  &lt;img src="/images/blog/feature-branch/vsm.png" class="has_border full_size" alt="Figure 12: Fan-in and VSM work" id="vsm_works" title="Fan-in and VSM work"&gt;
  Figure 12: Fan-in and VSM work &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;Shortcomings and known issues:&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;If multiple branches are updated at once, the plugin provides all of them as changes and Go will not run the pipeline
for every change separately. Go currently combines multiple changes into a single pipeline run (to save time). A
feature allowing &lt;a href="https://github.com/gocd/gocd/pull/939"&gt;"force trigger pipeline for each change"&lt;/a&gt; should be able to
overcome this. This has not yet been accepted into the main GoCD codebase.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;If there are multiple commits in a branch, the plugin only returns the top commit as a change. Hence only one change
shows up in the dashboard, value stream, etc. Also, since Go does not know about the other changes you will not be
able to manually trigger a pipeline with the other commits.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The UI is lacking in certain areas: For instance, it is not possible to add an SCM plugin material during pipeline
creation, to associate an existing SCM to a pipeline you will need to edit Config XML etc. These 
will be fixed in upcoming releases.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;References&lt;/h3&gt;

&lt;p&gt;Some discussions on the GoCD mailing lists and on GitHub about this:&lt;/p&gt;

 

&lt;h3&gt;Sample Configuration&lt;/h3&gt;

&lt;p&gt;Here is a part of the configuration used to create the images shown above:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-xml"&gt;  &lt;p class="nt"&gt;&amp;lt;scms&amp;gt;&lt;/p&gt;
    &lt;p class="nt"&gt;&amp;lt;scm&lt;/p&gt; &lt;p class="na"&gt;id=&lt;/p&gt;&lt;p class="s"&gt;"b7386c23-71d5-4581-8129-bba5b67638e4"&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"sample-repo"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;pluginConfiguration&lt;/p&gt; &lt;p class="na"&gt;id=&lt;/p&gt;&lt;p class="s"&gt;"github.pr"&lt;/p&gt; &lt;p class="na"&gt;version=&lt;/p&gt;&lt;p class="s"&gt;"1"&lt;/p&gt; &lt;p class="nt"&gt;/&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;configuration&amp;gt;&lt;/p&gt;
        &lt;p class="nt"&gt;&amp;lt;property&amp;gt;&lt;/p&gt;
          &lt;p class="nt"&gt;&amp;lt;key&amp;gt;&lt;/p&gt;url&lt;p class="nt"&gt;&amp;lt;/key&amp;gt;&lt;/p&gt;
          &lt;p class="nt"&gt;&amp;lt;value&amp;gt;&lt;/p&gt;https://github.com/srinivasupadhya/sample-repo.git&lt;p class="nt"&gt;&amp;lt;/value&amp;gt;&lt;/p&gt;
        &lt;p class="nt"&gt;&amp;lt;/property&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;/configuration&amp;gt;&lt;/p&gt;
    &lt;p class="nt"&gt;&amp;lt;/scm&amp;gt;&lt;/p&gt;
  &lt;p class="nt"&gt;&amp;lt;/scms&amp;gt;&lt;/p&gt;
  &lt;p class="nt"&gt;&amp;lt;pipelines&lt;/p&gt; &lt;p class="na"&gt;group=&lt;/p&gt;&lt;p class="s"&gt;"sample-group-master"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
    &lt;p class="nt"&gt;&amp;lt;pipeline&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"sample-pipeline-master"&lt;/p&gt; &lt;p class="na"&gt;template=&lt;/p&gt;&lt;p class="s"&gt;"sample-pipeline"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;materials&amp;gt;&lt;/p&gt;
        &lt;p class="nt"&gt;&amp;lt;git&lt;/p&gt; &lt;p class="na"&gt;url=&lt;/p&gt;&lt;p class="s"&gt;"https://github.com/srinivasupadhya/sample-repo.git"&lt;/p&gt; &lt;p class="na"&gt;dest=&lt;/p&gt;&lt;p class="s"&gt;"sample-repo"&lt;/p&gt; &lt;p class="na"&gt;materialName=&lt;/p&gt;&lt;p class="s"&gt;"sample-repo"&lt;/p&gt; &lt;p class="nt"&gt;/&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;/materials&amp;gt;&lt;/p&gt;
    &lt;p class="nt"&gt;&amp;lt;/pipeline&amp;gt;&lt;/p&gt;
    &lt;p class="nt"&gt;&amp;lt;pipeline&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"sample-downstream-pipeline-master"&lt;/p&gt; &lt;p class="na"&gt;template=&lt;/p&gt;&lt;p class="s"&gt;"sample-downstream-pipeline"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;materials&amp;gt;&lt;/p&gt;
        &lt;p class="nt"&gt;&amp;lt;pipeline&lt;/p&gt; &lt;p class="na"&gt;pipelineName=&lt;/p&gt;&lt;p class="s"&gt;"sample-pipeline-master"&lt;/p&gt; &lt;p class="na"&gt;stageName=&lt;/p&gt;&lt;p class="s"&gt;"sample-stage-2"&lt;/p&gt; &lt;p class="nt"&gt;/&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;/materials&amp;gt;&lt;/p&gt;
    &lt;p class="nt"&gt;&amp;lt;/pipeline&amp;gt;&lt;/p&gt;
  &lt;p class="nt"&gt;&amp;lt;/pipelines&amp;gt;&lt;/p&gt;
  &lt;p class="nt"&gt;&amp;lt;pipelines&lt;/p&gt; &lt;p class="na"&gt;group=&lt;/p&gt;&lt;p class="s"&gt;"sample-group-PR"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
    &lt;p class="nt"&gt;&amp;lt;pipeline&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"sample-pipeline-PR"&lt;/p&gt; &lt;p class="na"&gt;template=&lt;/p&gt;&lt;p class="s"&gt;"sample-pipeline"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;materials&amp;gt;&lt;/p&gt;
        &lt;p class="nt"&gt;&amp;lt;scm&lt;/p&gt; &lt;p class="na"&gt;ref=&lt;/p&gt;&lt;p class="s"&gt;"b7386c23-71d5-4581-8129-bba5b67638e4"&lt;/p&gt; &lt;p class="na"&gt;dest=&lt;/p&gt;&lt;p class="s"&gt;"sample-repo"&lt;/p&gt; &lt;p class="nt"&gt;/&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;/materials&amp;gt;&lt;/p&gt;
    &lt;p class="nt"&gt;&amp;lt;/pipeline&amp;gt;&lt;/p&gt;
    &lt;p class="nt"&gt;&amp;lt;pipeline&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"sample-downstream-pipeline-PR"&lt;/p&gt; &lt;p class="na"&gt;template=&lt;/p&gt;&lt;p class="s"&gt;"sample-downstream-pipeline"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;materials&amp;gt;&lt;/p&gt;
        &lt;p class="nt"&gt;&amp;lt;pipeline&lt;/p&gt; &lt;p class="na"&gt;pipelineName=&lt;/p&gt;&lt;p class="s"&gt;"sample-pipeline-PR"&lt;/p&gt; &lt;p class="na"&gt;stageName=&lt;/p&gt;&lt;p class="s"&gt;"sample-stage-2"&lt;/p&gt; &lt;p class="nt"&gt;/&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;/materials&amp;gt;&lt;/p&gt;
    &lt;p class="nt"&gt;&amp;lt;/pipeline&amp;gt;&lt;/p&gt;
  &lt;p class="nt"&gt;&amp;lt;/pipelines&amp;gt;&lt;/p&gt;
  &lt;p class="nt"&gt;&amp;lt;templates&amp;gt;&lt;/p&gt;
    &lt;p class="nt"&gt;&amp;lt;pipeline&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"sample-pipeline"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;stage&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"sample-stage-1"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
        &lt;p class="nt"&gt;&amp;lt;jobs&amp;gt;&lt;/p&gt;
          &lt;p class="nt"&gt;&amp;lt;job&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"sample-job-1"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
            &lt;p class="nt"&gt;&amp;lt;tasks&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;exec&lt;/p&gt; &lt;p class="na"&gt;command=&lt;/p&gt;&lt;p class="s"&gt;"ls"&lt;/p&gt; &lt;p class="nt"&gt;/&amp;gt;&lt;/p&gt;
            &lt;p class="nt"&gt;&amp;lt;/tasks&amp;gt;&lt;/p&gt;
          &lt;p class="nt"&gt;&amp;lt;/job&amp;gt;&lt;/p&gt;
        &lt;p class="nt"&gt;&amp;lt;/jobs&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;/stage&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;stage&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"sample-stage-2"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
        &lt;p class="nt"&gt;&amp;lt;jobs&amp;gt;&lt;/p&gt;
          &lt;p class="nt"&gt;&amp;lt;job&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"sample-job-2"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
            &lt;p class="nt"&gt;&amp;lt;tasks&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;exec&lt;/p&gt; &lt;p class="na"&gt;command=&lt;/p&gt;&lt;p class="s"&gt;"ls"&lt;/p&gt; &lt;p class="nt"&gt;/&amp;gt;&lt;/p&gt;
            &lt;p class="nt"&gt;&amp;lt;/tasks&amp;gt;&lt;/p&gt;
          &lt;p class="nt"&gt;&amp;lt;/job&amp;gt;&lt;/p&gt;
        &lt;p class="nt"&gt;&amp;lt;/jobs&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;/stage&amp;gt;&lt;/p&gt;
    &lt;p class="nt"&gt;&amp;lt;/pipeline&amp;gt;&lt;/p&gt;
    &lt;p class="nt"&gt;&amp;lt;pipeline&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"sample-downstream-pipeline"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;stage&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"sample-stage-3"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
        &lt;p class="nt"&gt;&amp;lt;jobs&amp;gt;&lt;/p&gt;
          &lt;p class="nt"&gt;&amp;lt;job&lt;/p&gt; &lt;p class="na"&gt;name=&lt;/p&gt;&lt;p class="s"&gt;"sample-job-3"&lt;/p&gt;&lt;p class="nt"&gt;&amp;gt;&lt;/p&gt;
            &lt;p class="nt"&gt;&amp;lt;tasks&amp;gt;&lt;/p&gt;
              &lt;p class="nt"&gt;&amp;lt;exec&lt;/p&gt; &lt;p class="na"&gt;command=&lt;/p&gt;&lt;p class="s"&gt;"ls"&lt;/p&gt; &lt;p class="nt"&gt;/&amp;gt;&lt;/p&gt;
            &lt;p class="nt"&gt;&amp;lt;/tasks&amp;gt;&lt;/p&gt;
          &lt;p class="nt"&gt;&amp;lt;/job&amp;gt;&lt;/p&gt;
        &lt;p class="nt"&gt;&amp;lt;/jobs&amp;gt;&lt;/p&gt;
      &lt;p class="nt"&gt;&amp;lt;/stage&amp;gt;&lt;/p&gt;
    &lt;p class="nt"&gt;&amp;lt;/pipeline&amp;gt;&lt;/p&gt;
  &lt;p class="nt"&gt;&amp;lt;/templates&amp;gt;&lt;/p&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As always, Go questions can be asked on the &lt;a href="https://groups.google.com/forum/#!forum/go-cd"&gt;mailing list&lt;/a&gt;.&lt;/p&gt;

&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:feature-branch-support.html</guid></item><item><title>Filtering Tests</title><link>http://ciandcd.github.io/filtering-tests.html</link><description>From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/717/dunitx-updated-filtering-tests"&gt;https://www.finalbuilder.com/resources/blogs/postid/717/dunitx-updated-filtering-tests&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;h2&gt;Still evolving&lt;/h2&gt;
&lt;p&gt;DUnitX is still quite young, and still evolving. One of the features most often requested (other than the gui runner, which is still planned) is the ability to select which tests to run. I found myself wishing for that feature recently. I never missed it while the number of my tests were relatively small and fast, but as time went by, it was taking longer and longer to debug tests. So, time to add filtering of fixtures and tests.&lt;/p&gt;
&lt;p&gt;The command options support in DUnitX was to be honest, quite useless and poorly though out. So my first task was to tackle how options were set/used in DUnitX, and find an extensible way of handling command line options. The result turned out better than I exepected, so I have published a separate project for that. &lt;a href="https://github.com/VSoftTechnologies/VSoft.CommandLineParser" alt="VSoft.CommandLine project on github" rel="nofollow" target="_blank"&gt;VSoft.CommandLine&lt;/a&gt; is a very simple library for defining and parsing command line options, which decouples the definition and parsing from where the parsed values are stored. I'll blog about this library separately.&lt;/p&gt;
&lt;p&gt;I did try to avoid breaking any existing test projects out there. To invoke the command line option parsing, you will need to add a call to TDUnitX.CheckCommandLine;  at the start of you project code, eg:&lt;/p&gt;
&lt;pre class="brush:delphi; toolbar:true;"&gt;begin
  try
    TDUnitX.CheckCommandLine;
    //Create the runner
    runner := TDUnitX.CreateRunner;
&lt;/pre&gt;
&lt;p&gt;The call should be inside the try/except because it will throw exceptions if any errors are found with the command line options. I modified the IDE Expert to include the needed changes in any new projects it creates, I recommend running the expert to generate a project and then compare it to your existing dpr.&lt;/p&gt;
&lt;h2&gt;Filtering&lt;/h2&gt;
&lt;p&gt;The next thing to look at was how to apply filtering. After much experimentation, I eventually settled on pretty much copying how NUnit does it. I ported the filter and CategoryExpression classes from NUnit, with a few minor mods needed to adapt them to our needs. The cool thing here is I was able to port the associated unit tests over with ease!&lt;/p&gt;
&lt;p&gt;There are two types of filters, namespace/fixture/test filters, and category filters.&lt;/p&gt;
&lt;h3&gt;Namespace/Fixture/Test filtering&lt;/h3&gt;
&lt;p&gt;The new command line options are :&lt;/p&gt;
&lt;pre&gt;--run - specify which Fixtures or Tests to run, separate values with a comma, or specify the option multiple times&lt;/pre&gt;
eg:
&lt;pre&gt;--run:DUnitX.Tests.TestFixture,DUnitX.Tests.DUnitCompatibility.TMyDUnitTest&lt;/pre&gt;
&lt;p&gt;eg:&lt;/p&gt;&lt;p&gt;If you specify a namespace (ie unit name or part of a unit name) then all fixtures and tests matching the namespace will run.&lt;/p&gt;
&lt;h3&gt;Category Filters&lt;/h3&gt;
&lt;p&gt;A new CategoryAttribute allows you to a apply categories to fixtures and/or tests. Tests inherit their fixture's categories, except when they have their own CategoryAttribute. You can specify multiple categories, separated by commas, eg:&lt;/p&gt;
&lt;pre class="brush:delphi; toolbar:true;"&gt;[TestFixture]
[Category('longrunning,suspect')]
TMyFixture  = class
public
    [Test]
    procedure Test1;
  
    [Test]
    [Category('fast')]
    procedure Test2;
&lt;/pre&gt;
&lt;p&gt;In the above example, Test1 would have "longrunning" and "suspect" categories, whilst Test2 would have just "fast".&lt;/p&gt;
&lt;p&gt;You can filter tests using these categories, using the --include and/or --exclude command line options. When both options are specifies, all the tests with the included categories are run, except for those with the excluded categories.  The following info is copied from the NUnit doco (on which these options are based) :&lt;/p&gt;

    
        
            Expression
            Action
        
    
    
        
            A|B|C
            Selects tests having any of the categories A, B or C.
        
        
            A,B,C
            Selects tests having any of the categories A, B or C.
        
        
            A+B+C
            Selects only tests having all three of the categories assigned
        
        
            A+B|C
            Selects tests with both A and B OR with category C.
        
        
            A+B-C
            Selects tests with both A and B but not C.
        
        
            -A
            Selects tests not having category A assigned
        
        
            A+(B|C)
            Selects tests having both category A and either of B or C
        
        
            A+B,C
            Selects tests having both category A and either of B or C
        
    

&lt;p&gt;As shown by the last two examples, the comma operator is equivalent to | but has a higher precendence. Order of evaluation is as follows:&lt;/p&gt;
&lt;p&gt;
&lt;/p&gt;
&lt;ol class="operators"&gt;
    &lt;li&gt;Unary exclusion operator (-)&lt;/li&gt;
    &lt;li&gt;High-precendence union operator (,)&lt;/li&gt;
    &lt;li&gt;Intersection and set subtraction operators (+ and binary -)&lt;/li&gt;
    &lt;li&gt;Low-precedence union operator (|)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&amp;#160;&lt;/p&gt;
&lt;p&gt;
Note :
Because the operator characters have special meaning, you should avoid creating a category that uses any of them in it's name. For example, the category "db-tests" could not be used on the command line, since it appears to means "run category db, except for category tests." The same limitation applies to characters that have special meaning for the shell you are using.
I have also fixed some other minor issues with the naming of repeated tests and test cases to allow them to work with the filter.
&lt;/p&gt;
&lt;h3&gt;Other options&lt;/h3&gt;
&lt;p&gt;Once you have added the command line check, run yourexe /? to see the other command line options available. None of the options are required so running the exe without any options will behave as it did before.&lt;/p&gt;
&lt;h3&gt;Delphi 2010&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Resolved&lt;/strong&gt;&amp;#160;- Thanks to Stefan Glienke for figuring this out - D2010 now support again . This fix was to remove any use of of STRONGLINKTYPES.&amp;#160;&lt;/p&gt;
&lt;p&gt;One thing of note: at the moment these changes break our D2010 support. I get a linker error when I build :&lt;/p&gt;
&lt;pre&gt;[DCC Fatal Error] F2084 Internal Error: L1737&lt;/pre&gt;
&lt;p&gt;Interestingly, the resulting executable is produced and does seem to run ok, however it makes debugging tests impossible, and of course it would fail in automated build. I did spend several hours trying to resolve this error but got nowhere. Since my usage of DUnitX is currently focused on XE2, I'm willing to live with this and just use an older version of DUnitX for D2010. I have tested with XE2, XE5 and XE6.&lt;/p&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:filtering-tests.html</guid></item><item><title>FinalBuilder 8 Beta</title><link>http://ciandcd.github.io/finalbuilder-8-beta.html</link><description>From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/729/finalbuilder-8-beta"&gt;https://www.finalbuilder.com/resources/blogs/postid/729/finalbuilder-8-beta&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;a&gt;&lt;/a&gt;&lt;br&gt;
&lt;h2&gt;What's new in FinalBuilder 8&lt;/h2&gt;
&lt;h3&gt;IDE Themes&lt;/h3&gt;
&lt;p&gt;It's almost 5 years since FinalBuilder 7 was released. Since it's release we have shipped &lt;a href="https://www.finalbuilder.com/downloads/finalBuilder/finalbuilder-7-version-history"&gt;44 official updates&lt;/a&gt; , nearly every update including new features or improvements. This program of continuous improvement has worked well, with customers not having to wait for major new versions to arrive to get support for new versions of Visual Studio or Delphi etc, but it has limited our ability to make major changes. So it's time for a new major version of FinalBuilder.&lt;/p&gt;&lt;p&gt;The IDE has two new themes, Dark and Light (yes, imaginatively named!). The IDE defaults to Dark on first run, however you can change the theme in the options quite easily. The themes are still a work in progress, we are waiting on an update from a third party control vendor to resolve some issues. &lt;/p&gt;

    
        
            
            &lt;img alt="IDE Light theme" height="276" width="400" src="/blogImages/vincent/fb8-beta/fb8-ide-light-small.png"&gt;
            
            
            &lt;img alt="IDE Light theme" height="276" width="400" src="/blogImages/vincent/fb8-beta/fb8-ide-dark-small.png"&gt;
            
        
    

&lt;p&gt;&amp;#160;&lt;/p&gt;
&lt;h3&gt;Debugger&lt;/h3&gt;
&lt;p&gt;One of the most asked for features now available in FinalBuilder 8, &lt;strong&gt;stepping into included projects&lt;/strong&gt;. In FinalBuilder 7 and earlier, you could only step over included projects, and wait for them to return. In FinalBuilder 8, you can step into the included project, if it is not already opened the IDE will open the project and switch to it automatically. To make this possible, there are now "Step Into" and "Step Over" functions. The Step into/over now also applies to targets (see below).&lt;br&gt;
&lt;br&gt;
Debugger breakpoints now have conditions :
&lt;/p&gt;
&lt;p&gt;
&lt;img alt="IDE Light theme" height="276" width="400" src="/blogImages/vincent/fb8-beta/fb8-breakpoint-props.png"&gt;
&lt;/p&gt;
&lt;h3&gt;Actionlists renamed to Targets&lt;/h3&gt;
&lt;p&gt;ActionLists have been renamed to Targets. Targets can now also define dependencies, so you can for example define Clean, Build, Test, and have Test depend on Build. If you execute the Test target, and Build has not already been executed, it will be executed first before Test. Targets can be specified on the command line.&lt;/p&gt;
&lt;p&gt;&lt;img alt="IDE Light theme" height="276" width="400" src="/blogImages/vincent/fb8-beta/fb8-target-depend.png"&gt;&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;In FinalBuilder 7 and earlier, projects had a Main and an OnFailure (global error handler) actionlist. In FinalBuilder 8, projects just have a Default Target. Older projects will be imported such that the Main and OnFailure Targets are called from the Default Target inside a try/catch block.&lt;/p&gt;
&lt;h3&gt;Run Target Action&lt;/h3&gt;
&lt;p&gt;You can now return values from Targets (ie out parameters) .&lt;/p&gt;
&lt;p&gt;&lt;img alt="IDE Light theme" height="276" width="400" src="/blogImages/vincent/fb8-beta/fb8-target-outparams.png"&gt;&lt;/p&gt;
&lt;h3&gt;New Help System&lt;/h3&gt;
&lt;p&gt;The help has moved online in the form of a wiki. This enables us to do inline help updates without needing to ship new builds. The new help is still being worked on, lots of screenshots are missing etc..&amp;#160;&lt;/p&gt;
&lt;h2&gt;Non Visible Changes&lt;/h2&gt;
&lt;h3&gt;Stepping Engine&lt;/h3&gt;
&lt;p&gt;The stepping engine was rewritten to enable stepping into included projects, and to enable target dependencies. This, work, together with the new variables architecture is where the bulk of effort/time was spent in the FinalBuilder 8 development cycle.&lt;/p&gt;
&lt;h3&gt;Variables Architecture&lt;/h3&gt;
&lt;p&gt;The variables architecture and the expression evaluator were rewritten to resolve several corner case issues that we were not able to resolve in FinalBuilder 7. The expression evaulator has a new parser that will allow us to more easily extend the syntax in the future. The User variable namespace was removed, it caused too many problems with projects not running under other users, not running on the build server etc. Use Project variables instead. &lt;/p&gt;
&lt;h3&gt;Core Messaging&lt;/h3&gt;
&lt;p&gt;Changes to the messaging has allowed us to improve the performance of the stepping engine and logging, with much less thread switching. This also improved the IDE performance.&lt;/p&gt;
&lt;h3&gt;CLR Hosting&lt;/h3&gt;
&lt;p&gt;The minimum CLR version is now .NET 4.0 (ie FinalBuilder requires .net 4.0 to be installed).&lt;/p&gt;
&lt;h3&gt;Code Changes&lt;/h3&gt;
&lt;p&gt;In addition to the architectural changes, we also spent a lot of time refactoring the code, running static analysis tools over the source, looking for memory leaks, potential bugs etc. One of the results of this is reduced memory usage during a build compared to FB7. The FB8 IDE does use slightly more memory than the FB7 IDE at startup (mostly due to the heavy use of delphi generics), however the runtime memory usage is much lower.A large &amp;#160;part of the refactoring involved unit testing (we created a new&amp;#160;&lt;a href="https://github.com/VSoftTechnologies/DUnitX" target="_blank"&gt;unit test framework&lt;/a&gt; to suite our needs!) and creating a suite of integration tests.&amp;#160;&lt;/p&gt;
&lt;h3&gt;FBCmd&lt;/h3&gt;
&lt;p&gt;The command line parameters have changed to be more consistent and easier to specify. You can also specify one or more targets to execute (when not specified, the default target is executed).
&lt;/p&gt;
&lt;h3&gt;New Project File Formats&lt;/h3&gt;
&lt;p&gt;FinalBuilder has used an xml file format since version 1, however a common complaint over the years, has been that it is difficult to diff file versions. FinalBuilder 8 has tackled this in two ways.&lt;/p&gt;
&lt;p&gt;A new DSL style project file format (.fbp8) is now the default format, it is very easy to diff.&lt;/p&gt;
&lt;pre class="brush:delphi; toolbar:true;"&gt;project
begin
    projectid = {04710B72-066E-46E7-84C7-C04A0D8BFE18}
    target
    begin
        name = Default
        targetid = {E6DE94D6-5484-45E9-965A-DB69885AA5E2}
        rootaction
        begin
            action.group
            begin
                id = {D860420B-DE46-4806-959F-8A92A0C86429}
            end
        end
    end
end
&lt;/pre&gt;
&lt;p&gt;A new xml format (.fbx8), much less verbose than the old format. &lt;/p&gt;
&lt;pre class="brush:xml; toolbar:true;"&gt;&amp;lt;?xml version="1.0" encoding="UTF-8"?&amp;gt;
&amp;lt;finalbuilder&amp;gt;
    &amp;lt;project&amp;gt;
        &amp;lt;projectid&amp;gt;{6A717C24-D00F-4983-9FD0-148B2C609634}&amp;lt;/projectid&amp;gt;
        &amp;lt;target&amp;gt;
            &amp;lt;name&amp;gt;Default&amp;lt;/name&amp;gt;
            &amp;lt;targetid&amp;gt;{E6DE94D6-5484-45E9-965A-DB69885AA5E2}&amp;lt;/targetid&amp;gt;
            &amp;lt;rootaction&amp;gt;
                &amp;lt;action.group&amp;gt;
                    &amp;lt;id&amp;gt;{D860420B-DE46-4806-959F-8A92A0C86429}&amp;lt;/id&amp;gt;
                &amp;lt;/action.group&amp;gt;
            &amp;lt;/rootaction&amp;gt;
        &amp;lt;/target&amp;gt;
    &amp;lt;/project&amp;gt;
&amp;lt;/finalbuilder&amp;gt;
&lt;/pre&gt;
&lt;p&gt;Compressed project files (.fbz8) use the dsl format internally (compressed projects are just a zip file with a project.fbp8 inside it).&lt;/p&gt;
&lt;p&gt;The default project file encoding is now UTF-8, which is more version control friendly (some version control systems treat utf-16 as binaries).&lt;/p&gt;
&lt;h3&gt;New Actions&lt;/h3&gt;
&lt;p&gt;There are no new actions at the moment, although several are in development, they will be added to the beta builds as they are completed.&amp;#160;&lt;/p&gt;
&lt;h3&gt;How do I get the Beta?&lt;/h3&gt;
Links to the beta downloads will be published to the &lt;a&gt;&lt;/a&gt;&lt;br&gt;
&lt;br&gt;
&lt;h3&gt;What if I find a bug?&lt;/h3&gt;
We have created a &lt;a&gt;&lt;/a&gt;&lt;br&gt;
&lt;br&gt;
We are particularly keen for people to load up their existing projects from older (ie 7 or earlier) versions of FinalBuilder, save them in FB8 format, and load them again and confirm that everything loaded ok.&amp;#160;&lt;br&gt;
&lt;br&gt;
&lt;h3&gt;When will it be released?&lt;/h3&gt;
&lt;h3&gt;
&lt;/h3&gt;
When it's ready ;)&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                         &amp;#13;
                    &lt;p&gt;Links to the beta downloads will be published to the &lt;a href="https://www.finalbuilder.com/downloads/finalbuilder"&gt;FinalBuilder Downloads&lt;/a&gt; page.We have created a &lt;a href="https://www.finalbuilder.com/support/forums/aff/66"&gt;Beta forum&lt;/a&gt; on our forums, or you can email support (please added Beta to the subject). When reporting an issue, be sure to include the beta build number and details about your environment. Please test with the latest beta build before reporting bugs.We are particularly keen for people to load up their existing projects from older (ie 7 or earlier) versions of FinalBuilder, save them in FB8 format, and load them again and confirm that everything loaded ok.When it's ready ;)&lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:finalbuilder-8-beta.html</guid></item><item><title>FinalBuilder and Team Foundation Server 2013</title><link>http://ciandcd.github.io/finalbuilder-and-team-foundation-server-2013.html</link><description>From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/705/finalbuilder-and-team-foundation-server-2013"&gt;https://www.finalbuilder.com/resources/blogs/postid/705/finalbuilder-and-team-foundation-server-2013&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;FinalBuilder offers you tight integration into TFS with an easy to understand IDE. In this post I will go into how to integrate FinalBuilder into your TFS build process. The post will cover;&lt;/p&gt;
 
&lt;br&gt;
&lt;p&gt;To make sure this post doesn't rival "war and peace" in size, I will assume a few things during the post. Namely that you have used TFS in some fashion, and/or have gotten a solution building under TFS with the default TFS template. For more information on getting up and running with TFS and common issues with TFS I suggest taking a look at the TFS ranger &lt;a href="http://blogs.msdn.com/b/willy-peter_schaub/archive/2013/05/16/visual-studio-alm-ranger-solutions-catalog.aspx" class="vt-p"&gt;books&lt;/a&gt; and &lt;a href="http://vsarbuildguide.codeplex.com/" class="vt-p"&gt;blog&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;
Prerequisites&lt;/h4&gt;
&lt;p&gt;To follow along with this post you will need the following installed:&lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;Team Foundation Server 2013, with build agent (12.0.21005.1 or later)&lt;/li&gt;
    &lt;li&gt;FinalBuilder 7 (7.0.0.2745 or later)&lt;/li&gt;
    &lt;li&gt;Required Visual Studio or MSBuild version available on agent&lt;/li&gt;
    &lt;li&gt;&lt;a href="http://www.microsoft.com/en-us/download/confirmation.aspx?id=40750" class="vt-p"&gt;Agents for Microsoft Visual Studio 2013&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href="http://www.visualstudio.com/downloads/download-visual-studio-vs" class="vt-p"&gt;Team Explorer 2013&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;p&gt;The Team Foundation Server can be of any configuration as long as it has at least one agent and a reporting service. FinalBuilder 7 is required on the agent machine, and could also be installed on the developer&amp;#8217;s machine for editing of scripts. Agents for Microsoft Visual Studio 2013 will provide access to VSTest.Console which we require for testing on the build agent. Lastly, Team Explorer is required for interaction with source control from FinalBuilder&amp;#8217;s IDE. Without this installed source control will need to be done manually.&lt;/p&gt;
 
&lt;p&gt;To start I have a solution under source control on a TFS 2013 collection. The solution I will be using is under a team project called VSoftSFTPLibrary &amp;#160;under the collection &amp;#8220;TFS2013\DefaultCollection&amp;#8221;. &amp;#160;The layouts of the team project looks like the following:&lt;/p&gt;
&lt;p&gt;&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/jason/FinalBuilderAndTeamFoundationServer2013/SourceControlExplorerLayout.png" alt="Define Report"&gt;&lt;/p&gt;
&lt;p&gt;I have a directory for the SFTP projects source, library files and its tests. The layout of your source control may vary from mine, however the main point to note here is that separating out directories isn&amp;#8217;t an issue. With the solution, all related files, and binaries under source control I now add a build definition to the team project.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/jason/FinalBuilderAndTeamFoundationServer2013/DefaultBuildName.png" alt="Build Name"&gt;&lt;/p&gt;
&lt;p&gt;Next the folders to be used in the FinalBuilder script need to be mapped from the server to an agent location. It&amp;#8217;s important to map all folders which contain files required for the build process. At this stage we only really know of the Source directory we are going to be build and the Library folder which the source relies on. Note that if your solution relies on a certain structure of folders this structure should be the same when it arrives on the agent. In the example the source and library paths are at the same folder depth, therefore this is reflected on the agent side.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/jason/FinalBuilderAndTeamFoundationServer2013/DefaultBuildSourceSettings.png" alt="Define Report"&gt;&lt;/p&gt;
&lt;p&gt;When the build is finished usually we want them &amp;#8220;dropped&amp;#8221; somewhere on the network. A FinalBuilder script can use this drop location, which we will go into later on in the artcile. For now I set this to a server location accessible by the build agent service user.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/jason/FinalBuilderAndTeamFoundationServer2013/DefaultBuildDropFolder.png" alt="Drop Folder"&gt;&lt;/p&gt;
 
&lt;p&gt;By default the build process is set to the default build process which comes with TFS2013. The template is called &amp;#8220;TfvcTemplate.12.xaml&amp;#8221;. When used the default template will enable the building, testing, impact testing, and deployment of a solution and its projects. Our aim is to perform all the same build activities with the additon of a FinalBuilder project.&amp;#160;&lt;/p&gt;
&lt;p&gt;To this end, the build process template needs to be changed over to one of the two supplied with FinalBuilder. In the [%ProgramFiles(x86)%\FinalBuilder &amp;#160;7\TFS Templates\2013] folder there are two TFS 2013 build workflow templates. &amp;#8220;FinalBuilderTFS2013Build.xaml&amp;#8221; performs all the same steps as the default build workflow and adds a FinalBuilder step just after the MSBuild activity and just before the optional &amp;#8220;after MSBuild script&amp;#8221;. This script is typically used by those looking to convert current default script builds to FinalBuilder in a simple and piece-meal fashion.&amp;#160;&lt;/p&gt;
&lt;p&gt;&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/jason/FinalBuilderAndTeamFoundationServer2013/FinalBuilderTFS2013Templates.png" alt="Define Report"&gt;&lt;/p&gt;
&lt;p&gt;The &amp;#8220;FinalBuilderOnlyTFS2013Build.xaml&amp;#8221; template is used when the FinalBuilder script is to take over the entire build process. For the moment I will use the &amp;#8220;FinalBuilderTFS2013Build.xaml&amp;#8221; script. Add these two scripts to the team project, typically under a BuildTemplates folder to separate them from the source and library code.&amp;#160;&lt;/p&gt;
&lt;p&gt;&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/jason/FinalBuilderAndTeamFoundationServer2013/DefaultBuildAddFBTemplates.png" alt="Add FB Template"&gt;&lt;/p&gt;
&lt;p&gt;Copy these templates into the local mapped location for this team project, and check them into source control. Now the &amp;#8220;FinalBuilderTFS2013Build.xaml&amp;#8221; template can be selected as the build process template. To do this add a new new build in the process section of the build definition. Navigate to the source control location where the template is stored and select it.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/jason/FinalBuilderAndTeamFoundationServer2013/DefaultBuildNewTemplateForBuild.png" alt="New Template For Build"&gt;&lt;/p&gt;
 
&lt;p&gt;The next step is to fill in the parameters for the build process. The majority of these are the exact same as the default TFS 2013 template with the addition of some FinalBuilder specific settings. The FinalBuilder section of settings allow for the specification of the project file, and custom arguments for the FinalBuilder project.&amp;#160;Note that the &amp;#8220;2. Build | Projects&amp;#8221;, and the &amp;#8220;6. FinalBuilder | Project File&amp;#8221; are both required by the build template. These are used to determine what should be built and what FinalBuilder project should be run.&amp;#160;&lt;/p&gt;
&lt;p&gt;&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/jason/FinalBuilderAndTeamFoundationServer2013/DefaultBuildTemplateArguments.png" alt="Define Report"&gt;&lt;/p&gt;
&lt;p&gt;To run a FinalBuilder project we need to create one. Therefore create a FinalBuilder project with just an [Action Group] action for the moment. Save this project to the team projects FinalBuilderScripts folder and check it into source control.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/jason/FinalBuilderAndTeamFoundationServer2013/DefaultBuildInitialFBProjectAddToSourceControl.png" alt="Project Added To Source Control"&gt;&lt;/p&gt;
&lt;p&gt;Once the FinalBuilder project is in source control select it in the build process using the file selector provided through the ellipse selector. You should end up with something reading like this &amp;#8220;$/VSoftSFTPLibrary/FinalBuilderScripts/BuildVSoftSFTPLibrary.fbp7&amp;#8221;&lt;/p&gt;
&lt;p&gt;Now that we have included the FinalBuilder project into our build process we need to make sure its folder is mapped to the agent. Open the source settings section, and add a mapping for the folder in which the FinalBuilder project resides. Something like the following should be what results.&amp;#160;&lt;/p&gt;
&lt;p&gt;&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/jason/FinalBuilderAndTeamFoundationServer2013/DefaultBuildSourceSettingsWithFinalBuilderFolderMapped.png" alt="Define Report"&gt;&lt;/p&gt;
&lt;p&gt;
&lt;/p&gt;
&lt;p&gt;Queue the build and the log should read like the following excerpt. The [Action Group] line is the action group you added in the FinalBuilder project.&amp;#160;&lt;/p&gt;
&lt;p&gt;&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/jason/FinalBuilderAndTeamFoundationServer2013/DefaultBuildFinalBuilderRunSuccessfullyJustActionGroup.png" alt="Successful Run With Just an Action Group"&gt;&lt;/p&gt;
&lt;p&gt;So now we have a TFS build process which is able to call a FinalBuilder script. In the next section we will delve more into how to extract information from TFS about the build inside our FinalBuilder script.&amp;#160;&lt;/p&gt;
&lt;h4&gt;Retrieving information from TFS in a FinalBuilder Script&lt;/h4&gt;
&lt;p&gt;For the FinalBuilder script to be of use in the TFS build process, it requires information about the TFS build currently running. To provide this we offer a number of actions that can extract this information during the TFS build run.&amp;#160;To get you started, there is an example project in &amp;lt;FinalBuilderInstallDir&amp;gt;\TFS Templates called TFSExample.fbp7. This sample project contains examples of the actions to use during a TFS build process. &amp;#160;&lt;/p&gt;
&lt;p&gt;&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/jason/FinalBuilderAndTeamFoundationServer2013/FinalBuilderTFSExampleProject.png" alt="Define Report"&gt;&lt;/p&gt;
&lt;p&gt;The [Get Team Foundataion Build Parameters] action is a special action that is only useful when a project is launched from TFS. It assigns TFS data to the specified project variables.&amp;#160;&lt;/p&gt;
&lt;p&gt;&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/jason/FinalBuilderAndTeamFoundationServer2013/FinalBuilderGetTeamFoundationBuildParams.png" alt="Foundation Build Params"&gt;&lt;/p&gt;
&lt;p&gt;Each of the variables in the [Get Team Foundation Build Parameters] action are as follows:&lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;Team Server URL: This is the URL of the team foundation server that queued the build.&lt;/li&gt;
    &lt;li&gt;Team Project: Is the name of the team project the build belongs to.&lt;/li&gt;
    &lt;li&gt;Build Id: Is the unique number allocated to this build.&lt;/li&gt;
    &lt;li&gt;Platform/Flavor: These are the build parameters for the compilation of the solution to be built.&lt;/li&gt;
    &lt;li&gt;Default Solution File: The solution file listed as the primary for the team project.&lt;/li&gt;
    &lt;li&gt;Solution File List: The list of solutions to be built by the build process.&lt;/li&gt;
    &lt;li&gt;Deployment Folder: The drop folder configured for the build process. It is blank if it is not set.&lt;/li&gt;
    &lt;li&gt;Source Root: The first listed solutions root folder.&lt;/li&gt;
    &lt;li&gt;Working Directory: A working directory on the agent for the current build definition. Typically space which is shared between builds made on the same agent.&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;p&gt;On the Custom Arguments tab is a list of ten variables which can be passed from the TFS build process to FinalBuilder. These are passed as plain text and converted to the variable types used to read them in the FinalBuilder script.&lt;/p&gt;
&lt;p&gt;For my script I only wanted to get the Team Foundation Build Parameters, and the variables that it used. So first I checked out the &amp;#8220;BuildVSoftSFTPLibrary.fbp7&amp;#8221; project using the built in source control features of FinalBuilder.&lt;/p&gt;
&lt;p&gt;First I need to make sure that it is indeed added to source control. If it hasn&amp;#8217;t detected that it is part of the TFS source control at this stage I add it to source control. I make sure to select the &amp;#8220;Microsoft Team Foundation Server MSSCCI provider&amp;#8221; which will use the Team Explorer 2013 installed on the machine. I select the TFS 2013 server and collection I am working with, also making sure the team project is correct. Once this is done I am then able to use the file menu to check the project out ready for editing.&amp;#160;&lt;/p&gt;
&lt;p&gt;Next I copy all the variables I want from the TFSExample project, and paste them into my BuildVSoftSFTPLibrary.fbp7 project. To paste the variables I open the Variables Editor, right click and select paste.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/jason/FinalBuilderAndTeamFoundationServer2013/FinalBuilderCopyVariables.png" alt="Define Report"&gt;&lt;/p&gt;
&lt;p&gt;Last I copy over the [Get Team Foundation Build Parameters] and [Trigger Files Iterator] actions. These use the variables we just copied over and will hook themselves up as they appeared in the example project.&amp;#160;&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/jason/FinalBuilderAndTeamFoundationServer2013/FinalBuilderProjectWithGetTFSBuildParamsAndIterateTiggerFiles.png"&gt;&lt;/p&gt;
&lt;p&gt;Now we can check in these changes and queue the build.&amp;#160;&lt;/p&gt;
&lt;p&gt;In the log for the build you will see the following:&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/jason/FinalBuilderAndTeamFoundationServer2013/FinalBuilderGetTeamFoundationBuildParamsAndLog.png"&gt;&lt;/p&gt;
&lt;p&gt;By default the [Get Team Foundation Build Parameters] action will write what it has retrieved from TFS to the build log. Something to keep in mind when debugging a FinalBuilder script in TFS.&lt;/p&gt;
 
&lt;p&gt;So now we want to make the FinalBuilder process take over the build completely. The first thing to do here is to stop the TFS build process from building, testing, and publishing results of the build. This requires changing the build workflow to remove the activities which do this (otherwise we would be doing things twice), and updating the FinalBuilder script to perform these tasks.&amp;#160;&lt;/p&gt;
&lt;p&gt;Instead of working out which activities to remove from the build template we provide a build template with all the build and testing activities removed. The &amp;#8220;FinalBuilderOnlyTFS2013Build.xaml&amp;#8221; template which was copied into the BuildTemplates folder is this template.&amp;#160;&lt;/p&gt;
&lt;p&gt;In the process section of the build definition, create a new build process using the &amp;#8220;FinalBuilderOnlyTFS2013Build.xaml&amp;#8221; file. You will notice that nearly everything in the build parameters is the same except now the before and after script events have been removed. Also the testing section is no longer present. All of this will be handled by the FinalBuilder script.&lt;/p&gt;
&lt;p&gt;Once again open your FinalBuilder project for this build and check it out. Also open up the TFSExample.fbp7 project and take a look at the [Build VS.Net Solution] action. Copy this action to the project used to build your solution.&amp;#160;&lt;/p&gt;
&lt;p&gt;The [Build VS.NET Solution] action builds a Visual Studio.NET solution. On the [Solution] tab you will see that the Solution File is set to &amp;#8220;%SourceRoot%\&amp;lt;YourSolution&amp;gt;.sln&amp;#8221;. Replace &amp;lt;YourSolution&amp;gt; with the name of the solution that you wish to build. Note that &amp;#8220;%SourceRoot%&amp;#8221; will be the directory of only the first solution in the list of projects to build. In my project I ended up with a Solution File value of &amp;#8220;%SourceRoot%\VSoftSFTPLibrary.sln&amp;#8221; for the [Build VS.NET Solution] action.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/jason/FinalBuilderAndTeamFoundationServer2013/FinalBuilderBuildVSSolution.png"&gt;&lt;/p&gt;
&lt;p&gt;On the [Paths] tab you will see that the Output Directory is set to %SourceRoot%\Binaries. You may change this if you wish, but it's it not necessary. Note because the drop location may be on a different server to the build agent, it is important that VSTest runs on files located on the build agent machine. Unless you explicitly set up the trust relationship, .NET will not allow executing of assemblies on remote machines. This is why we build and test in a directory under %SourcesRoot% and then move the files to the drop location after testing. This will be covered more in the next section.&amp;#160;&lt;/p&gt;
&lt;p&gt;On the agent the TFS agent the FinalBuilder options for Visual Studio will need to be set. If not and DEVENV.COM is required, the build will fail about the build tool location being unknown. &lt;/p&gt;
&lt;p&gt;Now are right to run the build with using just FinalBuilder. Queue the build again and now the project will build, not from a template activity but from the FinalBuilder script it is running.&amp;#160;
&lt;/p&gt;
 
&lt;p&gt;To perform testing we need to add a [Run VSTest.Console] action to the FinalBuilder project. The [Run VSTest.Console] uses VSTest.Console to run your test assemblies. On the [Settings] tab add the name of your test assembly to the list. You should end up with something along the lines of &amp;#8220;%SourceRoot%\Binaries\&amp;lt;YourTestAssembly&amp;gt;.dll&amp;#8221;. On the [Publish Results] tab the action should be set to automatically publish the results to the TFS server. This means that after the tests are run they will automatically be stored with the build on the TFS Server.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/jason/FinalBuilderAndTeamFoundationServer2013/FinalBuilderVSTestConsoleSettings.png"&gt;&lt;/p&gt;
&lt;p&gt;Note that the [Ignore Failure] option, located on the [Options] tab, is important. If any unit tests fail, the [Run VSTest.Console] action will fail, and setting [Ignore Failure] allows the FinalBuilder and TFS builds to continue. Un-check [Ignore Failure] if you would prefer the build to stop on failed tests. In either case, test failures will appear in the TFS build log and in TFS reports.&lt;/p&gt;
&lt;p&gt;On the agent the TFS agent the FinalBuilder options for VSTest.Console will need to be set. If not, the build will fail with an error about the VSTest.Console location being unknown. &lt;/p&gt;
 
&lt;p&gt;The last step to complete the process is to move all the files from the agent to your drop location. The simplest way to achieve this is by a [Move File(s)] action. We already have the drop folder location stored in the %DropShare% variable. It is this value which we then use in the [Move File(s)] action. &lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/jason/FinalBuilderAndTeamFoundationServer2013/FinalBuilderMoveFilesToDropFolder.png"&gt;&lt;/p&gt;
&lt;p&gt;Once this is run we will have a built solution, with tests run, and the binaries copied into the specified drop folder.&amp;#160;&lt;/p&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:finalbuilder-and-team-foundation-server-2013.html</guid></item><item><title>For Go 15.1 upgrade your Java</title><link>http://ciandcd.github.io/for-go-151-upgrade-your-java.html</link><description>From:&lt;a href="http://www.go.cd/2015/04/23/Go_15_1_jdk7_announcement.html"&gt;http://www.go.cd/2015/04/23/Go_15_1_jdk7_announcement.html&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;GoCD has &lt;a href="http://www.go.cd/2014/07/09/stopping-support-for-java-jdk-6.html"&gt;stopped support JDK 6&lt;/a&gt; for some time now. But we understand that some users were using Java 6, so we continued to support it as long as we could while helping users migrate their Go servers and agents to Java 7.&lt;/p&gt;

&lt;p&gt;Java 6 was declared end-of-life in February 2013, and Java 7 is scheduled to be declared end-of-life soon.&lt;/p&gt;

&lt;p&gt;Starting with the 15.1 release of GoCD, it will only run with Java 7. Users are encouraged to upgrade to the latest release of GoCD with Java 8.&lt;/p&gt;

&lt;p&gt;Starting with the next release, we plan on providing support for Java 8.&lt;/p&gt;

&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:for-go-151-upgrade-your-java.html</guid></item><item><title>Get Started Using Go</title><link>http://ciandcd.github.io/get-started-using-go.html</link><description>From:&lt;a href="http://www.go.cd/2015/05/06/Getting-Started-Resources.html"&gt;http://www.go.cd/2015/05/06/Getting-Started-Resources.html&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Some resources to help get started using Go.&lt;/p&gt;

&lt;h4&gt;Go User Documentation&lt;/h4&gt;

&lt;p&gt;There are a couple sections of the user documentation that can be especially helpful to people new to Go.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.go.cd/documentation/user/current/introduction/concepts_in_go.html"&gt;Concepts in Go&lt;/a&gt; - This covers some of the
basic concepts used in Go. A good understanding of what Pipelines, Stages, Jobs and Tasks are will be very helpful.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.go.cd/documentation/user/current/configuration/managing_a_build_cloud.html"&gt;Managing Agents&lt;/a&gt; - The Go server
produces the user interface for Go, but it doesn't actually run your jobs. Learn how to use Go Agents to "do the work".&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.go.cd/documentation/user/current/configuration/quick_pipeline_setup.html"&gt;Setting up a new Pipeline&lt;/a&gt; See how
to set up your first pipeline&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;/p&gt;&lt;p&gt;
Of course there's a lot more information available as well.&lt;/p&gt;

&lt;h4&gt;Other information online&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://groups.google.com/forum/#!forum/go-cd"&gt;The Go mailing list&lt;/a&gt; - A great place to search for answers to questions
you may have, or of course ask them if they aren't already covered.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://webchat.freenode.net/?channels=gocd"&gt;IRC&lt;/a&gt; - Connect to freenode with your own IRC client or use this web client.
Don't forget to uncheck "auth to services" if you're not planning to login with your preset freenode information.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;Live demonstrations&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.thoughtworks.com/products/go-continuous-delivery/resources#Webinars"&gt;Webinars&lt;/a&gt; - ThoughtWorks presents live
webinars every couple weeks so that you can see Go in action. There are also recordings of previous webinars on this blog.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;Professional Support&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.thoughtworks.com/products/go-continuous-delivery"&gt;ThoughtWorks&lt;/a&gt; - The first 30 days of professional support
provided by ThoughtWorks is free. You'll get access to a global support team, and tough issues can be escalated directly to
the Go development team.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;Alternative Trial Installation&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://registry.hub.docker.com/u/gocd/gocd-server/"&gt;Docker Container&lt;/a&gt; - This is an easy way to see what Go does. As it
says in the description, this is not a production container. You'll also need at least one instance of the &lt;a href="https://registry.hub.docker.com/u/gocd/gocd-agent/"&gt;agent container&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:get-started-using-go.html</guid></item><item><title>Go 14.3 Released</title><link>http://ciandcd.github.io/go-143-released.html</link><description>From:&lt;a href="http://www.go.cd/2014/11/11/Go_14_3_announced.html"&gt;http://www.go.cd/2014/11/11/Go_14_3_announced.html&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Today we released Go 14.3&lt;/p&gt;

&lt;p&gt;You can download it from &lt;a href="http://www.go.cd/download/"&gt;here&lt;/a&gt;. Take a look at &lt;a href="http://www.go.cd/releases/#latest"&gt;release notes&lt;/a&gt; to see details. &lt;/p&gt;

&lt;p&gt;This release saw lot of contributions from the community. A huge callout to the following contributors (not in any particular order) for their outstanding contributions : &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href="https://github.com/lcs777"&gt;@lcs777&lt;/a&gt;, &lt;a href="https://github.com/ciotlosm"&gt;@ciotlosm&lt;/a&gt;, &lt;a href="https://github.com/tusharm"&gt;@tusharm&lt;/a&gt;, &lt;a href="https://github.com/juniorz"&gt;@juniorz&lt;/a&gt;, &lt;a href="https://github.com/RikTyer"&gt;@RikTyer&lt;/a&gt;, &lt;a href="https://github.com/mmb"&gt;@mmb&lt;/a&gt;, &lt;a href="https://github.com/afoster"&gt;@afoster&lt;/a&gt; , &lt;a href="https://github.com/sahilm"&gt;@sahilm&lt;/a&gt;,  &lt;a href="https://github.com/gregoriomelo"&gt;@gregoriomelo&lt;/a&gt;, &lt;a href="https://github.com/greenmoss"&gt;@greenmoss&lt;/a&gt; , &lt;a href="https://github.com/dvarchev"&gt;@dvarchev&lt;/a&gt; and Temmert&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;(We have tried to be as accurate as possible. Sincere apologies if we missed mentioning anyone above)&lt;/p&gt;

&lt;p&gt;We would also like to thank people who reported issues/feature requests and participated in various discussions. That list is too big to be mentioned here, but please know that all the time and energy spent by everyone in improvising Go is very much appreciated.&lt;/p&gt;

&lt;p&gt;Thanks once again!&lt;/p&gt;

&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:go-143-released.html</guid></item><item><title>Go 14.4 Released</title><link>http://ciandcd.github.io/go-144-released.html</link><description>From:&lt;a href="http://www.go.cd/2014/12/17/Go_14_4_announced.html"&gt;http://www.go.cd/2014/12/17/Go_14_4_announced.html&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Today we released Go 14.4&lt;/p&gt;

&lt;p&gt;You can download it from &lt;a href="http://www.go.cd/download/"&gt;here&lt;/a&gt;. Take a look at &lt;a href="http://www.go.cd/releases/#latest"&gt;release notes&lt;/a&gt; to see details. &lt;/p&gt;

&lt;p&gt;Sincere thanks to everyone who contributed to Go in form of features, ideas, issues / feature requests and much more! A special mention goes to &lt;a href="https://github.com/mythgarr"&gt;@mythgarr&lt;/a&gt;, &lt;a href="https://github.com/hammerdr"&gt;@hammerdr&lt;/a&gt; and to the &lt;a href="http://www.pivotal.io/?mkt_tok=3RkMMJWWfF9wsRomrfCcI63Em2iQPJWpsrB0B%2FDC18kX3RUvIL6Wbgfind1SFJk7a8C6XFNJSt1Q5CkVSLnE"&gt;Pivotal&lt;/a&gt; team: &lt;a href="https://github.com/mmb"&gt;@mmb&lt;/a&gt;, &lt;a href="https://github.com/gajwani"&gt;@gajwani&lt;/a&gt; , &lt;a href="https://github.com/fkotsian"&gt;@fkotsian&lt;/a&gt;,  &lt;a href="https://github.com/bsnchan"&gt;@bsnchan&lt;/a&gt; for their active contributions and support.&lt;/p&gt;

&lt;p&gt;Thanks once again!&lt;/p&gt;

&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:go-144-released.html</guid></item><item><title>Go 15.1.0 Released</title><link>http://ciandcd.github.io/go-1510-released.html</link><description>From:&lt;a href="http://www.go.cd/2015/04/29/Go_15_1_announced.html"&gt;http://www.go.cd/2015/04/29/Go_15_1_announced.html&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;We would like to announce a new release of gocd. Head over to our &lt;a href="http://www.go.cd/download/"&gt;downloads page&lt;/a&gt; to get your hands on the latest and greatest. Read more about what's new in this release from our &lt;a href="http://www.go.cd/releases/#latest"&gt;release notes&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Sincere thanks to everyone who contributed to Go in form of features, ideas, issues / feature requests and much more! A special mention goes to &lt;a href="https://github.com/ashwanthkumar"&gt;@ashwanthkumar&lt;/a&gt;, &lt;a href="https://github.com/alexschwartz"&gt;@alexschwartz&lt;/a&gt;, &lt;a href="https://github.com/sachinsudheendra"&gt;@sachinsudheendra&lt;/a&gt;, &lt;a href="https://github.com/pwen"&gt;@pwen&lt;/a&gt;, &lt;a href="https://github.com/pamo"&gt;@pamo&lt;/a&gt;, &lt;a href="https://github.com/bernardn"&gt;@bernardn&lt;/a&gt;, &lt;a href="https://github.com/danielsomerfield"&gt;@danielsomerfield&lt;/a&gt;, &lt;a href="https://github.com/iliasbartolini"&gt;@iliasbartolini&lt;/a&gt; for their active contributions and support.&lt;/p&gt;

&lt;p&gt;Thanks once again!&lt;/p&gt;

&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:go-1510-released.html</guid></item><item><title>Go Plugin Competition</title><link>http://ciandcd.github.io/go-plugin-competition.html</link><description>From:&lt;a href="http://www.go.cd/2015/01/20/Go_plugin_competition.html"&gt;http://www.go.cd/2015/01/20/Go_plugin_competition.html&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Are you up for the challenge?&lt;/p&gt;

&lt;p&gt;Do you have what it takes to build an awesome Go plugin? Here&amp;#8217;s your chance to put your development skills to the test. ThoughtWorks invites you to the first ever Go plugin challenge. We want you to build a plugin that showcases the best of Go. Have you been playing with an idea on the side or has your organisation developed something really cool that others would love? This is your chance to showcase it and win a prize!
&lt;a href="http://thght.works/1CdY4aq"&gt;Read more...&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Important Dates&lt;/p&gt;

&lt;p&gt;Submission Deadline:
February 20, 2015 at 11:59 PM CST 
(February 21, 2015 at 5:59 AM GMT)&lt;/p&gt;

&lt;p&gt;Notification of Acceptance: 
February 27, 2015&lt;/p&gt;

&lt;p&gt;Results: 
March 10, 2015 &lt;/p&gt;

&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:go-plugin-competition.html</guid></item><item><title>Hardly Anyone Knows Continuous Delivery</title><link>http://ciandcd.github.io/hardly-anyone-knows-continuous-delivery.html</link><description>From:&lt;a href="http://www.go.cd/2015/06/23/hardly-anyone-knows-cd.html"&gt;http://www.go.cd/2015/06/23/hardly-anyone-knows-cd.html&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Those of us who work in or around teams doing continuous delivery often think it&amp;#8217;s a mainstream thing. This couldn&amp;#8217;t be further from the truth.&lt;/p&gt;

&lt;p&gt;I work for ThoughtWorks, a company that implements processes and technologies we think are good long before most. We built the first CI server with Cruise Control, and Go was the first purpose built Continuous Delivery server. I go to a lot of conferences and events, read a lot of blogs, talk to a lot of peers, work with a lot of partners, etc. I thought most people involved with the creation of software had a pretty good idea what CD is.&lt;/p&gt;

&lt;p&gt;I was wrong.&lt;/p&gt;

&lt;p&gt;I just got back from a pretty big software conference that was a bit off my normal track. They had a few DevOps sessions this year, but historically this particular conference has been more about agile methodologies. As one of the sponsors, I spent a lot of time at the booth talking to people.&lt;/p&gt;

&lt;p&gt;The conversations in a trade show booth generally start with the visitor asking what we do (gotta work more on that so they don&amp;#8217;t have to) and me telling them that Go is a continuous delivery server. From there we go on to talk about what makes Go unique and why they should use it.&lt;/p&gt;

&lt;p&gt;At this show, when I told people Go is a continuous delivery server I was met with mostly blank stares. This was a conference attended by 100% people who create software for a living. The people attending care enough about their craft to spend (or get their company to spend) a couple thousand US dollars to come. But they had no idea what Continuous Delivery really is. I probably should note, this isn't meant as a knock on that conference at all.&lt;/p&gt;

&lt;p&gt;The lack of knowledge is a really bad thing. Not just for the Go CD project, but for software in general. The world runs on software. Too much of that software is bad. The practices around Continuous Delivery could make some of it better, or kill it before it gets out.&lt;/p&gt;

&lt;h4&gt;So what can we do?&lt;/h4&gt;

&lt;p&gt;Buy or borrow a copy of &lt;a href="http://www.amazon.com/Continuous-Delivery-Deployment-Automation-Addison-Wesley/dp/0321601912"&gt;Continuous Delivery&lt;/a&gt; by Jez Humble and Dave Farley for your office. Make everyone read at least the chapters that apply to them. Yes, Jez and Dave both worked for ThoughtWorks when they were writing the book. Yes, Jez was the product owner of Go before the book came out. No, we won't make any money off the link if you buy it. I promise this isn&amp;#8217;t bias, it&amp;#8217;s the definitive work on the subject.&lt;/p&gt;

&lt;p&gt;Get &lt;a href="http://www.amazon.com/The-Phoenix-Project-Helping-Business/dp/0988262509/ref=pd_bxgy_14_img_y"&gt;The Phoenix Project&lt;/a&gt; by Gene Kim. It&amp;#8217;s a fictional novel and a bit corny at times, but people will learn a bit even if they don&amp;#8217;t mean to.&lt;/p&gt;

&lt;p&gt;Send people that don&amp;#8217;t know about Continuous Delivery to conferences that are specific to CD and DevOps. My favorite is &lt;a href="http://www.devopsdays.org/"&gt;DevOpsDays&lt;/a&gt;. You don't need huge, expensive conferences where you&amp;#8217;ll have to get finance approval to attend. The next one I&amp;#8217;m going to is 200 bucks. If they don&amp;#8217;t have one in your area create one or find someone that will. (FYI, if anyone in Seattle is interested in doing that let me know)&lt;/p&gt;

&lt;p&gt;Take a friend who&amp;#8217;s CD impaired to a &lt;a href="http://devops.meetup.com/"&gt;DevOps Meetup&lt;/a&gt;. As I&amp;#8217;m writing this there are groups in 404 cities worldwide at that link alone. Trying to get your meetup going and struggling for content and/or speakers? Tell me, I know a few people and might be able to help.&lt;/p&gt;

&lt;p&gt;Stop assuming everyone knows what we&amp;#8217;re talking about when we talk about CD. Many of them are smiling and nodding the same way I do when my mother talks about her flowers.&lt;/p&gt;

&lt;p&gt;Feel free to comment with your own resource, this isn't even close to a definite list.&lt;/p&gt;

&lt;h4&gt;One last thing...&lt;/h4&gt;

&lt;p&gt;Stop telling people that the phrases DevOps and Continuous Delivery are overused. They aren&amp;#8217;t. Hardly anyone knows what Continuous Delivery is.&lt;/p&gt;

&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:hardly-anyone-knows-continuous-delivery.html</guid></item><item><title>Help Us Improve JetBrains.com and Win a License</title><link>http://ciandcd.github.io/help-us-improve-jetbrainscom-and-win-a-license.html</link><description>From:&lt;a href="http://blog.jetbrains.com/blog/2015/06/01/help-us-improve-jetbrains-com-and-win-a-license/"&gt;http://blog.jetbrains.com/blog/2015/06/01/help-us-improve-jetbrains-com-and-win-a-license/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p id="fb-root"&gt;&lt;/p&gt;&amp;#13;
 &amp;#13;
&lt;p&gt;&amp;#13;
&lt;/p&gt;&lt;p class="g-plusone"&gt;&lt;/p&gt;
 
&lt;p&gt;&lt;/p&gt;
 
&lt;p class="fb-like"&gt;&lt;/p&gt;&amp;#13;
&amp;#13;
&lt;br clear="all"&gt;&lt;p&gt;It has been a while since the last time that we updated &lt;a href="http://jetbrains.com"&gt;our web site&lt;/a&gt; design, nearly three years ago when we switched to the current design from the one below.&lt;/p&gt;
&lt;p&gt;&lt;img class="alignleft size-full wp-image-7033" alt="jetbrains.com 2012" src="http://blog.jetbrains.com/wp-content/uploads/2015/06/20121204-jetbrainscom-th.png" width="600" height="486"&gt;&lt;/p&gt;
&lt;p&gt;We&amp;#8217;re thinking about making another update some time soon, but as a team of very technical geeks we love numbers. We do have lots of data already from the different analytics systems we&amp;#8217;re using but we want to do a special survey right now dedicated specifically for JetBrains.com. &lt;/p&gt;
&lt;p&gt;It is people like you who are visiting the web site and using it to find the information that you need, so we are asking for your help.&lt;/p&gt;
&lt;p&gt;As the survey is about a web site, it might feel odd that we&amp;#8217;re asking some questions which might not seem relevant. However, often decisions we make are somewhat related to other aspects in our lives. We&amp;#8217;re catering the site to so many diverse individuals and some of the questions play an role in this. Having said that, some questions are optional.&lt;/p&gt;
&lt;p&gt;If you are willing to help us, please &lt;strong&gt;&lt;a href="https://www.surveymonkey.com/s/web-jetbrains"&gt;complete our survey&lt;/a&gt;&lt;/strong&gt;. &lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.surveymonkey.com/s/web-jetbrains"&gt;&lt;img src="http://blog.jetbrains.com/wp-content/uploads/2015/06/users_survey.png" alt="Web Site" width="545" height="99" class="alignnone size-full wp-image-7035"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;And yes, we have some prizes for those who complete the survey: a chance to &lt;strong&gt;win one of 10 personal licenses&lt;/strong&gt; for a JetBrains product of your choice, or &lt;strong&gt;one of 20 Amazon vouchers worth $25&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Thank you!&lt;/p&gt;
											&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:help-us-improve-jetbrainscom-and-win-a-license.html</guid></item><item><title>How to Fix your system path after installing Delphi</title><link>http://ciandcd.github.io/how-to-fix-your-system-path-after-installing-delphi.html</link><description>From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/722/how-to-fix-your-system-path-after-installing-delphi"&gt;https://www.finalbuilder.com/resources/blogs/postid/722/how-to-fix-your-system-path-after-installing-delphi&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;&lt;strong&gt;&lt;p&gt;Update : Still the same situation with XE8.&amp;#160;&lt;/p&gt;&lt;/strong&gt;&lt;br&gt;
&lt;br&gt;
The Windows Path environment variable has a limit of &lt;p&gt;1023&lt;/p&gt;&amp;#160;*&amp;#160;&lt;p&gt;&lt;strong&gt;2,048&lt;/strong&gt;&amp;#160;&lt;/p&gt;characters, a stupidly short limit in this day and age, and when this limit is exceeded the path is truncated. Why this limit still exists on windows I have no idea.. for that matter why it ever existed... anyway, we're stuck with it (along with it's best buddy, MAX_PATH).&amp;#160;&lt;/p&gt;&lt;br&gt;
&lt;br&gt;
Each version of Delphi adds over 200 characters to your system path. Worst still, they add those 200+ characters to the front of the path, not the end. What happens, is that eventually, important entries get truncated off end of the path, and &lt;strong&gt;strange things happen&lt;/strong&gt;. You will find programs will not run, the task bar displays the wrong icons for programs, even getting to the control panel can be problematic.&amp;#160;&lt;br&gt;
&lt;br&gt;
If you look at the entries that XE7 added to the start of your path you will see something like this :&lt;br&gt;
&lt;br&gt;
C:\Program Files (x86)\Embarcadero\Studio\15.0\bin;&lt;br&gt;
&lt;p&gt;C:\Program Files (x86)\Embarcadero\Studio\15.0\bin64;&lt;br&gt;
&lt;/p&gt;C:\Users\Public\Documents\Embarcadero\Studio\15.0\Bpl;&lt;br&gt;
C:\Users\Public\Documents\Embarcadero\Studio\15.0\Bpl\Win64;&lt;br&gt;
&lt;br&gt;
Fortunately this can be shortened by the use of junction points. Sadly, this will polute your C: drive with new folders but it's better than the alternative.&lt;br&gt;
&lt;br&gt;
The trick is to create links for the most common paths, so on mine I created these&lt;br&gt;
For XE5 and earlier :&lt;br&gt;
mklink /j RS C:\Program Files (x86)\Embarcadero\RAD Studio&lt;br&gt;
mklink /j rspub&amp;#160;C:\Users\Public\Documents\RAD Studio&lt;br&gt;
&lt;br&gt;
XE6 and above&amp;#160;&lt;br&gt;
&lt;br&gt;
mklink /j Studio&amp;#160;C:\Program Files (x86)\Embarcadero\Studio&lt;br&gt;
&lt;p&gt;mklink /j spub&amp;#160;&lt;/p&gt;&lt;p&gt;C:\Users\Public\Documents\Embarcadero\Studio&lt;/p&gt;&lt;br&gt;
&lt;br&gt;
Once you have those junction points, you can then edit your path and replace the long paths, for example (for XE7) :&lt;br&gt;
&lt;br&gt;
&lt;p&gt;C:\Program Files (x86)\Embarcadero\Studio\15.0\bin -&amp;gt;&amp;#160;&lt;/p&gt;&lt;p&gt;C:\Studio\15.0\bin&lt;br&gt;
&lt;/p&gt;&lt;p&gt;C:\Program Files (x86)\Embarcadero\Studio\15.0\bin64 -&amp;gt;&amp;#160;C:\Studio\15.0\bin64&lt;/p&gt;&lt;br&gt;
&lt;p&gt;C:\Users\Public\Documents\Embarcadero\Studio\15.0\Bpl&amp;#160;-&amp;gt;&amp;#160;C:\spub\15.0\Bpl&lt;/p&gt;&lt;br&gt;
&lt;p&gt;C:\Users\Public\Documents\Embarcadero\Studio\15.0\Bpl\Win64 - &amp;gt; c:\spub\15.0\Bpl\Win64&lt;br&gt;
&lt;/p&gt;&lt;br&gt;
So for XE7, that cuts it down from 218 to 80 characters, if like me you also have multiple versions of Rad Studio installed, this can be a big saving.&lt;br&gt;
&lt;br&gt;
As for Rad Studio, it's extremely rude to add things to the start of the path, the truncation it causes can ruin a machine.. I wasted several hours again today after installing XE7. Embarcadero were told about this issue many times over several releases.. according to the &lt;a&gt;&lt;/a&gt;&lt;strong&gt;PLEASE ADD IT TO THE END!!&lt;/strong&gt; and save us all a bunch of time.&amp;#160;&lt;br&gt;
&lt;br&gt;
*&amp;#160;Correction, max path length is 2048 - very difficult to find a difinitive source of this information on the microsoft site - the max size of an env variable is 2048, however I have seen the path variable truncated at 1024 many times.&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;p&gt;Each version of Delphi adds over 200 characters to your system path. Worst still, they add those 200+ characters to the front of the path, not the end. What happens, is that eventually, important entries get truncated off end of the path, and. You will find programs will not run, the task bar displays the wrong icons for programs, even getting to the control panel can be problematic.If you look at the entries that XE7 added to the start of your path you will see something like this :C:\Program Files (x86)\Embarcadero\Studio\15.0\bin;C:\Users\Public\Documents\Embarcadero\Studio\15.0\Bpl;C:\Users\Public\Documents\Embarcadero\Studio\15.0\Bpl\Win64;Fortunately this can be shortened by the use of junction points. Sadly, this will polute your C: drive with new folders but it's better than the alternative.The trick is to create links for the most common paths, so on mine I created theseFor XE5 and earlier :mklink /j RS C:\Program Files (x86)\Embarcadero\RAD Studiomklink /j rspub C:\Users\Public\Documents\RAD StudioXE6 and abovemklink /j Studio C:\Program Files (x86)\Embarcadero\StudioOnce you have those junction points, you can then edit your path and replace the long paths, for example (for XE7) :So for XE7, that cuts it down from 218 to 80 characters, if like me you also have multiple versions of Rad Studio installed, this can be a big saving.As for Rad Studio, it's extremely rude to add things to the start of the path, the truncation it causes can ruin a machine.. I wasted several hours again today after installing XE7. Embarcadero were told about this issue many times over several releases.. according to the &lt;a href="http://docwiki.embarcadero.com/RADStudio/XE7/en/Installation_Path_Length_Problem"&gt;doco&lt;/a&gt; , XE7 will popup a message about this.. I didn't see it so not sure when that is supposed to appear, but in any event, if your installer or progam needs to add something to the path environment variable,and save us all a bunch of time.Correction, max path length is 2048 - very difficult to find a difinitive source of this information on the microsoft site - the max size of an env variable is 2048, however I have seen the path variable truncated at 1024 many times.&lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:how-to-fix-your-system-path-after-installing-delphi.html</guid></item><item><title>Integrating DUnitX Unit Testing with Continua CI</title><link>http://ciandcd.github.io/integrating-dunitx-unit-testing-with-continua-ci.html</link><description>From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/699/integrating-dunitx-unit-testing-with-continua-ci"&gt;https://www.finalbuilder.com/resources/blogs/postid/699/integrating-dunitx-unit-testing-with-continua-ci&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Continua CI includes support for running and reporting on Unit Tests, in this post we will take a look at running &lt;a href="https://github.com/VSoftTechnologies/DUnitX" title="DUnitX is open source, on GitHub"&gt;DUnitX&lt;/a&gt;&amp;#160;Unit Tests. If you not familiar with &lt;a href="https://github.com/VSoftTechnologies/DUnitX" title="DUnitX is open source, on GitHub"&gt;DUnitX&lt;/a&gt;, it's a newish Delphi Unit Test framework, I &lt;a href="http://www.finalbuilder.com/Resources/Blogs/PostId/697/introducing-dunitx" title="Introducing DUnitX - a Unit Test framework for Delphi"&gt;blogged about it recently&lt;/a&gt;.&amp;#160;&lt;/p&gt;
&lt;p&gt;I'm not going to cover how to get up and running in Continua CI, but rather I'll focus on the Unit Testing support. If you are not familiar with Continua CI, take a look at &lt;a href="http://www.finalbuilder.com/Resources/Blogs/PostId/695/building-delphi-projects-with-continua-ci" title="Building Delphi projects with Continua CI"&gt;this recent post&lt;/a&gt; which describes how to build Delphi projects with Continua CI.&lt;/p&gt;
&lt;p&gt;Assuming you have you Continua CI Configuration all set up, lets take a quick look at how to integrate our unit tests into the build process. You need to build a console application, and make use of the xml logger. This is how the dpr of our typical DUnitX console test application might look &amp;#160;:&lt;/p&gt;
&lt;pre class="brush:delphi; toolbar:true;"&gt;var
  runner : ITestRunner;
  results : IRunResults;
  logger : ITestLogger;
  xmlLogger : ITestLogger;
begin
  try
    //Create the runner
    runner := TDUnitX.CreateRunner;
   
    //add a console logger, pass in true to specify quiet mode
    //as we don't need detailed console output.
    logger    := TDUnitXConsoleLogger.Create(true);
    runner.AddLogger(logger);
    
    //add an nunit xml loggeer
    xmlLogger := TDUnitXXMLNUnitFileLogger.Create;
    runner.AddLogger(nunitLogger);

    //Run tests
    results := runner.Execute;

    {$IFDEF CI}
    //Let the CI Server know that something failed.
    if not results.AllPassed then
      System.ExitCode := 1;
    {$ELSE}
    //We don;t want this happening when running under CI.
    System.Write('Done.. press  key to quit.');
    System.Readln;
    {$ENDIF}
    
  except
    on E: Exception do
    begin
      System.Writeln(E.ClassName, ': ', E.Message);
      System.ExitCode := 2;
    end;
  end;
end.
&lt;/pre&gt;
&lt;p&gt;The key thing to remember, is that this application is going to be running unattended, so never use ReadLn or any sort of interaction/prompting for input etc. If I had a dollar for every "Finalbuilder/Continua CI hangs during my build" bug report in the last 13 years, I'd be a... well not rich, but a few hundred dollars better off! Notice I used $IFDEF CI above to set the exit code to 1&amp;#160;if not all tests pass.&amp;#160;&lt;/p&gt;
&lt;p&gt;So the next thing we need to is actually get the console application building in Continua CI. I covered building delphi applications with Continua CI in earlier post, so I'll just highlight a few things specific items that we need. Firsly, if you don't have the DUnitX source code in your repository, and have configured a repositoroy for it in Continua CI, then you need to update the Search Path for your console application. If you are using MSBuild to build the console app, then it's done on the Properties tab of the MSBuild Action :&lt;/p&gt;
&lt;p&gt;&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/vincent/DUnitX-CI/DUnitX-MSBuild.png" alt="MSBuild Properties"&gt;
&lt;/p&gt;
&lt;p&gt;I have DUnitX in a Continau CI repository named DUnitX, and I've used the default path to the repository in the workspace ( $Source.DUnitX$ translates to "/Source/DUnitX" in the build workspace). If you are using FinalBuilder, you need to pass that to a FinalBuilder variable in the FinalBuilder Action, I'll cover that in more detail in a future post. Notice I also set the CI define I used in my code. The other important setting, is the ExeOutput path, which much be somewhere inside the build's workspace, so I set it to $Workspace$\Output - Continua CI will translate $Workspace$ at build time to be the workspace folder for the build (each Continua CI build gets a clean unique workspace folder).&amp;#160;&lt;/p&gt;
&lt;p&gt;Now it's time to add our DUnitX action, somewhere in the stage workflow after we have built the test application.&amp;#160;&lt;/p&gt;
&lt;p&gt;&amp;#160;&lt;/p&gt;
&lt;p&gt;&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/vincent/DUnitX-CI/DUnitX-Workflow.png" alt="Stage Workflow"&gt;
&lt;/p&gt;
&lt;p&gt;Setting up the DUnitX action is quite simple :
&lt;/p&gt;
&lt;p&gt;&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/vincent/DUnitX-CI/DUnitX-Action.png" alt="DUnitX Action"&gt;
&lt;/p&gt;
&lt;p&gt;&amp;#160;&lt;/p&gt;
&lt;p&gt;We set the Test Executable to our test console app, which in the MSBuild action we configured to be output to $Workspace$\Output - and we specify where to put the xml file that DUnitX will generate (because we added the NUnit logger). &amp;#160;The other two options control whether the to fail the Action/Build if any tests fail or error. If you have more than one Unit Test action to run in your build process, then it's bests to leave these unchecked and use the Stage Gate feature (on the Stage Options dialog) to fail the build (more on this later).&amp;#160;&lt;/p&gt;
&lt;p&gt;After running the build, the Unit Test results appear in a two places, firstly the Build Details page, which shows the totals for the build (for all unit tests run) :&lt;/p&gt;
&lt;p&gt;&amp;#160;&lt;/p&gt;
&lt;p&gt;&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/vincent/DUnitX-CI/DUnitX-BuildResult.png" alt="Unit Test Totals"&gt;
&lt;/p&gt;
&lt;p&gt;You can drill into the tests by clickong on the numbers, or by clicking on the Unit Tests tab :&amp;#160;&lt;/p&gt;
&lt;p&gt;&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/vincent/DUnitX-CI/DUnitX-Results.png" alt="Unit Test Details"&gt;
&lt;/p&gt;
&lt;p&gt;This page allows you to filter by status (click on the numbers), and filter by Fixture, Namespacve etc. The first time a test fails, it will show up inder the New Failures category and under Failures. Clicking on a Failed or Errored test expands the row to show the error message logged by the test framework :&lt;/p&gt;
&lt;p&gt;&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/vincent/DUnitX-CI/DUnitX-FailingDetail.png" alt="Failing Test Details"&gt;
&lt;/p&gt;
&lt;p&gt;Notice the Shelve button next to each test. If you have a test that always fails, and you don't want it to cause the build to fail, &lt;a href="http://wiki.finalbuilder.com/display/continua/Unit+Tests#UnitTests-ShelvingTests" title="Shelving/Unshelving Tests"&gt;shelving&lt;/a&gt;&amp;#160;the tests tells Continua CI to ignore those failures in the future, until you unshelve them. &amp;#160;&lt;/p&gt;
&lt;p&gt;One last feature which I touched on, is the use of Stage Gates to fails the build. Continua CI collects a bunch of metrics during the build, and we can use those metrics in Stage Gate Conditions to fail the build if for example, there are any failing tests. Each Stage has it's own Gate Conditions, which are evaluated once the stage completes.. When the build fails at the Stage Gate, you will see the output of the condition expressions (note, the expressions below are the defaults on all stages) :&lt;/p&gt;
&lt;p&gt;&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/vincent/DUnitX-CI/DUnitX-FailingSummary.png" alt="Failed at Stage Gate"&gt;
&lt;/p&gt;
&lt;p&gt;&amp;#160;&lt;/p&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:integrating-dunitx-unit-testing-with-continua-ci.html</guid></item><item><title>IntelliJ IDEA and WebStorm: InfoWorld’s 2015 Technology of the Year Award Winners</title><link>http://ciandcd.github.io/intellij-idea-and-webstorm-infoworlds-2015-technology-of-the-year-award-winners.html</link><description>From:&lt;a href="http://blog.jetbrains.com/blog/2015/01/30/intellij-idea-and-webstorm-infoworlds-2015-technology-of-the-year-award-winners/"&gt;http://blog.jetbrains.com/blog/2015/01/30/intellij-idea-and-webstorm-infoworlds-2015-technology-of-the-year-award-winners/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p id="fb-root"&gt;&lt;/p&gt;&amp;#13;
 &amp;#13;
&lt;p&gt;&amp;#13;
&lt;/p&gt;&lt;p class="g-plusone"&gt;&lt;/p&gt;
 
&lt;p&gt;&lt;/p&gt;
 
&lt;p class="fb-like"&gt;&lt;/p&gt;&amp;#13;
&amp;#13;
&lt;br clear="all"&gt;&lt;p&gt;On January 26th, 2015, &lt;strong&gt;&lt;a title="InfoWorld Announces the 2015 Technology of the Year Award Recipients" href="http://www.idgenterprise.com/press/infoworld-announces-the-2015-technology-of-the-year-award-recipients" target="_blank"&gt;InfoWorld announced their 2015 Technology of the Year award recipients&lt;/a&gt;&lt;/strong&gt;. In total there were 32 winners representing the best of cloud, data, hardware and software applications.&lt;/p&gt;
&lt;p&gt;For the &lt;strong&gt;second year in a row WebStorm is a winner&lt;/strong&gt; and &lt;strong&gt;IntelliJ IDEA returns to the list in 2015&lt;/strong&gt;!&lt;/p&gt;
&lt;p&gt;&lt;img class="wp-image-6917 aligncenter" alt="InfoWorld 2015 Technology of the Year Award" src="http://blog.jetbrains.com/wp-content/uploads/2015/01/InfoWorld_TOY_Logo_2015.png" width="383" height="287"&gt;&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;WebStorm&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;The WebStorm review by Martin Heller, InfoWorld Test Center Editor, highlights the core features that makes WebStorm &amp;#8220;more than an editor&amp;#8221; such as: built-in code inspections and code quality tools, Node.js and JavaScript debugger and tracer, Live edit, and integration with the testing tools.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;IntelliJ IDEA&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Just last month IntelliJ IDEA 14 picked up the&amp;#160;&lt;strong&gt;&lt;a title="Jolt Awards 2015: Coding Tools" href="http://www.drdobbs.com/joltawards/jolt-awards-2015-coding-tools/240169420?pgno=6" target="_blank"&gt;2015 Jolt Productivity Award for Coding Tools&lt;/a&gt;&lt;/strong&gt; and now InfoWorld&amp;#8217;s 2015 Technology of the Year. What a great ending to 2014 and start to the new year!&lt;/p&gt;
&lt;p&gt;Here is part of what Rick Grehan had to say in his review.&lt;/p&gt;
&lt;p&gt;&amp;#8220;Granted, we wish the Community edition were equipped with the sorts of J2EE development tools found only in the Ultimate edition: database tools, support for frameworks such as JPA and Hibernate, deployment tools for application servers like JBoss AS, WildFly, and Tomcat. Nevertheless, the Community edition makes a fine Java application development platform that also gives you Android tools, as well as support for other JVM languages like Groovy, Clojure, and Scala (the last two via free plug-ins). Whichever version of IntelliJ IDEA you use, you&amp;#8217;ll find a rich array of tools designed to simplify otherwise tedious development chores.&amp;#8221;&lt;/p&gt;
&lt;p&gt;Read more about WebStorm (slide 15), IntelliJ IDEA (slide 16) and the other winners in &lt;strong&gt;&lt;a title="InfoWorld&amp;#x27;s 2015 Technology of the Year Award winners" href="http://www.infoworld.com/article/2871935/application-development/infoworlds-2015-technology-of-the-year-award-winners.html" target="_blank"&gt;InfoWorld&amp;#8217;s 2015 Technology of the Year Award slide show&lt;/a&gt;&lt;/strong&gt;.&amp;#160;&lt;strong&gt;&lt;a title="InfoWorld&amp;#x27;s 2015 Technology of the Year Award winners" href="http://www.infoworld.com/article/2871935/application-development/infoworlds-2015-technology-of-the-year-award-winners.html" target="_blank"&gt;&lt;br&gt;
&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
											&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:intellij-idea-and-webstorm-infoworlds-2015-technology-of-the-year-award-winners.html</guid></item><item><title>Introducing VSoft.CommandLineParser for Delphi</title><link>http://ciandcd.github.io/introducing-vsoftcommandlineparser-for-delphi.html</link><description>From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/719/introducing-vsoftcommandline-for-delphi"&gt;https://www.finalbuilder.com/resources/blogs/postid/719/introducing-vsoftcommandline-for-delphi&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;h2&gt;Command line parsing&lt;/h2&gt;
&lt;p&gt;Pretty much every delphi console application I have ever written or worked on had command line options, and every one of the projects tried different ways for defining and parsing the supplied options.
Whilst working on DUnitX recently, I needed to add some command line options, and wanted to find a nice way to add them and make it easy to add more in the future. The result is &lt;a href="https://github.com/VSoftTechnologies/VSoft.CommandLineParser" target="_blank"&gt;VSoft.CommandLineParser&lt;/a&gt;
(copies of which are included with the latest DUnitX).&lt;/p&gt;
&lt;h3&gt;Defining Options&lt;/h3&gt;
&lt;p&gt;One of the things I really wanted, was to have the parsing totally decoupled from definition and the storage of the options values. Options are defined by registering them with the TOptionsRegistry, via
TOptionsRegistry.RegisterOption&amp;lt;T&amp;gt; - whilst it makes use of generics, only certain types can be used, the types are checked at runtime, as generic constraints are not flexible enough to specify
which types we allow at compile time. Valid types are string, integer, boolean, enums &amp;amp; sets and floating point numbers. &lt;/p&gt;
&lt;p&gt;Calling RegisterOption will return a definition object which implements IOptionDefinition. This definition object allows you to set various settings (such as Required).
When registering the option, you specify the long option name, the short option name, help text (will be used when showing the usage) and a TProc&amp;lt;T&amp;gt; anonymous method that will take the parsed value as a parameter.&lt;/p&gt;
&lt;pre class="brush:delphi; toolbar:true;"&gt;procedure ConfigureOptions;
var
  option : IOptionDefintion;
begin
  option := TOptionsRegistry.RegisterOption&amp;lt;string&amp;gt;('inputfile','i','The file to be processed',
    procedure(value : string)
    begin
        TSampleOptions.InputFile := value;
    end);
  option.Required := true;

  option := TOptionsRegistry.RegisterOption&amp;lt;string&amp;gt;('outputfile','o','The processed output file',
    procedure(value : string)
    begin
        TSampleOptions.OutputFile := value;
    end);
  option.Required := true;

  option := TOptionsRegistry.RegisterOption&amp;lt;boolean&amp;gt;('mangle','m','Mangle the file!',
    procedure(value : boolean)
    begin
        TSampleOptions.MangleFile := value;
    end);
  option.HasValue := False;

  option := TOptionsRegistry.RegisterOption&amp;lt;boolean&amp;gt;('options','','Options file',nil);
  option.IsOptionFile := true;
end;
&lt;/pre&gt;
&lt;p&gt;For options that are boolean in nature, ie they have do not value part, the value passed to the anonymous method will be true if the option was specified, otherwise the anonymous method will not be called. The 'mangle' option in the above example shows this scenario. &lt;/p&gt;
&lt;p&gt;You can also specify that an option is a File, by setting the IsOptionFile property on the option definition. This tells the parser the value will be a file, which contains other options to be parsed (in the same format as the command line). This is useful for working around windows command line length limitations.&lt;/p&gt;
&lt;p&gt;Currently the parser will accept&lt;br&gt;
-option:value&lt;br&gt;
--option:value&lt;br&gt;
/option:value
&lt;/p&gt;
&lt;p&gt;Note the : delimiter between the option and the value.&lt;/p&gt;
&lt;p&gt;Unnamed parameters are registered via the TOptionsRegistry.RegisterUnNamedOption&amp;lt;T&amp;gt; method. Unlike named options, unnamed options are positional, but only when more than one is registered, as they will
be passed to the anonymous methods in the order they are registered.&lt;/p&gt;
&lt;h3&gt;Parsing the options.&lt;/h3&gt;
&lt;p&gt;Parsing the options is as simple as calling TOptionsRegistry.Parse, which returns a ICommandLineParseResult object. Check the HasErrors property to see if the options were valid, the ErrorText property has the parser error messages.&lt;/p&gt;
&lt;h3&gt;Printing Usage&lt;/h3&gt;
&lt;p&gt;If the parser reports errors, then typically you would show the user what the valid options are and exit the application, e.g:&lt;/p&gt;
&lt;pre class="brush:delphi; toolbar:true;"&gt;    parseresult := TOptionsRegistry.Parse;
    if parseresult.HasErrors then
    begin
      Writeln(parseresult.ErrorText);
      Writeln('Usage :');
      TOptionsRegistry.PrintUsage(
        procedure(value : string)
        begin
          Writeln(value);
        end);
    end
    else
        ..start normal execution here
&lt;/pre&gt;
&lt;p&gt;The TOptionsRegistry.PrintUsage makes it easy to print the usage to the command line.&lt;/p&gt;
&lt;p&gt;When I started working on this library, I found some really complex libraries (mostly .net) out there with a lot of options, but I decided to keep mine as simple as possible and only cover off the scenarios I need right now. So it's entirely possible this doesn't do everything people might need, but it's pretty easy to extend. The &lt;a href="https://github.com/VSoftTechnologies/VSoft.CommandLineParser" target="_blank"&gt;VSoft.CommandLineParser&lt;/a&gt; library (just three units) is open source and available on Github, with a sample application and unit tests (DUnitX) included.&lt;/p&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:introducing-vsoftcommandlineparser-for-delphi.html</guid></item><item><title>Issue with uploading compressed artifacts in Go 14.3.0</title><link>http://ciandcd.github.io/issue-with-uploading-compressed-artifacts-in-go-1430.html</link><description>From:&lt;a href="http://www.go.cd/2014/11/14/Go_14_3_issue_with_uploading_compressed_artifacts.html"&gt;http://www.go.cd/2014/11/14/Go_14_3_issue_with_uploading_compressed_artifacts.html&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;There was an &lt;a href="https://github.com/gocd/gocd/issues/703"&gt;issue&lt;/a&gt; reported with respect to artifact uploads in the 14.3.0 release of Go. &lt;/p&gt;

&lt;h3&gt;Issue&lt;/h3&gt;

&lt;p&gt;On Go server running with OpenJDK7, uploading compressed artifacts fails. The operation is reported as success in console-log on job details page but actual artifact does not get uploaded. Please note this does not affect uploading console-log itself or even a simple file as an artifact. This is an issue only with Go v14.3.0. Read further to know if you are affected by this defect.&lt;/p&gt;

&lt;h3&gt;Who does this affect?&lt;/h3&gt;

&lt;p&gt;This defect would affect you only if your Go Server v14.3.0 is run using OpenJDK(jdk or jre) and the agent responsible for artifact upload is using a version of java other than the one used by Go server. &lt;/p&gt;

&lt;p&gt;You are unaffected by this defect if:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;you use Sun/Oracle java to run Go Server&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;you have SunEC extension installed for your OpenJDK [EDIT: on your Go server]&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Both your server and agent processes run using OpenJDK (not necessarily the same version) [EDIT: without &lt;a href="http://en.wikipedia.org/wiki/Elliptic_curve_cryptography"&gt;ECC cipher suites&lt;/a&gt;.
As explained in "What caused this?" section, this issue occurs when java on agent supports ECC cipher suites but java on server doesnot. You should definitely run the litmus test to be sure.]&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;Litmus test&lt;/h4&gt;

&lt;p&gt;You should run a pipeline which uploads a compressed file as an artifact to ensure you are not affected by this defect. If the artifact shows up on the artifacts tab of the job and can be successfully downloaded, you are safe from the defect.&lt;/p&gt;

&lt;h3&gt;Workaround&lt;/h3&gt;

&lt;p&gt;We are aware that you have been waiting to try your hands on the new APIs and several bug fixes that came out in 14.3.0. 
Fortunately we have a few workarounds available to help you move ahead with the upgrade, meanwhile we would be working on finding the best possible fix for this issue. 
You could go for one of the workarounds listed below:&lt;/p&gt;

&lt;p&gt;Options:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Install SunEC extension on your OpenJDK setup. Get sunec.jar and place it under &lt;code&gt;jre/lib/ext/&lt;/code&gt; folder. You must also place libsunec.so in &lt;code&gt;jre/lib/amd64/&lt;/code&gt; folder. &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;OR&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Install Oracle JRE on your Go server and switch to that. 
For Go server running on Windows, this means updating the system level environment variable &lt;code&gt;GO_SERVER_JAVA_HOME&lt;/code&gt; to oracle jre home
For Linux based installations, update &lt;code&gt;/etc/default/go-server&lt;/code&gt; to set &lt;code&gt;JAVA_HOME&lt;/code&gt; to oracle jre home.
For Others, set the value of system level environment variable &lt;code&gt;JAVA_HOME&lt;/code&gt; to oracle jre home.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;OR&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Install the same version of java as you have on your agent. Update java used by Go server to appropriate value as suggested in the previous option.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;At this point restart Go Server. Trigger your affected pipeline to ensure the artifact got uploaded successfully. This should resolve the issue.
If the issue persists even after applying the suggested workaround, do write to the go-cd mailing list reporting the same.&lt;/p&gt;

&lt;h3&gt;What caused this?&lt;/h3&gt;

&lt;p&gt;I cannot speak about this without getting into some technical details. &lt;/p&gt;

&lt;p&gt;As a part of upgrading to Rails v4, we also had to upgrade bouncycastle-bcprov library. Earlier versions of Go used bouncycastle-bcprov v1.40. With that the cipher suites accepted by Go server would always be one of &lt;code&gt;SSL_RSA_WITH_RC4_128_SHA&lt;/code&gt;, &lt;code&gt;SSL_RSA_EXPORT_WITH_RC4_40_MD5&lt;/code&gt; or &lt;code&gt;SSL_RSA_WITH_RC4_128_MD5&lt;/code&gt;.
Go 14.3.0 has moved on to use org.bouncycastle-bcprov v1.47. Bouncycastle v1.46 brought in support for &lt;a href="http://tools.ietf.org/html/rfc4492"&gt;ECC cipher suites&lt;/a&gt;. ECC cipher suites are made available by SunEC extension which is not packaged along with OpenJDK7 by default. 
Go server is run using Jetty which uses bouncycastle crypto package (i.e. bcprov) for the handshake. At this point, instead of agreeing on the expected SSL &amp;amp; RSA based ciphers, one of the ECC ciphers get picked during the agent/server handshake. Jetty6 (yes, we are still using this!) does not work well with the modern cipher suites and causes issues like the one mentioned above. To tackle such scenarios, all supported ciphers suites apart from the three mentioned above are excluded from Jetty. Since, ECC cipher suites were not available on the server, they did not get excluded. However if your JVM has ECC ciphers available (by default or after applying one of the workarounds), Go would ensure they get excluded and make Jetty happy. &lt;/p&gt;

&lt;p&gt;Jetty upgrade has been on the cards for a while, and that would possibly help resolve this. But that is a much involved task and hence works better as a long term solution. We need to evaluate other options as well which could fix the issue in the short term. &lt;/p&gt;

&lt;p&gt;Many thanks to &lt;a href="https://github.com/bormotov"&gt;Vladimir Bormotov&lt;/a&gt; for reporting this issue and allowing us to use his setup to gather the required debug information.&lt;/p&gt;

&lt;p&gt;As always, you could write to &lt;a href="https://groups.google.com/forum/#!forum/go-cd"&gt;go-cd&lt;/a&gt; and &lt;a href="https://groups.google.com/forum/#!forum/go-cd-dev"&gt;go-cd-dev&lt;/a&gt; mailing lists if you have any ideas/feedback/questions.&lt;/p&gt;

&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:issue-with-uploading-compressed-artifacts-in-go-1430.html</guid></item><item><title>Jazz Team Blog Announcing Rational Publishing Engine 2.0 GA</title><link>http://ciandcd.github.io/jazz-team-blog-announcing-rational-publishing-engine-20-ga.html</link><description>From:&lt;a href="https://jazz.net/blog/index.php/2015/06/17/announcing-rational-publishing-engine-2-0-ga/"&gt;https://jazz.net/blog/index.php/2015/06/17/announcing-rational-publishing-engine-2-0-ga/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;The Rational Publishing Engine 2.0 is now available as a GA download. This major release includes a simplified web interface that will help clients focus on generating documents with minimal steps and also apply effective template reuse within their organization.&lt;/p&gt;
&lt;p&gt;To learn more about the capabilities of this release, read the &amp;#8220;&lt;a href="www-01.ibm.com/support/knowledgecenter/SS6RHZ_2.0.0/com.ibm.rational.pe.overview.doc/topics/c_whats_new_20.html?lang=en-us"&gt;What&amp;#8217;s new&lt;/a&gt;&amp;#8221; section in our &lt;a href="http://www-01.ibm.com/support/knowledgecenter/SS6RHZ_2.0.0/com.ibm.rational.pe.nav.doc/helpindex_rpe.html"&gt;Infocenter documentation for RPE 2.0&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You can try the document generation capabilities by accessing our cloud sandbox on &lt;a href="https://rpe.mybluemix.net/rpeng/home"&gt;https://rpe.mybluemix.net/rpeng/home&lt;/a&gt;. &amp;#160;Login with your id and click on &amp;#8220;Create Examples&amp;#8221; for a quick start on using the new web interface.&lt;/p&gt;
&lt;p&gt;We look forward to your feedback on the design and usability of the system. If there are any use cases in your organization that is not addressed with the current system, please write to us at &lt;strong&gt;rpe20_beta_support@wwpdl.vnet.ibm.com&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In this release, we have adopted IBM Design Thinking methodology for the first time. We have received valuable inputs from our clients and our stakeholders through the design partner program. I would like to thank all our clients who participated in the design partner and in the Beta program. We look forward to your inputs on the GA version of Rational Publishing Engine 2.0.&lt;/p&gt;
&lt;span&gt;&lt;img src="https://jazz.net/blog/wp-content/plugins/wp-spamfree/img/wpsf-img.php" width="0" height="0" alt=""&gt;&lt;/span&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:jazz-team-blog-announcing-rational-publishing-engine-20-ga.html</guid></item><item><title>Jazz Team Blog Big changes coming to jazz.net</title><link>http://ciandcd.github.io/jazz-team-blog-big-changes-coming-to-jazznet.html</link><description>From:&lt;a href="https://jazz.net/blog/index.php/2015/04/22/big-changes-coming-to-jazz-net/"&gt;https://jazz.net/blog/index.php/2015/04/22/big-changes-coming-to-jazz-net/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;You may have noticed some changes when you came to visit Jazz.net today. After 8 years, the jazz.net team thought it was time to give the site a more thorough overhaul then it has had in the past. Keeping Agile and Lean principles in mind, we&amp;#8217;re starting small and looking to get early feedback on the changes we make.&lt;/p&gt;
&lt;p&gt;To start, we are rolling out a new look for our &lt;a href="https://jazz.net/"&gt;Home&lt;/a&gt; page, a &lt;a href="https://jazz.net/products"&gt;combined Product and Download&lt;/a&gt; landing page, as well as a new navigation bar and footer. For the new look and feel, we want to incorporate current IBM Design principles. This will help us to be more consistent with other IBM sites, and pare down some of the content that has made the pages get more crowded over the years. We also want to have our site be more mobile-friendly, to reflect the growing portion of our audience accessing our site from mobile devices.&lt;/p&gt;
&lt;p&gt;Over the coming months, we&amp;#8217;ll start rolling out updates to the rest of the site. In addition to updating the look for all the pages on the site, we&amp;#8217;ll be reviewing the content in the &lt;a href="https://jazz.net/library/"&gt;jazz.net Library&lt;/a&gt; and on the &lt;a href="https://jazz.net/wiki/bin/view/Deployment/"&gt;Deployment Wiki&lt;/a&gt; to make sure the content is up to date. We also want to make sure we have our development team engaged with the community, so look for more content about our Jazz based products over the coming months as well.&lt;/p&gt;
&lt;p&gt;As I mentioned above, we want to incorporate Agile and Lean principles in this rollout, and this is where you come in. We&amp;#8217;re looking for your feedback on the changes we&amp;#8217;re making. Hopefully you like it, and let us know if you do!&lt;/p&gt;
&lt;p&gt;If there are things we should do differently, or you have other thoughts about the overhaul, we want to hear that as well. The sooner we get the feedback, the better job we can do of incorporating it and making this site as useful to you as possible. So drop a comment on this blog, tell us on &lt;a href="https://www.facebook.com/jazzdotnet"&gt;Facebook&lt;/a&gt; or Twitter (&lt;a href="https://twitter.com/JazzDotNet"&gt;@JazzDotNet&lt;/a&gt;), or post in the &lt;a href="https://jazz.net/forum"&gt;forums&lt;/a&gt; using the tag &amp;#8220;jazz-dot-net-overhaul&amp;#8221;! We look forward to hearing from you!&lt;/p&gt;
&lt;span&gt;&lt;img src="https://jazz.net/blog/wp-content/plugins/wp-spamfree/img/wpsf-img.php" width="0" height="0" alt=""&gt;&lt;/span&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:jazz-team-blog-big-changes-coming-to-jazznet.html</guid></item><item><title>Jazz Team Blog Bluemix Devops Services is hiring!</title><link>http://ciandcd.github.io/jazz-team-blog-bluemix-devops-services-is-hiring.html</link><description>From:&lt;a href="https://jazz.net/blog/index.php/2015/04/08/bluemix-devops-services-is-hiring/"&gt;https://jazz.net/blog/index.php/2015/04/08/bluemix-devops-services-is-hiring/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;We&amp;#8217;re hiring! IBM is serious about the Cloud. It&amp;#8217;s where business is headed and you should be there too.&lt;/p&gt;
&lt;p&gt;Developing and deploying web and mobile applications in a continuous delivery environment is complex and challenging.&amp;#160;&lt;a title="IBM Bluemix cloud" href="https://console.ng.bluemix.net/?cm_mmc=developerWorks-_-dWdevcenter-_-devops-services-_-lp" target="_blank"&gt;IBM Bluemix cloud&lt;/a&gt; technology is based on open standards such as Cloud Foundry and Docker, with industrial strength software-defined infrastructure provided by IBM SoftLayer.&amp;#160;&lt;a title="Bluemix DevOps Services" href="https://hub.jazz.net/" target="_blank"&gt;Bluemix DevOps Services&lt;/a&gt; combines a core devops tool chain and integrations with popular tools like GitHub, into a single highly productive environment built on a modern micro-services architecture.&lt;/p&gt;
&lt;p&gt;Work here to develop the future and change the computing landscape. If you have the drive, IBM has the grit and the clout to make it happen.&lt;/p&gt;
&lt;p&gt;Contact us at&amp;#160;&lt;a title="idsorg@us.ibm.com" href="mailto:idsorg@us.ibm.com"&gt;idsorg@us.ibm.com&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Dave Thomson&lt;br&gt;
Director and Distinguished Engineer, IBM Bluemix DevOps Services&lt;/p&gt;
&lt;span&gt;&lt;img src="https://jazz.net/blog/wp-content/plugins/wp-spamfree/img/wpsf-img.php" width="0" height="0" alt=""&gt;&lt;/span&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:jazz-team-blog-bluemix-devops-services-is-hiring.html</guid></item><item><title>Jazz Team Blog Collaborative Lifecycle Management 6.0 in a nutshell</title><link>http://ciandcd.github.io/jazz-team-blog-collaborative-lifecycle-management-60-in-a-nutshell.html</link><description>From:&lt;a href="https://jazz.net/blog/index.php/2015/06/26/collaborative-lifecycle-mangagement-6-0-in-a-nutshell/"&gt;https://jazz.net/blog/index.php/2015/06/26/collaborative-lifecycle-mangagement-6-0-in-a-nutshell/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;&lt;a rel="attachment wp-att-13334" href="https://jazz.net/blog/index.php/2015/06/26/collaborative-lifecycle-mangagement-6-0-in-a-nutshell/clm-splash-ga2/"&gt;&lt;img class="aligncenter size-full wp-image-13334" title="clm-splash-ga2" src="https://jazz.net/blog/wp-content/uploads/2015/06/clm-splash-ga2.png" alt="CLM 6.0 is here!" width="580" height="300"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Since &lt;a href="http://www-01.ibm.com/common/ssi/cgi-bin/ssialias?subtype=ca&amp;amp;infotype=an&amp;amp;appname=iSource&amp;amp;supplier=897&amp;amp;letternum=ENUS215-208" target="_blank"&gt;our announcement&lt;/a&gt; on June 9th, we&amp;#8217;ve spent the last couple of weeks here on Jazz.net sharing with all of you more information about the new features and their value. We&amp;#8217;re planning on spending some more time in the next couple of weeks continuing that sharing. But today is an exciting day for all of us on the Collaborative Lifecycle Management (CLM) team&amp;#8212;&lt;a href="https://jazz.net/downloads/clm/releases/6.0" target="_blank"&gt;Version 6.0 is generally available!&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is a culmination of a lengthy development cycle for us. If you were following along here on Jazz.net, we developed new capabilities over the course of 11 sprints. Much of that, which you&amp;#8217;ll see as you look through the content in v6.0, was required for the effort&amp;#8212;from the Jazz Foundation on up&amp;#8212;to provide configuration management across the integrated solution. But what you don&amp;#8217;t see, or what maybe isn&amp;#8217;t immediately apparent, is all the work occurring behind the scenes.&lt;/p&gt;
&lt;p&gt;So, to highlight just a few of the changes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;During v6.0, we shifted to      building twice per day&amp;#8212;10 times per week. This allowed us to slow the      amount of feature change occurring in just daily builds to ensure a more      stable experience.&lt;/li&gt;
&lt;li&gt;We expanded our      development pipeline to 14 different tests, and those tests run against      every build. If you look back as far as five years ago, we had no      automated development pipeline. So from zero automated pipeline testing to      running 140 pipeline tests (14 tests for 10 builds every week) in five      years.&lt;/li&gt;
&lt;li&gt;We built a federated      environment in which to test configuration management. This distributed      environment was built to mimic some of our more complex customer shops and      allow us a much greater depth of testing for v6.0 than we&amp;#8217;ve had in the      past.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Feature development included Configuration Management as well as a number of DevOps enhancements.&lt;/p&gt;
&lt;p&gt;You&amp;#8217;ll see a lot of Configuration Management content on Jazz.net related to CLM v6.0. Rather than try to give it a full summary here, I&amp;#8217;ll point you to some key information:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We&amp;#8217;ve put Configuration      Management behind an activation key. The intent here was to ensure you are      walking through &lt;a href="https://jazz.net/servlet/clm-cm/request-key" target="_blank"&gt;all the considerations related to CM&lt;/a&gt; before you turn it on.&lt;/li&gt;
&lt;li&gt;If you&amp;#8217;re worried that CM      is really just for clients who are building complex hardware devices, it&amp;#8217;s      not. You can use &lt;a href="https://jazz.net/blog/index.php/2015/06/15/configuration-management-%E2%80%93-it%E2%80%99s-not-just-for-building-airplanes-or-cars/" target="_blank"&gt;CM in simple scenarios&lt;/a&gt; as well.&lt;/li&gt;
&lt;li&gt;And finally, of course,      once you&amp;#8217;ve considered it and understand how you might use it, visit &lt;a href="http://www-01.ibm.com/support/knowledgecenter/SSYMRC_6.0.0/com.ibm.jazz.vvc.doc/topics/c_cm_assess.html?lang=en" target="_blank"&gt;Getting      Started with Configuration Management&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But CM wasn&amp;#8217;t the only set of feature work in CLM v6.0. &lt;a href="https://jazz.net/blog/index.php/2015/06/24/introducing-safe%c2%ae-with-the-power-of-ibm-devops/" target="_blank"&gt;SAFe 3.0 brings a new template to Rational Team Concert&lt;/a&gt; (RTC) and extends a project to the business teams involved in development. You can get out of the box and up and running with the SAFe template, improving agility and predictability with role-based dashboards. Continued scalability improvements to Enterprise Edition, integration with UrbanCode Deploy, Single Sign-On (SSO) for Kerberos and OIDC for all RTC clients are numbered among other enhancements. Finally, our Reporting team improved setup and configuration, simplified the customer experience, integrated reports into QuickPlanner, and have given you &amp;#8220;near live&amp;#8221; operational reporting.&lt;/p&gt;
&lt;p&gt;I urge you to stop by our &lt;a href="https://jazz.net/wiki/bin/view/Deployment/WebHome" target="_blank"&gt;Deployment wiki&lt;/a&gt;, one of our most popular destinations.&lt;/p&gt;
&lt;p&gt;All in all, it&amp;#8217;s been a very active release for both Development and Operations, and one we&amp;#8217;re very proud of.&lt;/p&gt;
&lt;span&gt;&lt;img src="https://jazz.net/blog/wp-content/plugins/wp-spamfree/img/wpsf-img.php" width="0" height="0" alt=""&gt;&lt;/span&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:jazz-team-blog-collaborative-lifecycle-management-60-in-a-nutshell.html</guid></item><item><title>Jazz Team Blog Configuration management – it’s not just for building airplanes or cars</title><link>http://ciandcd.github.io/jazz-team-blog-configuration-management-its-not-just-for-building-airplanes-or-cars.html</link><description>From:&lt;a href="https://jazz.net/blog/index.php/2015/06/15/configuration-management-%e2%80%93-it%e2%80%99s-not-just-for-building-airplanes-or-cars/"&gt;https://jazz.net/blog/index.php/2015/06/15/configuration-management-%e2%80%93-it%e2%80%99s-not-just-for-building-airplanes-or-cars/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Can you imagine a software team working without a configuration management system? Could your team do any collaboration without versions, streams and baselines?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Do you ever need to reverse a change that introduced a defect? If so, then you need to keep track of versions with a history of who changed what, when, and why.&lt;/li&gt;
&lt;li&gt;Do you want some of your engineers to be able to work on the next release while the current release is in final stabilization and testing? If so, then you need multiple streams of development.&lt;/li&gt;
&lt;li&gt;Do you ever want to produce a report on the changes in a new release? If so, then you need to compare the versions in a previous baseline to the new baseline, or to the current state of the development stream.&lt;/li&gt;
&lt;li&gt;Do you ever need to create a patch to a previous release? If so, you would need a baseline of that previous release, and a way to branch a new stream from it.&lt;/li&gt;
&lt;li&gt;Do you ever need to try an experiment, or make a one-off change? If so, you need to create a new stream, make some changes there, and then possibly merge the contents of that experimental stream into the main line of development.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Software Configuration Management provides these and other benefits, such as improved collaboration and reuse.&lt;/p&gt;
&lt;p&gt;Wouldn&amp;#8217;t you want these same capabilities and benefits in your other tools, including requirements management, modeling, and quality testing? DOORS Next Generation 6.0 and Rational Quality Manager 6.0 provide these features, just as Rational Rhapsody Design Manager has done since release 4.0.&lt;/p&gt;
&lt;p&gt;And now that you have configuration management in each tool, think about all these configuration management concepts but in the broader sense &amp;#8211; the ability to do it across the lifecycle &amp;#8211; for the overall combination of your requirements, designs, test plans, and more. Global Configurations, introduced in Collaborative Lifecycle Management 6.0, provides the ability to do just that &amp;#8211; to keep track of versions, streams, and baselines of your entire system.&lt;/p&gt;
&lt;p&gt;Whether you are building airplanes, cars, financial systems, web sites, health care systems, or entertainment systems, configuration management is a key part of your path to success.&lt;/p&gt;
&lt;p&gt;Nick Crossley&lt;/p&gt;
&lt;span&gt;&lt;img src="https://jazz.net/blog/wp-content/plugins/wp-spamfree/img/wpsf-img.php" width="0" height="0" alt=""&gt;&lt;/span&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:jazz-team-blog-configuration-management-its-not-just-for-building-airplanes-or-cars.html</guid></item><item><title>Jazz Team Blog IBM Rational Publishing Engine 2.0 M5 Beta – Improved document styling</title><link>http://ciandcd.github.io/jazz-team-blog-ibm-rational-publishing-engine-20-m5-beta-improved-document-styling.html</link><description>From:&lt;a href="https://jazz.net/blog/index.php/2015/03/25/ibm-rational-publishing-engine-2-0-m5-beta-improved-document-styling/"&gt;https://jazz.net/blog/index.php/2015/03/25/ibm-rational-publishing-engine-2-0-m5-beta-improved-document-styling/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;We&amp;#8217;re glad to announce that the Rational Publishing Engine (RPE) 2.0 Beta on Bluemix has been &lt;a href="https://rpe.mybluemix.net/rpeng" target="_blank"&gt;updated to the M5 build&lt;/a&gt;!&amp;#160;There is no registration or special process required in order to access the beta. Aside from announcing this update, the intention of this post is to provide a little extra help to those looking for guidance on getting started using using the RPE 2.0 M5 Beta via some helpful resources. We&amp;#8217;ll also touch on what&amp;#8217;s new in this build of the beta.&lt;/p&gt;
&lt;h2&gt;Goal of the beta&lt;/h2&gt;
&lt;p&gt;This is meant to give RPE users an opportunity to provide feedback on the  features and usability of our new web interface. The focus is on the  report designer and end user scenarios.&lt;/p&gt;
&lt;p&gt;What we&amp;#8217;d like to learn is:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Is the design simple enough for our end users?&lt;/li&gt;
&lt;li&gt;Do you see all the capabilities that your report designers need?&lt;/li&gt;
&lt;li&gt;Is the overall interface intuitive enough?&lt;/li&gt;
&lt;li&gt;What is missing from this new component of RPE to make it attractive for your organization?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We welcome all your feedback, so please send your thoughts to &lt;a href="mailto:rpe20_beta_support@wwpdl.vnet.ibm.com"&gt;rpe20_beta_support@wwpdl.vnet.ibm.com&lt;/a&gt;!&lt;/p&gt;
&lt;h2&gt;Resources&lt;/h2&gt;
&lt;p&gt;Help Guide:&amp;#160;&lt;a href="https://jazz.net/blog/wp-content/uploads/2015/03/IBM-Rational-Publishing-Engine-2-M5-Help.pdf"&gt;IBM Rational Publishing Engine 2 M5 Help&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Video Tutorials:&lt;/p&gt;
 
&lt;h2&gt;What&amp;#8217;s new in this build&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: Due to the new features implemented in M5, we had to recreate the database which means that assets and documents created using the previous build have been lost.&lt;/p&gt;
&lt;h2&gt;(i) &amp;#160;&amp;#160; Notifications&lt;/h2&gt;
&lt;p&gt;The notifications widget at the top of the screen is now active and will show all new events that occurred since you last checked its contents. The only event supported for now is the completion (successful or not) of a document generation.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://jazz.net/blog/wp-content/uploads/2015/03/Notifications.png"&gt;&lt;img class="alignnone size-full wp-image-12936" title="Notifications" src="https://jazz.net/blog/wp-content/uploads/2015/03/Notifications.png" alt="" width="460" height="68"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;(ii) &amp;#160;&amp;#160; Stylesheet support&lt;/h2&gt;
&lt;p&gt;You can now upload stylesheets and use them in your reports.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://jazz.net/blog/wp-content/uploads/2015/03/Styleseheet.png"&gt;&lt;img class="alignnone size-full wp-image-12937" title="Styleseheet" src="https://jazz.net/blog/wp-content/uploads/2015/03/Styleseheet.png" alt="" width="440" height="273"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;(iii)&amp;#160;&amp;#160; Advanced Configuration Mode for reports&lt;/h2&gt;
&lt;p&gt;Report designers now have access to an advanced edit mode where the report configuration can be tailored in detail. It is now possible to:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Set the default connection      for the report data sources&lt;/li&gt;
&lt;li&gt;Set the default values for      the report variables&lt;/li&gt;
&lt;li&gt;Rename variables and data      sources to be more meaningful to the end user&lt;/li&gt;
&lt;li&gt;Hide variables and data      sources from the end user&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a href="https://jazz.net/blog/wp-content/uploads/2015/03/Configuration.png"&gt;&lt;img class="alignnone size-full wp-image-12938" title="Configuration" src="https://jazz.net/blog/wp-content/uploads/2015/03/Configuration.png" alt="" width="697" height="631"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In the image above, the report designer modifies the &amp;#8220;News Glimpse&amp;#8221; report by setting its data source connection to the BBC News Feed and at the same time hiding the data source. This will effectively set the report to this configuration and end users can run it without further configuration.&lt;/p&gt;
&lt;h2&gt;(iv) &amp;#160;&amp;#160; Other changes&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;The action list has been      pruned with many of the redundant actions removed or redistributed.&lt;/li&gt;
&lt;li&gt;The default action in the Design      page has been changed to &amp;#8220;Edit&amp;#8221;.&lt;/li&gt;
&lt;li&gt;The user can view all      documents generated for a report from the Generate page by clicking &amp;#8220;View      Generated documents&amp;#8221; in the Actions menu.&lt;/li&gt;
&lt;li&gt;Users can create examples      multiple times.&amp;#160; The assets created      in each run of &amp;#8220;Create Examples&amp;#8221; are independent of one another.&lt;/li&gt;
&lt;li&gt;Internet Explorer 10 and      11 are now supported.&lt;/li&gt;
&lt;li&gt;Error messages should be      more informative now.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Bug Fixes&lt;/h2&gt;
&lt;p&gt;The following limitations of the previous build have been addressed:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;On the Generate page, if      you select the Generate Later action, the scheduled run of the report is      created but you cannot download the documents or the logs&lt;/li&gt;
&lt;li&gt;If there is an error while      scheduling a report using the Generate Later action, check if the date is      in the past.&lt;/li&gt;
&lt;li&gt;IE is supported&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Known Issues&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;If after signing on you      are redirected to an empty page by the IBM Single Sign-On you need to      issue the original request in the browser, https://rpe.mybluemix.net/rpeng&lt;/li&gt;
&lt;/ol&gt;
&lt;span&gt;&lt;img src="https://jazz.net/blog/wp-content/plugins/wp-spamfree/img/wpsf-img.php" width="0" height="0" alt=""&gt;&lt;/span&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:jazz-team-blog-ibm-rational-publishing-engine-20-m5-beta-improved-document-styling.html</guid></item><item><title>Jazz Team Blog Introducing SAFe® with the Power of IBM DevOps</title><link>http://ciandcd.github.io/jazz-team-blog-introducing-safer-with-the-power-of-ibm-devops.html</link><description>From:&lt;a href="https://jazz.net/blog/index.php/2015/06/24/introducing-safe%c2%ae-with-the-power-of-ibm-devops/"&gt;https://jazz.net/blog/index.php/2015/06/24/introducing-safe%c2%ae-with-the-power-of-ibm-devops/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Do you need to orchestrate software development and delivery in your complex, heterogeneous environment but you&amp;#8217;re not sure where to start? Have you heard about SAFe but you don&amp;#8217;t know what it is or why you should care?&lt;/p&gt;
&lt;p&gt;New in Rational Team Concert V6.0 is a feature that supports the &lt;a href="http://scaledagileframework.com/" target="_blank"&gt;Scaled Agile Framework&lt;/a&gt;&amp;#174; (SAFe) out of the box. This feature enables you to explore the framework and establish a SAFe Program of your own, complete with the infrastructure, artifacts, best practices, and guidance prescribed by SAFe built right into the tooling.&lt;/p&gt;
&lt;p&gt;SAFe is the market-leading process framework for scaling lean and agile across the enterprise, providing guidance and best practices to help organizations realize success. &lt;strong&gt;SAFe with the Power of IBM DevOps&lt;/strong&gt; is the combination of SAFe plus IBM DevOps to provide a comprehensive process and tooling framework that helps your organization balance the efficiencies gained through adoption of lean principles with the effectiveness realized through agile adoption to &lt;strong&gt;deliver the right things right&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The result is a framework which synchronizes&amp;#160;development, testing and deployment across teams in heterogeneous environments, and enables collaboration of all roles in the organization in the planning and execution of software delivery.&lt;/p&gt;
&lt;h2&gt;Get Up and Running Quickly&lt;/h2&gt;
&lt;p&gt;The SAFe support in Rational Team Concert V6.0 provides an easy way for you to get up and running quickly to lead a SAFe-based transformation. Whether you are a SAFe novice who is just starting to explore, or an expert who is quite familiar with what it means to &amp;#8220;do SAFe&amp;#8221;, our support combines the flexibility and scale you need to support true enterprise teams using multiple processes, technologies, and tooling.&amp;#160; Let&amp;#8217;s take a look at a few details.&lt;/p&gt;
&lt;h3&gt;Project Area Initialization&lt;/h3&gt;
&lt;p&gt;Rational Team Concert 6.0 includes a new &lt;strong&gt;SAFe 3.0 Program &lt;/strong&gt;&lt;strong&gt;process template&lt;/strong&gt; that helps you to easily establish a SAFe Program-level tooling infrastructure. When you use the template to create a Rational Team Concert project area, you will get out-of-the-box support for Programs and Teams wanting to incorporate agile and lean practices into the development and delivery of software with SAFe best practices and guidance. This includes an Agile Release Train timeline, SAFe roles and permissions, and a SAFe Program/Team hierarchy with associated work item categories.&lt;/p&gt;
&lt;p&gt;While the project area is configured to support SAFe Programs with Teams in the same Rational Team Concert project area, it can easily be used to support Programs that are tracking the work of existing Teams in separate project areas as well. Furthermore, it can be used to establish project areas for SAFe Teams separate from the Program because the process template includes updated Scrum elements that are aligned with SAFe. Simple editing of the project area configuration provides you with the flexibility you need to support multiple different Program and Team topologies.&lt;/p&gt;
&lt;h3&gt;SAFe Artifacts&lt;/h3&gt;
&lt;p&gt;SAFe artifacts are manifested in Rational Team Concert through work item types, plan types, and plan views. These artifacts support the most critical SAFe best practices, including relative ranking based on Weighted Shortest Job First (WSJF), Kanban planning, and Program value-based delivery.&lt;/p&gt;
&lt;h4&gt;Work Item Types&lt;/h4&gt;
&lt;p&gt;The process template includes Program Epic and Feature work item types for the SAFe Program level, Story and Task work item types for the SAFe Team level, and PI Objectives for both Program and Team levels. Additional work item types for Defect, Risk, and Retrospective are also included.&lt;/p&gt;
&lt;p&gt;Program Epics and Features include the WSJF attribute to help ease adoption of lean thinking by providing an economic means of decision-making. This enables the prioritization of work that maximizes business benefit. The WSJF attribute is calculated using this formula:&lt;/p&gt;
&lt;p&gt;The WSJF component attributes (User/Business Value, Time Criticality, RR/OE, and Job Size) are provided as Fibonacci enumerations, which can be tailored to suit your organization&amp;#8217;s preferences. For the Epic, we also provide a Value Statement template to remind you of how best to articulate Program Epics.&lt;/p&gt;
&lt;p&gt;The PI Objective is a way to track value delivery, which is a critical aspect of Enterprise Scaled Agile and IBM DevOps principles. By capturing the notion of planned and actual value delivery, we can provide you with insights into your organization&amp;#8217;s ability to deliver value to your business and to customers.&lt;/p&gt;
&lt;h4&gt;Plan Views&lt;/h4&gt;
&lt;p&gt;Plan Views provided by the process template enable high-value SAFe processes. The SAFe Kanban System for Program Epics is a visual representation of rank and status.&lt;/p&gt;
&lt;p&gt;The ability to capture and enforce Work in Progress (WIP) limits enables your team to practice the lean principle of &amp;#8220;just enough&amp;#8221; investment, reminding you again to take an economic view in decision-making.&lt;/p&gt;
&lt;p&gt;The WSJF Ranked List view takes this concept a step further by helping your team learn how to quickly and relatively rank Features based on WSJF.&lt;/p&gt;
&lt;p&gt;Remember, it is not about high value alone, but the &amp;#8220;biggest bang for the buck&amp;#8221;. This plan view helps your team learn how to consistently rank Features to maximize benefit&amp;#8212;to your customers as well as to your business.&lt;/p&gt;
&lt;h4&gt;Dashboards, Queries, Reports&lt;/h4&gt;
&lt;p&gt;No tooling infrastructure provides value unless it can turn your planning and tracking data into actionable analysis, so the process template helps you get started by providing Program and Team dashboards, along with queries and reports that are consistent with the SAFe Program and Team metrics. Here are some examples:&lt;/p&gt;
&lt;p&gt;We also augment the SAFe guidance with our own, applying the knowledge of our experience working with enterprise customers to create incisive reports that you can use to drive decision-making. In particular, we provide insight into cross-team dependencies to help you address a critical pain point in managing software development and delivery across the Program.&lt;/p&gt;
&lt;h2&gt;Learn by Doing&lt;/h2&gt;
&lt;p&gt;So, the &amp;#8220;process&amp;#8221; and &amp;#8220;tooling&amp;#8221; to help your Program adopt lean and agile principles is provided&amp;#8212;but what about the &amp;#8220;people&amp;#8221; aspect? The cultural transformation is perhaps the hardest part of an agile transformation initiative, no doubt about it. To help you with this, we incorporate process mentoring with the SAFe support in Rational Team Concert by providing you with work item templates that remind you of the typical tasks related to specific SAFe events and activities. The process template includes Work Item Templates for:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Program      Initiation Activities&lt;/strong&gt;. Creates      tasks that guide you on the activities required to initiate your SAFe      Program&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Program      Increment. &lt;/strong&gt;Creates tasks that guide your team to lead a Program Increment, from the Release      Planning Event through delivery&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Development      Iteration. &lt;/strong&gt;Creates tasks      to help teams plan development iterations through delivery of      functionality&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Innovation      and Planning. &lt;/strong&gt;Creates tasks for the      Innovation and Planning sprints&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All of the work item tasks describe activities consistent with those prescribed by SAFe and include in-context mentoring via a direct link to the topic described by the task on the &lt;a href="http://www.scaledagileframework.com/" target="_blank"&gt;SAFe website&lt;/a&gt;. This enables you to learn as you go and helps to ease adoption of SAFe, step by step.&lt;/p&gt;
&lt;h2&gt;Plan SAFely&lt;/h2&gt;
&lt;p&gt;While no tool alone can plan for you or make your teams collaborate, IBM&amp;#8217;s SAFe solution can greatly simplify the transformation through tooling integrated with process guidance, coupled with the right data to help with your decision-making. I hope you like what you see. We would appreciate any and all feedback as we enhance our SAFe support going forward. As always, visit the &lt;a href="https://jazz.net/products/clm/whats-happening/" target="_blank"&gt;Collaborative Lifecycle Management&lt;/a&gt; and &lt;a href="https://jazz.net/products/rational-team-concert/whats-happening/" target="_blank"&gt;Rational Team Concert&lt;/a&gt; &lt;strong&gt;What&amp;#8217;s Happening&lt;/strong&gt; sections for the latest news. And to keep abreast of everything related to our SAFe support now and in the future, please visit our &lt;a href="https://bit.ly/ibmsafesupport" target="_blank"&gt;SAFe landing page&lt;/a&gt; on the IBM DevOps Community and check back often for updates!&lt;/p&gt;
&lt;p&gt;Thank you!&lt;/p&gt;
&lt;span&gt;&lt;img src="https://jazz.net/blog/wp-content/plugins/wp-spamfree/img/wpsf-img.php" width="0" height="0" alt=""&gt;&lt;/span&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:jazz-team-blog-introducing-safer-with-the-power-of-ibm-devops.html</guid></item><item><title>Jazz Team Blog New single sign-on options in CLM 6.0</title><link>http://ciandcd.github.io/jazz-team-blog-new-single-sign-on-options-in-clm-60.html</link><description>From:&lt;a href="https://jazz.net/blog/index.php/2015/06/19/new-single-sign-on-options-in-clm-6-0/"&gt;https://jazz.net/blog/index.php/2015/06/19/new-single-sign-on-options-in-clm-6-0/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Collaborative Lifecycle Management (CLM) has directly supported two types of single sign-on (SSO) authentication for some time. First, all applications installed in the same application server (whether IBM WebSphere Application Server or Tomcat) automatically share login sessions, such that if you log in to one application, you are also logged into all the other applications deployed in the same server. Second, when all applications are deployed in one or more WebSphere Application Servers, you can configure&amp;#160;&lt;a title="Lightweight Third Party Authentication" href="http://www-01.ibm.com/support/knowledgecenter/api/content/nl/en-us/SSYMRC_6.0.0/com.ibm.jazz.install.doc/topics/c_jazz_single_sign_on.html#c_jazz_single_sign_on__was-ltpa-auth-sec" target="_blank"&gt;Lightweight Third Party Authentication (LTPA) SSO&lt;/a&gt; so that login sessions are shared across all the WebSphere servers.&lt;/p&gt;
&lt;p&gt;We are excited to announce that we have added &lt;a title="Jazz single sign-on options" href="http://www-01.ibm.com/support/knowledgecenter/SSYMRC_6.0.0/com.ibm.jazz.install.doc/topics/c_jazz_single_sign_on.html" target="_blank"&gt;two new SSO options&lt;/a&gt; in the CLM 6.0 release. You&amp;#8217;ll now have the option to use either &lt;a title="Kerberos" href="http://en.wikipedia.org/wiki/Kerberos_%28protocol%29" target="_blank"&gt;Kerberos&lt;/a&gt; authentication, or what we call &amp;#8220;Jazz Security Architecture Single Sign-On&amp;#8221;, which is based on the &lt;a title="OpenID Connect" href="http://openid.net/connect/" target="_blank"&gt;OpenID Connect&lt;/a&gt; standards.&lt;/p&gt;
&lt;p&gt;Kerberos is a well-established SSO protocol that is also the default authentication protocol used by Microsoft Windows, so if your organization uses Windows workstations, Microsoft Active Directory for user management, and deploy Jazz applications in WebSphere 8 or later, it will be possible to configure CLM so that your Windows login session is automatically used to log in to CLM. Kerberos can also be used with non-Windows workstations, as long as you use a Microsoft Active Directory server to manage your user accounts. While it has been possible to configure CLM servers to use Kerberos for some time, only web browser clients could take advantage of Kerberos login sessions &amp;#8211; the RTC Eclipse client, the Microsoft Visual Studio RTC client, the other Windows .NET clients, the RTC build engine and clients, and the various command-line clients could not use Kerberos. Now, all those RTC clients will work with Kerberos. See &amp;#160;&lt;a title="Single sign-on authentication in CLM" href="http://www-01.ibm.com/support/knowledgecenter/SSYMRC_6.0.0/com.ibm.jazz.install.doc/topics/c_jazz_single_sign_on.html" target="_blank"&gt;Single sign-on authentication in CLM&lt;/a&gt; for the complete list of RTC clients that support Kerberos, and &lt;a title="Configuring Kerberos" href="http://www-01.ibm.com/support/knowledgecenter/SSYMRC_6.0.0/com.ibm.jazz.install.doc/topics/c_kerSso_config.html" target="_blank"&gt;Configuring Kerberos&lt;/a&gt; for details on setting up Kerberos for CLM.&lt;/p&gt;
&lt;p&gt;The OpenID Connect (OIDC) authentication protocol was established in early 2014 as an extension of the&amp;#160;&lt;a title="OAuth 2.0" href="http://oauth.net/2/" target="_blank"&gt;OAuth 2.0&lt;/a&gt; protocol, designed to be easier to adopt across a wide range of clients (native applications, browsers, browser-based applications, and mobile devices). It is extensible and configurable (with optional features). Jazz Security Architecture (JSA) is a particular profile of OIDC, specifying which optional features are included, and a few extensions. Authentication is handled by the Jazz Authorization Server (JAS); Jazz applications delegate to that server instead of relying on the application server to handle authentication. Single sign-on is supported across all applications that are configured to use the same JAS, independent of what sort of application servers they are deployed in, and what platform they are running on. To use Jazz Security Architecture SSO, you must &lt;a title="Installing the Rational solution for Collaborative Lifecycle Management by using IBM Installation Manager" href="http://www-01.ibm.com/support/knowledgecenter/SSYMRC_6.0.0/com.ibm.jazz.install.doc/topics/t_s_server_installation_im.html" target="_blank"&gt;install the Jazz Authorization Server&lt;/a&gt;, &lt;a title="Deploying and starting Jazz Authorization Server" href="http://www-01.ibm.com/support/knowledgecenter/SSYMRC_6.0.0/com.ibm.jazz.install.doc/topics/c_jsasso_jas_deploy_start.html" target="_blank"&gt;configure it and start it up&lt;/a&gt;, and either enable JSA SSO in CLM applications when installing (for a new installation), or &lt;a title="Enabling Jazz Security Architecture single sign-on after upgrading" href="http://www-01.ibm.com/support/knowledgecenter/SSYMRC_6.0.0/com.ibm.jazz.install.doc/topics/c_JsaSso_enable_after_upgrade.html" target="_blank"&gt;enable JSA SSO after upgrading to the 6.0 release&lt;/a&gt; (for existing installations).&lt;/p&gt;
&lt;p&gt;The login form for the JAS looks very similar to the Jazz application login form, but you&amp;#8217;ll know that you&amp;#8217;re using the JAS for authentication if the login form says &amp;#8220;AUTHORIZATION SERVER&amp;#8221; instead of &amp;#8220;TEAM SERVER&amp;#8221;:&lt;/p&gt;
&lt;p&gt;You can find more information on how authentication works in general, and the various options available, in the &lt;a title="Jazz Server Authentication Explained" href="https://jazz.net/library/article/75" target="_blank"&gt;Jazz Server Authentication Explained&lt;/a&gt; article. We&amp;#8217;re hoping these new SSO options provide increased flexibility and ease-of-use for our users.&lt;/p&gt;
&lt;p&gt;John Vasta&lt;br&gt;
Senior Software Engineer&lt;/p&gt;
&lt;span&gt;&lt;img src="https://jazz.net/blog/wp-content/plugins/wp-spamfree/img/wpsf-img.php" width="0" height="0" alt=""&gt;&lt;/span&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:jazz-team-blog-new-single-sign-on-options-in-clm-60.html</guid></item><item><title>Jazz Team Blog Raising your game with configuration management in and across your tools</title><link>http://ciandcd.github.io/jazz-team-blog-raising-your-game-with-configuration-management-in-and-across-your-tools.html</link><description>From:&lt;a href="https://jazz.net/blog/index.php/2015/06/09/raising-your-game-with-configuration-management-in-and-across-your-tools/"&gt;https://jazz.net/blog/index.php/2015/06/09/raising-your-game-with-configuration-management-in-and-across-your-tools/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;High-performing teams are never satisfied with their performance. They regularly ask, &amp;#8220;How can we do better?&amp;#8221;&amp;#160; They have a certain restlessness. A sense of mission, stewardship, and empathy for the people who will use the things they design and build.&lt;/p&gt;
&lt;p&gt;It&amp;#8217;s our mission to provide tools and make possible development practices that help your high-performing teams improve their game.&amp;#160; To that end, Collaborative Lifecycle Management (CLM) 6.0 brings significant new capabilities for configuration management within and across your Jazz tools &amp;#8212; with the potential for tools from other vendors to participate in these innovations.&lt;/p&gt;
&lt;p&gt;In our days you&amp;#8217;d be hard pressed to find a software development team that would undertake serious work without using a SCM system.&amp;#160; In CLM 6.0, we are extending configuration management capabilities (including development streams, baselines, branching, merging, change sets, comparing across streams) to other tools, so practitioners in other disciplines can gain the same kinds of efficiencies. We are solving this in an open, federated way through (1) new implementations of configuration management in Rational DOORS Next Generation and Rational Quality Manager; and (2) support for Global Configurations as defined in in the OASIS &lt;a href="https://wiki.oasis-open.org/oslc-ccm/" target="_blank"&gt;OSLC Configuration Management&lt;/a&gt; specification.&lt;/p&gt;
&lt;p&gt;We expect these capabilities will help teams be more effective in using baselines, doing parallel development, working in large programs of projects, and doing product line engineering.&amp;#160; Look for baby steps you can take. Walk now; run later.&lt;/p&gt;
&lt;p&gt;To learn more, check out the &lt;a href="https://www.ibm.com/developerworks/community/blogs/35dfcb99-111b-423a-aaa4-50f3fddae141?lang=en" target="_blank"&gt;Continuous Engineering blog&lt;/a&gt; on developerWorks, or see the short videos on &lt;a href="https://www.ibm.com/developerworks/library/?sort_by=&amp;amp;show_abstract=true&amp;amp;show_all=&amp;amp;search_flag=&amp;amp;contentarea_by=All+Zones&amp;amp;search_by=&amp;amp;product_by=All++Products&amp;amp;topic_by=Configuration+management&amp;amp;industry_by=All++Industries&amp;amp;type_by=Video+and+audio&amp;amp;ibm-search=Search" target="_blank"&gt;developerWorks&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Daniel Moul&lt;br&gt;
Senior Product Manager&lt;/p&gt;
&lt;p&gt;P.S. Many thanks to those of you who downloaded beta milestones and provided feedback, or sat down with us to share your insights about what your engineers need to raise their game.&amp;#160; We know you are on a journey; we are too. It&amp;#8217;s a privilege to run together.&lt;/p&gt;
&lt;span&gt;&lt;img src="https://jazz.net/blog/wp-content/plugins/wp-spamfree/img/wpsf-img.php" width="0" height="0" alt=""&gt;&lt;/span&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:jazz-team-blog-raising-your-game-with-configuration-management-in-and-across-your-tools.html</guid></item><item><title>Jazz Team Blog Success with System Verification Test (SVT) Automation</title><link>http://ciandcd.github.io/jazz-team-blog-success-with-system-verification-test-svt-automation.html</link><description>From:&lt;a href="https://jazz.net/blog/index.php/2015/06/05/success-with-system-verification-test-svt-automation/"&gt;https://jazz.net/blog/index.php/2015/06/05/success-with-system-verification-test-svt-automation/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Back when the System Verification Test (SVT) team started thinking about Collaborative Lifecycle Management (CLM) 6.0, they put some automation goals in place.&amp;#160; Having identified a key bottleneck of long periods of time being spent on setting up the configurations for scenario testing, the first goal was to build automated scripts to speed up the configurations in order for the manual testers to start testing faster and reduce the test cycle time.&amp;#160; The second automation goal was aimed more conventionally at uncovering defects in code changes and increasing automated test coverage.&amp;#160; This was focused on adding automation to cover PLE scenarios and also to enhancing scenarios to include new features like configuration management.&lt;/p&gt;
&lt;p&gt;Prior to 2014, System Test focus was on deploying configurations in an automated way. &amp;#160;At the beginning of 2014, System Test had one and a half automation engineers who were automating the out of the box customer experience, the Money that Matters scenario.&amp;#160; While that goal of ensuring that scenario was mostly automated was achieved by end of year, the process was painful and slow. In light of the DevOps transformation, at the and of 2014, SVT decided to invest more in automation.&amp;#160; They added three more engineers to work on this. That wasn&amp;#8217;t an easy decision, but a necessary one, and it meant taking on a risk as less manual test coverage was provided as a result of this move.&lt;/p&gt;
&lt;p&gt;2015 has been a great year and the five engineers working on automation have already commissioned seven automated scenarios this year.&amp;#160; These have been focused on data generation, to help manual testers and shorten the test cycle in addition to the automated configurations. There is good communication with development teams.&amp;#160; An automation team is mostly useless if you don&amp;#8217;t get the right amount of support from development when you&amp;#160;raise concerns or defects if they don&amp;#8217;t follow up quickly. &amp;#160;The close relationships with development allows the System Team to cover the cutting edge use cases and quickly respond to defects found.&amp;#160; Now, turn around time is typically within a day.&lt;/p&gt;
&lt;p&gt;The teams have come from a time where there was little support for automated testing to today with a fully automated set of tests.&amp;#160; They didn&amp;#8217;t have a BVT, or rather it was manual.&amp;#160; Each team would blindly take the build and hope it installed.&amp;#160; They moved to automation where the build&amp;#160;is created, gets picked up, automation runs jUnits, then it gets deployed to our golden topologies, using different app servers, different tests, and they are all designed according to how customers use the products.&amp;#160; The team is also using our tools, &lt;a href="https://jazz.net/products/rational-quality-manager/"&gt;Rational Quality Manager (RQM)&lt;/a&gt; for test execution and reporting, and &lt;a href="https://jazz.net/products/rational-team-concert/"&gt;Rational Team Concert (RTC)&lt;/a&gt; for test development.&amp;#160; They have gone from no automation to now where a large number of automated tests are executed daily against both maintenance and new release streams.&lt;/p&gt;
&lt;p&gt;This has been worth the investment, but it has not been easy.&amp;#160; For one thing, there have been some plan changes along the way.&amp;#160; Trying to keep up with developing the new automation while product plans are changing makes it difficult to make sure that the teams are covering the right user experience.&amp;#160; Also, there are new members to the automation team who need to be trained not only on the development of the automation, but also the framework for the automated tests.&lt;/p&gt;
&lt;p&gt;There is a process in place to get the automation engineers up to speed quickly, but probably the most important part is working together as a team and starting simple before moving to the more complex areas, like the framework.&amp;#160; There is a review process with the team so that everyone learns from one another and if there is a problem the reviewer will identify the area in need of improvement and also make a suggestion about how to solve the issue.&lt;/p&gt;
&lt;p&gt;Given that there is a good mix of manual testers and now test automation developers, it&amp;#8217;s important to work together for the least risk and the most coverage.&amp;#160; This has paid off for the team, so that the team is building automation to help the manual testers find defects quickly, build automation to find regressions in existing code and to find defects in new features.&amp;#160; There has been a significant number of defects found prior to GA so far, and the majority of them have been critical and higher severity.&amp;#160; Just knowing that they won&amp;#8217;t be released is a huge confidence builder for the teams.&lt;/p&gt;
&lt;p&gt;The System Test team will continue to invest in automation, making use of the automation community that has been built up out of these efforts.&amp;#160; The community is geographically distributed, under different leadership and has great collaboration with development.&amp;#160; The openness and transparency allows for the development teams to execute newly created automated tests against their code changes prior to delivery.&amp;#160; The increased confidence in quality has been and continues to be worth the investment.&lt;/p&gt;
&lt;p&gt;Beth Zukowsky&lt;br&gt;
Program Director and Rational DevOps Protagonist&lt;/p&gt;
&lt;span&gt;&lt;img src="https://jazz.net/blog/wp-content/plugins/wp-spamfree/img/wpsf-img.php" width="0" height="0" alt=""&gt;&lt;/span&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:jazz-team-blog-success-with-system-verification-test-svt-automation.html</guid></item><item><title>Jazz Team Blog Transforming your product development for the IoT</title><link>http://ciandcd.github.io/jazz-team-blog-transforming-your-product-development-for-the-iot.html</link><description>From:&lt;a href="https://jazz.net/blog/index.php/2015/06/25/transforming-your-product-development-for-the-iot/"&gt;https://jazz.net/blog/index.php/2015/06/25/transforming-your-product-development-for-the-iot/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;h2&gt;Development Practices for the IoT Era&lt;/h2&gt;
&lt;p&gt;The Internet of Things (IoT) is not just about connecting things to the Internet and controlling them remotely. It is a major opportunity for developers of things (makers) and operators of things to unlock new value propositions from the lifecycle of things, and to improve innovation and the quality of things. In our context, things are products such as automobiles, medical devices, consumer goods, factory machines, etc. To leverage the value of connected and instrumented devices, there are several important aspects to consider, one of which is a proper digital product development process. Also, it is no longer a secret that in today&amp;#8217;s advanced products most of the innovation comes from the embedded software, so the effectiveness of the software development process is an important parameter of the overall product development process.&lt;/p&gt;
&lt;p&gt;Here are some key leverage points of connected products:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It is possible to continuously collect operational data from devices when in operation.&lt;/li&gt;
&lt;li&gt;It is possible to remotely update the software that is embedded in the products.&lt;/li&gt;
&lt;li&gt;With the addition of social media, product makers can also get continuous information on how products are used in different market segments.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;However, to leverage such enablers, product makers need to change their traditional development processes. The development processes need to be much more dynamic and agile to leverage the connectivity and advanced engagement of connected products. Here are some key transformational aspects for the development process:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Connected product complexity&lt;/strong&gt;&amp;#8212;Complexity is increasing with the additional functionalities provided by new interactions between products and product to cloud. Practices for handling this complexity rely on digital systems engineering processes that are based on digital representations of product requirements, product architecture, and product verification plans. Such digital systems engineering approaches enable continuous verification of product designs to eliminate risks early in the process as part of addressing this complexity. Continuous verification utilizes techniques such as simulation and rules-based checking to validate the requirements and the system architecture.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Transforming data into engineering insight&lt;/strong&gt;&amp;#8212;The amount of operational data available from connected systems is overwhelming and typically engineering information is locked in isolated silos.  Data coming from operations and manufacture may trace to product requirements, product design, and product test. Being able to properly analyze all those product engineering aspects requires complete digitalization, traceability, and analytics of all product development aspects.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Increasing speed of development&lt;/strong&gt;&amp;#8212;The connected world increases the need to respond much more quickly to market findings and demands. The ability to effectively respond to change in multidisciplinary products depends on an effective change management process, where impact analysis of the change is conducted in a completely digital manner based on query across lifecycle data. It also relies on the ability to create change contexts across the lifecycle, without interfering with the overall system state before the change is actually approved. Creating such change contexts is enabled by configurations across the lifecycle.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Specialization&lt;/strong&gt;&amp;#8212;With the advancement of social media around connected products there is going to be higher demand to create more specialized products to deal with competition and optimize product revenue.  That requires capabilities to properly manage reuse and variation as part of the product development process. Ineffective ways to manage variation limit the ability of product makers to effectively leverage product variation.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Streamlined process with continuous integration&lt;/strong&gt;&amp;#8212;IoT architectures require both proper support for embedded software that can be updated on devices, as well as software on cloud that analyzes and controls devices.&lt;/p&gt;
&lt;p&gt;In order to achieve this transformation of the engineering development process, customers should look to the &lt;a href="http://www.ibm.com/software/info/iot_ce_solution/" target="_blank"&gt;IBM Internet of Things Continuous Engineering Solution&lt;/a&gt;. The IBM Continuous Engineering (CE) platform, which is based on the &lt;a href="http://www.ibm.com/software/products/en/ratlclm" target="_blank"&gt;Rational solution for Collaborative Lifecycle Management&lt;/a&gt; (CLM), provides the infrastructure and capabilities to enable a digital engineering lifecycle, which is necessary to meet the challengse of rapid and effective multidisciplinary development.  Any activity and artifact as part of the process are digital and cross-linked&amp;#8212;whether those artifacts are requirements, product designs and architectures, test plans or change history. There is no need to rely on traditional documents in the process, which are typically the main blocker for digitalization of the lifecycle.  Open, standards-based lifecycle data indexing, query, reporting, and analysis are also key to effectively supporting the stream of incoming changes as part of the connected lifecycle. Recent updates to the CE platform now provide the new capability to define cross-lifecycle configurations, enabling parallel work on new innovations as well as effectively handling product variations by efficient reuse.&lt;/p&gt;
&lt;p&gt;To summarize, the new generation of connected products that makes the Internet of Things is a major opportunity for product makers if they properly adapt their product development practices to leverage the opportunities and meet the challenges.  As already identified by some key IoT-related initiatives, such as&amp;#160; &lt;a href="http://www.bmbf.de/en/19955.php" target="_blank"&gt;Industrie 4.0&lt;/a&gt; in Germany, and &lt;a href="http://www.iiconsortium.org/" target="_blank"&gt;Industrial Internet of Things&lt;/a&gt; (IIoT) initiatives in the United States, the required transformation is to shift product development to a digital platform.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;span&gt;&lt;img src="https://jazz.net/blog/wp-content/plugins/wp-spamfree/img/wpsf-img.php" width="0" height="0" alt=""&gt;&lt;/span&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:jazz-team-blog-transforming-your-product-development-for-the-iot.html</guid></item><item><title>Jazz Team Blog Try out the new configuration management features in CLM 6.0 RC1!</title><link>http://ciandcd.github.io/jazz-team-blog-try-out-the-new-configuration-management-features-in-clm-60-rc1.html</link><description>From:&lt;a href="https://jazz.net/blog/index.php/2015/05/14/try-out-the-new-configuration-management-features-in-clm-6-0-rc1/"&gt;https://jazz.net/blog/index.php/2015/05/14/try-out-the-new-configuration-management-features-in-clm-6-0-rc1/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;The recent release of Collaborative Lifecycle Management (CLM) 6.0 RC1 signals the release candidate (RC) phase of development, which means that the official CLM 6.0 release is in its final stages. The 6.0 release offers new and exciting configuration management capabilities. To learn more about these capabilities, read the &lt;a href="http://www-01.ibm.com/support/knowledgecenter/SSYMRC_6.0.0/com.ibm.jazz.vvc.doc/topics/c_cm_assess.html?lang=en"&gt;Getting started with configuration management&lt;/a&gt; help topic or watch the &lt;a href="https://www.youtube.com/watch?v=Yv4-G79OUDI&amp;amp;list=PLZGO0qYNSD4V6xyq6nmZgD8jg7Y9iDpGM&amp;amp;index=6"&gt;Introduction to configuration management&lt;/a&gt; video, which is part of a larger &lt;a href="https://www.youtube.com/playlist?list=PLZGO0qYNSD4V6xyq6nmZgD8jg7Y9iDpGM"&gt;video series&lt;/a&gt;. You can try the configuration management capabilities in an existing &lt;a href="https://jazz.net/products/sandbox/?tag=clm"&gt;cloud sandbox&lt;/a&gt;, or you can evaluate them in your own environment by downloading &lt;a href="https://jazz.net/downloads/clm/"&gt;CLM 6.0 RC1&lt;/a&gt;, reading the &lt;a href="https://jazz.net/servlet/clm-cm/request-key"&gt;considerations&lt;/a&gt;, and obtaining an activation key.&lt;/p&gt;
&lt;p&gt;&lt;img src="" alt="" width="644" height="289"&gt;&lt;/p&gt;
&lt;p&gt;Tim Feeney&lt;br&gt;
Executive IT Specialist&lt;/p&gt;
&lt;span&gt;&lt;img src="https://jazz.net/blog/wp-content/plugins/wp-spamfree/img/wpsf-img.php" width="0" height="0" alt=""&gt;&lt;/span&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:jazz-team-blog-try-out-the-new-configuration-management-features-in-clm-60-rc1.html</guid></item><item><title>Jazz Team Blog Unlocking engineering insight for an IoT world</title><link>http://ciandcd.github.io/jazz-team-blog-unlocking-engineering-insight-for-an-iot-world.html</link><description>From:&lt;a href="https://jazz.net/blog/index.php/2015/06/24/unlocking-engineering-insight-for-an-iot-world/"&gt;https://jazz.net/blog/index.php/2015/06/24/unlocking-engineering-insight-for-an-iot-world/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Gary Cernosek&lt;/p&gt;
&lt;p&gt;Sr. Product Manager&lt;/p&gt;
&lt;p&gt;IBM IoT Continuous Engineering&lt;/p&gt;
&lt;p&gt;I&amp;#8217;m writing this series of posts over the next few weeks to spur dialog on the topic of how organizations practicing in an IoT world need better ways to extract and derive value from the many sources that comprise their environment of engineering information. I plan to post this topic in four parts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Part 1: The State of engineering information&lt;/strong&gt;. I open this series of blog entries with the context of why customers care about gaining insight from their engineering data now more than ever.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Part 2: Aggregating engineering information from multiple sources&lt;/strong&gt;. I&amp;#8217;ll next address the problems indicated in Part 1 by discussing old and new ways for bringing multiple sources of information together and unifying the way engineers gain access to and work with such information.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Part 3: Integrating across disparate tools&lt;/strong&gt;. Here I&amp;#8217;ll address the need to gain access to engineering information from tools not originally designed to be integrated with the outside world.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Part 4: From information to insight&lt;/strong&gt;. Imagine a world where we connect everything that needs to be connected. Then what? Here I&amp;#8217;ll discuss the vision for IBM&amp;#8217;s Continuous Engineering solution as it provides the basis for analytics and turning raw tool data into true engineering insight.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Part 1: The State of engineering information &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Gary Cernosek&lt;/p&gt;
&lt;p&gt;Sr. Product Manager&lt;/p&gt;
&lt;p&gt;IBM IoT Continuous Engineering&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;I know it&amp;#8217;s here, somewhere&amp;#8230; &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Workers across engineering disciplines spend a lot of time (not) finding the information they need to do their jobs. Consider these statistics captured by KMWorld and The Ridge Group:1&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Knowledge      workers spend 15% to 35% of their time searching for information&lt;/li&gt;
&lt;li&gt;40%      of corporate users report they cannot find the information they need to do      their jobs&lt;/li&gt;
&lt;li&gt;50%      of Internet searches are abandoned&lt;/li&gt;
&lt;li&gt;90%      of the time that knowledge workers spend in creating new reports is recreating      information that already exists&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The problem is not creating good information, it&amp;#8217;s finding it! What&amp;#8217;s the root cause of these problems?&lt;/p&gt;
&lt;p&gt;Much of it has to do with how engineering environments tend to be highly fragmented across disparate tools. And the challenge to connect them is growing exponentially. Each engineering tool comes with its own user interface, and often multiple interfaces for use on the Web vs. desktop application. Behind the scenes, the tools offer various presentations of views and tasks, and often proprietary logic for workflow, process, search, query, scale, security, and collaboration. Storage methods vary from use of individual files on workstation or servers to databases with proprietary interfaces.&lt;/p&gt;
&lt;p&gt;This degree of variance makes it very difficult for organizations to ensure that engineering information is available to users and traceable across different tools&amp;#8212;even when the tools come from the same vendor! The results are brittle/poor integrations, silos everywhere, high cost to maintain and administer the tools, and little reuse.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What&amp;#8217;s so special about IoT?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Maybe your organization has handled these challenges fine up to now. But many are finding that IoT presents new or amplified issues that challenge their status quo. Two trends tend to stand out for organizations delivering products and systems connected to the Internet:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Market      pressure to increase product delivery frequency and compress cycle time&lt;/li&gt;
&lt;li&gt;Sheer      volume and complexity of software required in modern products and systems&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These trends are depicted in the graphics below and illustrate the need for organizations to be more &amp;#8216;agile&amp;#8217; and to build &amp;#8216;smarter&amp;#8217; products:&lt;a rel="attachment wp-att-13291" href="https://jazz.net/blog/index.php/2015/06/24/unlocking-engineering-insight-for-an-iot-world/image-for-uei-blog/"&gt;&lt;img class="aligncenter size-full wp-image-13291" title="Image for UEI blog" src="https://jazz.net/blog/wp-content/uploads/2015/06/Image-for-UEI-blog.jpg" alt="" width="783" height="306"&gt;&lt;/a&gt;Projects that used to take years are expected to deliver in months, and those previously completed in months now have make at least incremental progress in weeks, or even days. Environments that historically treated software as a &amp;#8216;part&amp;#8217; that was captured once per product release cycle and stored off in the product data management tool for simple compliance now require greater granularity of lifecycle assets and tighter coordination between software and hardware engineering processes. These factors are driving organizations to reevaluate the way they develop and deliver their products and systems.&lt;/p&gt;
&lt;h2&gt;Do you identify with these issues and trends?&lt;/h2&gt;
&lt;p&gt;If these issues and challenges resonate with your experience, comment in the blog. Let me and others know how it&amp;#8217;s affecting your day-to-day worklife and your organization&amp;#8217;s business results. And stay tuned for the next parts of my entries for &amp;#8220;Unlocking engineering insight for an IoT world.&amp;#8221;&lt;/p&gt;
&lt;h2&gt;1Sources:&lt;/h2&gt;
&lt;p&gt;KMWorld, &amp;#8220;The high cost of not finding information,&amp;#8221; &lt;a href="http://bit.ly/1AnNGZO"&gt;http://bit.ly/1AnNGZO&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Information Gathering in the Electronic Age: The Hidden Cost of the Hunt, The Ridge Group&lt;/p&gt;
&lt;span&gt;&lt;img src="https://jazz.net/blog/wp-content/plugins/wp-spamfree/img/wpsf-img.php" width="0" height="0" alt=""&gt;&lt;/span&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:jazz-team-blog-unlocking-engineering-insight-for-an-iot-world.html</guid></item><item><title>Jazz Team Blog Using dashboards for status reviews: An interview with CLM Product Delivery Lead Brian Lang</title><link>http://ciandcd.github.io/jazz-team-blog-using-dashboards-for-status-reviews-an-interview-with-clm-product-delivery-lead-brian-lang.html</link><description>From:&lt;a href="https://jazz.net/blog/index.php/2015/05/12/using-dashboards-for-status-reviews-an-interview-with-clm-product-delivery-lead-brian-lang/"&gt;https://jazz.net/blog/index.php/2015/05/12/using-dashboards-for-status-reviews-an-interview-with-clm-product-delivery-lead-brian-lang/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Having experience with different types of reporting and status updates, Brian Lang, the Collaborative Lifecycle Management (CLM) Product Delivery Leader, spent some time discussing with me some of the key productivity gains he&amp;#8217;s noticed in using Rational Team Concert (RTC).&amp;#160; The focus here is on the benefits of having a collaborative and transparent workflow, especially when it comes to meeting preparations.&amp;#160; Brian shares with us the benefits of using RTC Dashboards so that the data is available, current, and updated as part of the natural development workflow.&lt;/p&gt;
&lt;p&gt;Brian, what types of meetings have you needed to pull together presentations in the past and today?&lt;/p&gt;
&lt;p&gt;In the past, when I was using a chart-based status process, leading up to the Senior VP&amp;#8217;s Monthly Operations Review (MOR), there would be a review with my VP where we would review the status of everything in my portfolio.&amp;#160; This included key dates of delivery, status (red, yellow, green), and any additional key points that we wanted to raise to an executive level.&amp;#160; These topics might typically included key capabilities, beta feedback, or what kinds of achievements or accomplishments the team had this month. &amp;#160;Also, we prepared risks&amp;#160;and mitigations. &amp;#160;Each product would have their own chart.&lt;/p&gt;
&lt;p&gt;Additionally, we covered other things like burn down charts, user stories, velocity, story points, and month&amp;#160;to month trends.&amp;#160; We also covered various forms of technical debt in the form of APARs, defect backlogs which rounded out the reviews.&lt;/p&gt;
&lt;p&gt;Now, in CLM, while we still have MORs, the process is different even though the types of data are the same.&amp;#160; Rather than create a separate set of material, the materials are baked into our workflow with regular reviews with teams.&amp;#160; The same sorts of materials that would have been prepared and reviewed are part of the workflow including scrum meetings, release team meetings, and daily communications and work activities.&amp;#160; The schedule is laid out and published for the whole team.&amp;#160; Risks and mitigations are captured and updated in plan items.&amp;#160; If a plan item&amp;#8217;s risk changes from green to yellow or red, the viewlet in the dashboard will pull in that plan item, with the latest updates about actions.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What kinds of preparation do you do for these meetings?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;When pulling together charts, we would work our way backwards from the review with the Senior VP.&amp;#160; We ended up with four separate meetings to review material specific to the status update.&amp;#160; With the CLM dashboards, we can be ready for an update at any time.&amp;#160; It&amp;#8217;s transparent and anyone in the team can check on the overall status because transparency is built into the product and supports our process.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How long did it take to create the dashboards?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Viewlets are part of the RTC capabilities and some are out of the box. For example, risk and issues are available out of the box. &amp;#160;It doesn&amp;#8217;t take long to set up the queries against project areas. Depending on how many and the complexity, it typically takes less than an hour to get them put up.&amp;#160; Once they&amp;#8217;re there, they are automatically updated, so you don&amp;#8217;t have to repeat creating them.&amp;#160; One example is that we have a tab on our dashboard for risks and issues.&amp;#160; When we are tracking multiple releases, like we did with 5.0.2 and 6.0, we can separate them out, while keeping them on the same tab.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Going back to collecting the data for the charts, how many people are typically involved in gathering and consolidating that information?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;First, the offering team pulls together the information.&amp;#160; They usually have a release engineer, a project management, a development lead or chief programmer, an architect, a test lead, and a support lead, six people typically.&amp;#160; Sometimes there is the first line manager too so about six to seven people gathering and generating content to be reviewed. &amp;#160;The managers were the ones who presented the data to me, they are responsible for the content being presented.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How many teams did you have for a typical monthly status review?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;When I was doing chart-based reporting, I had about three key teams.&amp;#160; This meant that 18-21 people were preparing for the meeting with me.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How long does it take to pull that information together&amp;#160;for each&amp;#160;team?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;It takes a couple of hours for each person, approximately two to three hours to verify and answer are we green, yellow, or red?; how many test cases did we run?; what kinds of things are blocking us, etc. &amp;#160;That was spent running reports and following up with people for verification.&amp;#160; If things are not looking good, we may need more activity, up to maybe four hours.&amp;#160; That&amp;#8217;s about 24 hours per team.&amp;#160; Add on a 60-90 minute review in the offering team meeting making up another nine hours of people time (33 hours), plus another three hours for turnaround time on any follow ups. &amp;#160;We&amp;#8217;re looking at maybe 36 &amp;#8211; 40 person hours to generate that first set of data for review.&lt;/p&gt;
&lt;p&gt;Then there is the review with me.&amp;#160; The least number of people in the room are the three managers and maybe someone from their team&amp;#160;if there was a key technical issue to discuss, so five to six people for another 90 minutes making up another nine to ten hours. Then another set of questions, and we&amp;#8217;re up to 45-50 hours.&amp;#160; We have another review including me and another person or two, the support and development leads, for another hour.&amp;#160; After all of that, it adds up to about 60-65 person hours to get ready for the&amp;#160; Sr. VP MOR.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Talk a little more about how the preparation differs.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The preparation is baked into the process.&amp;#160; I update the executive status on the dashboard weekly as part of my preparation for the ALM release team weekly meeting.&amp;#160; That is where I update my overall take on the release. &amp;#160;If we&amp;#8217;re yellow, I share why I think we&amp;#8217;re yellow and what we&amp;#8217;re doing to mitigate the risk. &amp;#160;It takes about 15 minutes for me to update that and it&amp;#8217;s part of my workflow.&amp;#160; The release team meeting is where we talk about the release and where we need to focus.&amp;#160; It&amp;#8217;s less about status and more about what the team needs to work on accomplishing that week.&lt;/p&gt;
&lt;p&gt;The chart-based reporting teams were also working on&amp;#160;those things, but they needed to document it outside their natural process. &amp;#160;How they met and communicated was a key difference because these types of updates were not part of their daily or weekly workflow.&lt;/p&gt;
&lt;p&gt;It&amp;#8217;s hard to do an apples to apples comparison because they are such different ways of working. &amp;#160;In the CLM world, everyone can see when risks and issues are updated. &amp;#160;In the chart world, the risks and issues were only seen by about 10% of the team. &amp;#160;If only a subset of the team understands the risk, it&amp;#8217;s hard to go to a newly hired developer and ask about the work they were doing on risk &amp;#8220;X&amp;#8221; because they might not know what you&amp;#8217;re talking about, or know about it in the same context.&amp;#160; Also, the &amp;#8220;man hours&amp;#8221; involved may be similar with the dashboards because the whole team is involved in updating issues regularly, but it&amp;#8217;s a natural part of the workflow so it doesn&amp;#8217;t feel like anyone on the team is spending time gathering status.&lt;/p&gt;
&lt;p&gt;We use Jazz.net to build Jazz.net, using the dashboards to drive our work.&amp;#160; Once that work is done, we all can see our prioritized backlog to pull off the next thing to do more work.&amp;#160;The collaborative nature of the design makes transparency, priorities, and risk part of the process vs ppt where only a select number of people see it.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Most meetings result in follow up actions, how are actions from the meetings captured?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Actions in the chart world&amp;#160;would have been tracked in an email.&amp;#160; I&amp;#8217;d get an email saying that the VP met with Sr. vP and here are the two to three things to work on based on the review. &amp;#160;Then I&amp;#8217;d assign the work, and follow up. &amp;#160;If my VP doesn&amp;#8217;t remember, or loses the email, the actions fall through the cracks. &amp;#160;We&amp;#8217;d report on those actions through email and follows up in status meetings or 1&amp;#215;1s.&lt;/p&gt;
&lt;p&gt;In the RTC world, actions are captured as work items. &amp;#160;We review the actions to pursue which are tracked and prioritized with other work items in RTC. &amp;#160;So, if anyone has any questions, they can revert to the work item. &amp;#160;There is a live audit trail, when it was opened, who opened it, who owns, what has happened, etc.&amp;#160; It becomes part of the workflow.&lt;/p&gt;
&lt;p&gt;I can also add that in test we have major productivity gains from dashboards usage that are linked to test plans. They help to eliminate the manual chart compilation work and results are kept live and up to date, which is imperative as our releases and test cycles are getting shorter.&lt;/p&gt;
I&amp;#8217;d like to thank Brian for taking the time to discuss this topic. Using RTC for dashboards enables a natural development workflow supporting open communication and transparency while reducing overhead for the organization.&amp;#160; Understanding the priority of the work, the status of the work, and the risks of the work all help keep teams focused. By making it part of the natural development workflow it increases productivity.&amp;#160; I&amp;#8217;m not sure who to attribute this quote to: &amp;#8220;If it hurts, do it more often&amp;#8221; (&lt;a&gt;&lt;/a&gt;&lt;p&gt;I&amp;#8217;d like to thank Brian for taking the time to discuss this topic. Using RTC for dashboards enables a natural development workflow supporting open communication and transparency while reducing overhead for the organization. Understanding the priority of the work, the status of the work, and the risks of the work all help keep teams focused. By making it part of the natural development workflow it increases productivity. I&amp;#8217;m not sure who to attribute this quote to: &amp;#8220;If it hurts, do it more often&amp;#8221; ( &lt;a href="http://martinfowler.com/bliki/FrequencyReducesDifficulty.html"&gt;maybe&lt;/a&gt; ?). But, it definitely has reduced stress and overhead in this context!&lt;/p&gt;&lt;p&gt;Beth Zukowsky&lt;br&gt;
Program Director and Rational DevOps Protagonist&lt;/p&gt;
&lt;span&gt;&lt;img src="https://jazz.net/blog/wp-content/plugins/wp-spamfree/img/wpsf-img.php" width="0" height="0" alt=""&gt;&lt;/span&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:jazz-team-blog-using-dashboards-for-status-reviews-an-interview-with-clm-product-delivery-lead-brian-lang.html</guid></item><item><title>Jazz Team Blog What’s new in DOORS Next Generation 6.0?</title><link>http://ciandcd.github.io/jazz-team-blog-whats-new-in-doors-next-generation-60.html</link><description>From:&lt;a href="https://jazz.net/blog/index.php/2015/06/26/what%e2%80%99s-new-in-doors-next-generation-6-0/"&gt;https://jazz.net/blog/index.php/2015/06/26/what%e2%80%99s-new-in-doors-next-generation-6-0/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;This release could well be introducing the most fundamental function into a requirements management (RM) tool since RM systems began.&amp;#160; While we continue our drive with usability and productivity, we are also providing support for requirements configuration management (CM), built from the ground up as part of the native tool, rather than simply integrating an external CM system.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;  &lt;/p&gt;
&lt;h2&gt;Configuration Management&lt;/h2&gt;
&lt;p class="MsoNormal"&gt;&lt;a href="https://jazz.net/downloads/rational-doors-next-generation/releases/6.0" target="_blank"&gt;DOORS Next Generation 6.0&lt;/a&gt; is our first release providing native configuration management of requirements, enabling functionality for strategic reuse and Product Line Engineering. &lt;/p&gt;
&lt;p class="MsoNormal"&gt;RM offers the ability to define the scope of a project, program, or deliverable&amp;#8212;but unless you have control over change this scope could well consume more of your project costs than you expected. Placing requirements under CM allows for the scope to be controlled, while enabling your teams to work in parallel versions at the same time without the need to make project copies to handle variants. &lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;&lt;a rel="attachment wp-att-13270" href="https://jazz.net/blog/index.php/2015/06/26/what%e2%80%99s-new-in-doors-next-generation-6-0/cfgm/"&gt;&lt;img class="aligncenter size-full wp-image-13270" title="CfgM" src="https://jazz.net/blog/wp-content/uploads/2015/06/CfgM.png" alt="" width="524" height="179"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;  &lt;/p&gt;
&lt;p class="MsoNormal"&gt;On a basic level, CM provides a way to manage groups of artifacts and their versions. Versions can be split to support different variants and merged in order to deliver changes of requirements back to accepted releases. With CM, users can efficiently create different streams to help manage parallel versions without the need to make copies of their requirements. Additionally, there is robust linking that is specific to the stream the user is working in. This means that following the link shows users the requirement, test, or design element on the other end of the link that is appropriate for the stream they are working in. The ability to compare across streams and baselines helps users to understand how their versions or variants are different and to correct any mistakes.&lt;/p&gt;
&lt;p class="MsoNormal"&gt;The functionality has been designed expecting only a small number of people to engage directly with parallel versions and CM, while the rest of the engineers continue with their work, mostly as if nothing has changed. &lt;/p&gt;
&lt;p class="MsoNormal"&gt;By default, these new capabilities are turned off and project administrators have to enable them for the server and for each project area where users want to take advantage of them. &lt;/p&gt;
&lt;h2&gt;Global Configuration Management&lt;/h2&gt;
&lt;p class="MsoNormal"&gt;For some time we have been discussing the benefits of being able to support use cases such as &amp;#8220;link a version of a test case with a version of a requirement&amp;#8221;.&lt;/p&gt;
&lt;p&gt;&lt;a rel="attachment wp-att-13269" href="https://jazz.net/blog/index.php/2015/06/26/what%e2%80%99s-new-in-doors-next-generation-6-0/global-configurations/"&gt;&lt;img class="alignleft size-full wp-image-13269" title="Global Configurations" src="https://jazz.net/blog/wp-content/uploads/2015/06/Global-Configurations.jpg" alt="" width="366" height="215"&gt;&lt;/a&gt;6.0 extends CM with a federated approach to lifecycle information. Strategic reuse for complex systems and software is now possible for requirements (RDNG), design (RDM), test (RQM) and software development (RTC). &lt;/p&gt;
&lt;ul type="disc"&gt;
&lt;li class="MsoNormal"&gt;Plan and manage the reuse      of configurations in the many versions or variants of the product or      software line.&lt;/li&gt;
&lt;li class="MsoNormal"&gt;Define complex products      and applications as hierarchies of components and reuse those components      in multiple products and applications.&lt;/li&gt;
&lt;li class="MsoNormal"&gt;Automatically handle links      between artifacts when branching or delivering changes to another stream      such as, links between tests and requirements.&lt;/li&gt;
&lt;li class="MsoNormal"&gt;Create cross lifecycle      baselines to support parallel development of multiple versions and      variants, branching and merging, and change management.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Diagram editor&lt;/h2&gt;
&lt;p class="MsoNormal"&gt;Users can create many types of diagrams to refine and communicate their ideas and to elaborate their requirements.&lt;/p&gt;
&lt;p class="MsoNormal"&gt;&lt;a rel="attachment wp-att-13268" href="https://jazz.net/blog/index.php/2015/06/26/what%e2%80%99s-new-in-doors-next-generation-6-0/picture1-2/"&gt;&lt;img class="alignright size-full wp-image-13268" title="DNG informal diagram editor" src="https://jazz.net/blog/wp-content/uploads/2015/06/Picture11.jpg" alt="" width="376" height="288"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p class="MsoNormal"&gt;The new diagram editor provides high-quality diagrams that are simple to create in all supported browsers without the need for a Java&amp;#8482; plug-in. The large selection of shapes and themed styles make it easy to create many types of diagrams with eye-catching color palettes. To increase productivity, users can use the keyboard to create all the diagrams. They can comment on and create links between individual diagram elements and other artifacts. Diagrams can be added to modules and embedded in rich-text artifacts.&lt;/p&gt;
&lt;p class="MsoNormal"&gt;
&lt;/p&gt;&lt;p class="MsoNormal"&gt;See the &lt;a href="https://jazz.net/downloads/rational-doors-next-generation/releases/6.0?p=releaseNotes" target="_blank"&gt;Release Notes&lt;/a&gt; for further information!&lt;/p&gt;
&lt;p class="MsoNormal"&gt;  &lt;/p&gt;
&lt;p class="MsoNormal"&gt;This release could well be introducing the most fundamental function into a requirements management tool since RM systems began. While we continue our drive with usability and productivity we are also providing support for requirements configuration management, built from the ground up as part of the native tool, rather than simply integrating to an external CM system.&lt;/p&gt;
&lt;p&gt;  &lt;/p&gt;
&lt;span&gt;&lt;img src="https://jazz.net/blog/wp-content/plugins/wp-spamfree/img/wpsf-img.php" width="0" height="0" alt=""&gt;&lt;/span&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:jazz-team-blog-whats-new-in-doors-next-generation-60.html</guid></item><item><title>Jazz Team Blog What’s new in Rational Quality Manager 6.0?</title><link>http://ciandcd.github.io/jazz-team-blog-whats-new-in-rational-quality-manager-60.html</link><description>From:&lt;a href="https://jazz.net/blog/index.php/2015/06/26/whats-new-in-rational-quality-manager-6-0/"&gt;https://jazz.net/blog/index.php/2015/06/26/whats-new-in-rational-quality-manager-6-0/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;IBM &lt;a href="https://jazz.net/downloads/rational-quality-manager/releases/6.0" target="_blank"&gt;Rational Quality Manager&lt;/a&gt; (RQM) 6.0 brings both incremental improvements over v5 and a completely new dimension to managing test artifacts. On the incremental improvements front, the team has done a great job to continue to work closely with our customers to further improve the user experience on specific areas such as dashboard widgets or collaboration. At the same time, v6.0 introduces the support of configuration management for test artifacts, linked to other domains such as requirements or design, and contributing to the notion of global configurations across our &lt;a href="https://jazz.net/downloads/clm/releases/6.0" target="_blank"&gt;Collaborative Lifecycle Management&lt;/a&gt; (CLM) solution. This version marks the beginning of a completely new set of capabilities that empower users to do parallel development and test, and to reuse artifacts in an effective way.&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;Improved user experience&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Continuing on the work done in RQM 5.0.1 with the introduction of the Test Artifact dashboard widget, RQM 6.0 offers the new Test Statistics widget. Both of those widgets leverage the saved queries created in one of the test artifact views, such as the Test Case Execution Record view. Those live queries can now be reused with their results displayed directly on a dashboard. The Test Statistic widget offers the option to display the result in table format or in graphs such as bar charts, pie charts, or column charts.&lt;/p&gt;
&lt;p&gt;&lt;a rel="attachment wp-att-13259" href="https://jazz.net/blog/index.php/2015/06/26/whats-new-in-rational-quality-manager-6-0/improved-ui/"&gt;&lt;img class="aligncenter size-full wp-image-13259" title="improved-UI" src="https://jazz.net/blog/wp-content/uploads/2015/06/improved-UI.png" alt="" width="537" height="185"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The team has also worked on improving collaboration support, specifically for concurrent modification of test artifacts. If two people modify the same test plan, suite, or case at the same time, the second person to attempt to save is now prompted with the option to merge the changes.&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;Single sign-on authentication&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;On top of the existing types of single sign-on (SSO) authentication already supported, this version introduces the Jazz Security Architecture SSO based on the OpenID Connect authentication protocol. The new Jazz Authorization Server simplifies the authentication administration. Read more in John Vasta&amp;#8217;s post about &lt;a href="https://jazz.net/blog/index.php/2015/06/19/new-single-sign-on-options-in-clm-6-0/" target="_blank"&gt;SSO options in CLM 6.0&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;Reporting&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;In v5, we introduced Jazz Reporting Service (JRS) as a new option to generate customizable analytics reports with a user-friendly web-based report builder. In v6.0, JRS is now included directly in the CLM package. This increases the availability for better reporting services for all of your applications without requiring the additional effort of organizing, installing, and configuring reporting capability through a separate download and install. There are also a number of new capabilities which make JRS the recommended analytics reporting solution for CLM, such as calculation and roll-up along with graphical report drill-through, new out-of-the-box reports, and interactive runtime filters in the dashboard widget. If you&amp;#8217;d like to learn more, see Ernest Mah&amp;#8217;s post on &lt;a href="https://jazz.net/blog/index.php/2015/06/22/whats-new-in-reporting-for-collaborative-lifecycle-management-6-0/" target="_blank"&gt;reporting in CLM 6.0&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Configuration management&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;RQM 6.0 is the first release that includes capabilities to aid in configuration management of test artifacts.&lt;/p&gt;
&lt;p&gt;On a basic level, configuration management enables users to better manage changes and to go back in time if needed through the creation of baselines and the ability to compare and merge. Users can create baselines to record a state in time of a Quality Management (QM) project area. Baselines are immutable and defined for an entire project area. Test artifacts of a baseline cannot be modified. Users can then compare the current state of a QM project area with any previous baseline. The comparison provides both a high-level view of the differences at the project area level as well as a detailed side-by-side comparison at the artifact level. Then, users have the opportunity to roll back some of the changes by merging a previous baseline into the current state and replacing some artifacts with the previous versions from that baseline.&lt;/p&gt;
&lt;p&gt;&lt;a rel="attachment wp-att-13260" href="https://jazz.net/blog/index.php/2015/06/26/whats-new-in-rational-quality-manager-6-0/baseline-rollback/"&gt;&lt;img class="aligncenter size-full wp-image-13260" title="baseline-rollback" src="https://jazz.net/blog/wp-content/uploads/2015/06/baseline-rollback.png" alt="" width="460" height="155"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In a more advanced usage model, configuration management offers the ability for testers to work independently and in parallel on multiple versions or variants of test artifacts. Users can create parallel streams by branching from an existing baseline. Streams are versions of all the test artifacts of a project area that can be changed. Users can merge changes made in one stream into another by first looking at the differences and then replacing all or some of the current versions by the versions of the artifacts in the baseline.&lt;/p&gt;
&lt;p&gt;&lt;a rel="attachment wp-att-13261" href="https://jazz.net/blog/index.php/2015/06/26/whats-new-in-rational-quality-manager-6-0/multi-stream/"&gt;&lt;img class="aligncenter size-full wp-image-13261" title="multi-stream" src="https://jazz.net/blog/wp-content/uploads/2015/06/multi-stream.png" alt="" width="468" height="193"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The local Quality Management configurations, both streams and baselines, can then be contributed to global configurations. Global configurations are cross-domain configurations that can link to multiple local configurations from the Requirements Management, Design Management, Software Configuration Management, and Quality Management applications. Global configurations are used to define a common context in which users can work and create all the deliverables for a given version or variant.&lt;/p&gt;
&lt;p&gt;&lt;a rel="attachment wp-att-13262" href="https://jazz.net/blog/index.php/2015/06/26/whats-new-in-rational-quality-manager-6-0/configuration-mgmt/"&gt;&lt;img class="aligncenter size-full wp-image-13262" title="configuration-mgmt" src="https://jazz.net/blog/wp-content/uploads/2015/06/configuration-mgmt.png" alt="" width="468" height="153"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Finally, by creating a hierarchy of global configurations, it is possible to manage composite product definitions and configurations that enable complex reuse scenarios at the subsystems and components levels.&lt;/p&gt;
&lt;p&gt;&lt;a rel="attachment wp-att-13263" href="https://jazz.net/blog/index.php/2015/06/26/whats-new-in-rational-quality-manager-6-0/configuration-mgmt-hierarchy/"&gt;&lt;img class="aligncenter size-full wp-image-13263" title="configuration-mgmt-hierarchy" src="https://jazz.net/blog/wp-content/uploads/2015/06/configuration-mgmt-hierarchy.png" alt="" width="468" height="180"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Learn more about RQM 6.0&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For details of what&amp;#8217;s new      in 6.0, check out &lt;a href="https://jazz.net/downloads/clm/releases/6.0?p=news" target="_blank"&gt;New &amp;amp; Noteworthy&lt;/a&gt; in the Downloads section.&lt;/li&gt;
&lt;li&gt;See the &lt;a href="https://jazz.net/downloads/clm/releases/6.0?p=releaseNotes" target="_blank"&gt;Release Notes&lt;/a&gt;&lt;strong&gt; &lt;/strong&gt;for      a list of fixes.&lt;/li&gt;
&lt;li&gt;To see what&amp;#8217;s supported,      see the &lt;a href="https://jazz.net/wiki/bin/view/Deployment/CLMSystemRequirements60" target="_blank"&gt;System Requirements&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;span&gt;&lt;img src="https://jazz.net/blog/wp-content/plugins/wp-spamfree/img/wpsf-img.php" width="0" height="0" alt=""&gt;&lt;/span&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:jazz-team-blog-whats-new-in-rational-quality-manager-60.html</guid></item><item><title>JetBrains 2014: The Year in Review</title><link>http://ciandcd.github.io/jetbrains-2014-the-year-in-review.html</link><description>From:&lt;a href="http://blog.jetbrains.com/blog/2015/01/21/jetbrains-2014-the-year-in-review/"&gt;http://blog.jetbrains.com/blog/2015/01/21/jetbrains-2014-the-year-in-review/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p id="fb-root"&gt;&lt;/p&gt;&amp;#13;
 &amp;#13;
&lt;p&gt;&amp;#13;
&lt;/p&gt;&lt;p class="g-plusone"&gt;&lt;/p&gt;
 
&lt;p&gt;&lt;/p&gt;
 
&lt;p class="fb-like"&gt;&lt;/p&gt;&amp;#13;
&amp;#13;
&lt;br clear="all"&gt;&lt;p dir="ltr"&gt;Our team was hard at work in 2014 delivering new releases of our existing products and bringing new ones to market. In this post we are going to take a look at those and some of the other biggest moments of the year.&lt;/p&gt;
&lt;p dir="ltr"&gt;If you remember back to&amp;#160;&lt;strong&gt;&lt;a title="JetBrains Day @ FooCafé" href="http://blog.jetbrains.com/blog/2013/09/12/jetbrains-day-foocafe-recap-announcements-and-videos/" target="_blank"&gt;JetBrains Day @ FooCaf&amp;#233;&lt;/a&gt;&lt;/strong&gt; in September 2013, we announced several new projects. 2014 saw those plans come to fruition. In February,&amp;#160;&lt;strong&gt;&lt;a title="ReShaper C++" href="https://www.jetbrains.com/resharper/features/cpp.html" target="_blank"&gt;ReSharper C++ Early Access Program&lt;/a&gt;&lt;/strong&gt;&amp;#160;went live, in May&amp;#160;&lt;strong&gt;&lt;a title="Nitra was made open source" href="http://blog.jetbrains.com/blog/2014/05/27/nitra-goes-open-source/" target="_blank"&gt;Nitra was made open source&lt;/a&gt;&lt;/strong&gt;, September brought&amp;#160;&lt;strong&gt;&lt;a title="CLion EAP program" href="https://www.jetbrains.com/clion/" target="_blank"&gt;CLion EAP&lt;/a&gt;&lt;/strong&gt;, and in December&amp;#160;&lt;strong&gt;&lt;a title="Upsource" href="https://www.jetbrains.com/upsource/" target="_blank"&gt;Upsource&lt;/a&gt;&lt;/strong&gt;, our repository browsing and code review tool, reached a stable 1.0 build.&lt;/p&gt;
&lt;p dir="ltr"&gt;&lt;img class="aligncenter size-full wp-image-6888" alt="Upsource" src="http://blog.jetbrains.com/wp-content/uploads/2015/01/pic_upsource.png" width="274" height="120"&gt;&lt;/p&gt;
&lt;p dir="ltr"&gt;We didn&amp;#8217;t stop there. Two new products were also added to our portfolio:&amp;#160;&lt;strong&gt;&lt;a title="0xDBE" href="https://www.jetbrains.com/dbe/" target="_blank"&gt;0xDBE&lt;/a&gt;&lt;/strong&gt;, JetBrains&amp;#8217; brand new IDE for DBAs and SQL developers, was first announced in June and in October&amp;#160;&lt;strong&gt;&lt;a title="PyCharm Education Edition" href="https://www.jetbrains.com/pycharm-educational/" target="_blank"&gt;PyCharm Education Edition&lt;/a&gt;&lt;/strong&gt;, a free IDE for learning and teaching programming with Python, went public. You may be interested in checking out our&amp;#160;&lt;strong&gt;&lt;a title="Interactive Python Programming Course Contest" href="https://www.jetbrains.com/pycharm-educational/contest/" target="_blank"&gt; Interactive Python Programming Course Contest&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;p dir="ltr"&gt;In 2014 we continued our commitment to the open source community through our various projects and by providing&amp;#160;&lt;strong&gt;&lt;a title="Free Open Source Licenses" href="https://www.jetbrains.com/devnet/sponsorship/open-source/" target="_blank"&gt;free open source licenses&lt;/a&gt;&lt;/strong&gt; to non-commercial OS software projects. In July a&amp;#160;&lt;strong&gt;&lt;a title="New Kotlin website" href="http://kotlinlang.org/" target="_blank"&gt;new open source Kotlin website&lt;/a&gt;&lt;/strong&gt; went live and steady releases of JetBrains&amp;#160;&lt;strong&gt;&lt;a title="Meta Programming System (MPS)" href="https://www.jetbrains.com/mps/" target="_blank"&gt;Meta Programming System&lt;/a&gt;&lt;/strong&gt; (MPS) continued to go out the door.&lt;/p&gt;
&lt;p dir="ltr"&gt;&lt;img class="aligncenter size-full wp-image-6889" alt="Open Source" src="http://blog.jetbrains.com/wp-content/uploads/2015/01/pic_pyCharm.png" width="415" height="83"&gt;&lt;/p&gt;
&lt;p dir="ltr"&gt;Travel again back in time to May 2013 when&amp;#160;&lt;strong&gt;&lt;a title="Google to Build Android Studio on IntelliJ Platform" href="http://blog.jetbrains.com/blog/2013/05/15/intellij-idea-is-the-base-for-android-studio-the-new-ide-for-android-developers/" target="_blank"&gt;Google announced their selection of IntelliJ IDEA as the base of Android Studio&lt;/a&gt;&lt;/strong&gt;. Well, in December, the highly anticipated&amp;#160;&lt;strong&gt;&lt;a href="http://developer.android.com/tools/studio/index.html"&gt;Android Studio 1.0&lt;/a&gt;&lt;/strong&gt; release hit the virtual shelves! This is a great example of open source collaboration working both ways with the work being done on Android Studio being incorporated back into &lt;strong&gt;&lt;a title="IntelliJ IDEA" href="https://www.jetbrains.com/idea/" target="_blank"&gt;IntelliJ IDEA Ultimate Edition&lt;/a&gt;&lt;/strong&gt; and the free and open source &lt;strong&gt;Community Edition&lt;/strong&gt;.&lt;/p&gt;
&lt;p dir="ltr"&gt;One of the proudest moments of the year came in September when we announced &lt;strong&gt;&lt;a title="JetBrains Student License Program" href="https://www.jetbrains.com/student/" target="_blank"&gt;JetBrains Student License Program&lt;/a&gt;&lt;/strong&gt;. Through this program students and teachers have access to our entire product line of IDEs and .NET Tools. Within the first two weeks of the program, more than&amp;#160;&lt;strong&gt;&lt;a title="34,000 students receive free licenses" href="http://blog.jetbrains.com/blog/2014/10/07/jetbrains-student-program-34k-students-join-in-two-weeks/" target="_blank"&gt;34,000 students were approved&lt;/a&gt;&lt;/strong&gt; and now there are &lt;strong&gt;nearly 100,000 students using JetBrains tools for free!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class="alignright size-full wp-image-6890" alt="JetBrains Startup Discount" src="http://blog.jetbrains.com/wp-content/uploads/2015/01/pic_discount-2.png" width="149" height="103"&gt;Nearly a decade and a half on we haven&amp;#8217;t forgotten our startup roots. In February we announced&amp;#160;&lt;strong&gt;&lt;a title="JetBrains Startup Discount Plan" href="https://www.jetbrains.com/estore/startup/" target="_blank"&gt;JetBrains Startup Discount Plan&lt;/a&gt;&lt;/strong&gt;. Software startup businesses that meet straightforward criteria get a &lt;strong&gt;50% discount on all of our products&lt;/strong&gt;. If your startup is just getting off the ground, this is a great place to begin.&lt;/p&gt;
&lt;p&gt;Lastly, here are some of the &lt;strong&gt;honors that our products picked up in 2014&lt;/strong&gt;.&lt;/p&gt;
 
&lt;p&gt;&lt;strong&gt;2014 was a fantastic year and we expect more of the same excitement in 2015. We sincerely thank you; all of our friends and colleagues, for your continued support and wish you all the best in the coming year. Here&amp;#8217;s to another outstanding and productive year in 2015!&lt;/strong&gt;&lt;/p&gt;
											&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:jetbrains-2014-the-year-in-review.html</guid></item><item><title>JetBrains Night in Munich Recap, Raffle Winners and Recording</title><link>http://ciandcd.github.io/jetbrains-night-in-munich-recap-raffle-winners-and-recording.html</link><description>From:&lt;a href="http://blog.jetbrains.com/blog/2015/04/29/jetbrains-night-in-munich-recap-raffle-winners-and-recording/"&gt;http://blog.jetbrains.com/blog/2015/04/29/jetbrains-night-in-munich-recap-raffle-winners-and-recording/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p id="fb-root"&gt;&lt;/p&gt;&amp;#13;
 &amp;#13;
&lt;p&gt;&amp;#13;
&lt;/p&gt;&lt;p class="g-plusone"&gt;&lt;/p&gt;
 
&lt;p&gt;&lt;/p&gt;
 
&lt;p class="fb-like"&gt;&lt;/p&gt;&amp;#13;
&amp;#13;
&lt;br clear="all"&gt;&lt;p&gt;In March 2015, we announced an evening event at our JetBrains office in Munich where we would show our guests how to Use ReSharper Effectively, and Perform Exploratory Code Reviews with Upsource. &lt;strong&gt;The level of interest was so great that we decided to hold an additional night to accommodate the volume of demand.&lt;/strong&gt; We could have filled a much larger venue, but we wanted to provide an opportunity to mingle with the team in a relaxed informal atmosphere. In hindsight, this was a good decision.&lt;/p&gt;
&lt;p&gt;Over two nights, March 24th and 25th, &lt;strong&gt;120 participants&lt;/strong&gt; gathered at JetBrains office to see in action &lt;strong&gt;&lt;a title="Repository Browser and Code Review Tool" href="https://www.jetbrains.com/upsource/" target="_blank"&gt;Upsource&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a title="Why Prefer ReSharper Ultimate" href="https://www.jetbrains.com/dotnet/" target="_blank"&gt;ReSharper Ultimate&lt;/a&gt;&lt;/strong&gt; (ReSharper, dotTrace, dotMemory and dotCover). The feedback that we received on location and through a follow-up survey were overwhelmingly positive, so much so that we are &lt;strong&gt;currently planning to extend the same concept with 3 hour in-depth workshops&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img class="aligncenter size-full wp-image-7009" alt="JetBrains Night in Munich" src="http://blog.jetbrains.com/wp-content/uploads/2015/04/CA8yHBQUcAAQRJH.jpg" width="599" height="337"&gt;&lt;/p&gt;
&lt;p&gt;JetBrains, and our Munich team in particular, would like to thank all of the participants for their time, great conversations and overall positive sentiment that contributed to making the evenings successful. As promised, today we are announcing the &lt;strong&gt;winners of our free personal license raffle&lt;/strong&gt;, along with their product of choice:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Maik Heller&amp;#160;&amp;#8211; dotCover&lt;/li&gt;
&lt;li&gt;Michael Baur&amp;#160;&amp;#8211; IntelliJ IDEA&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Lastly, we would like to share the recorded session featuring Matt Ellis (&lt;a title="Follow Matt Ellis on Twitter" href="https://twitter.com/citizenmatt" target="_blank"&gt;@citizenmatt&lt;/a&gt;), Using ReSharper Effectively. Enjoy the video and we hope to meet you at an upcoming event near you!&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;Develop with Pleasure!&lt;/p&gt;
&lt;p&gt;- The JetBrains Team&lt;/p&gt;
											&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:jetbrains-night-in-munich-recap-raffle-winners-and-recording.html</guid></item><item><title>Live Webinar: Reactive Stream Processing with Akka Streams</title><link>http://ciandcd.github.io/live-webinar-reactive-stream-processing-with-akka-streams.html</link><description>From:&lt;a href="http://blog.jetbrains.com/blog/2015/01/14/live-webinar-reactive-stream-processing-with-akka-streams/"&gt;http://blog.jetbrains.com/blog/2015/01/14/live-webinar-reactive-stream-processing-with-akka-streams/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p id="fb-root"&gt;&lt;/p&gt;&amp;#13;
 &amp;#13;
&lt;p&gt;&amp;#13;
&lt;/p&gt;&lt;p class="g-plusone"&gt;&lt;/p&gt;
 
&lt;p&gt;&lt;/p&gt;
 
&lt;p class="fb-like"&gt;&lt;/p&gt;&amp;#13;
&amp;#13;
&lt;br clear="all"&gt;&lt;p&gt;We are pleased to invite you to our upcoming webinar, &lt;strong&gt;&lt;a title="Register Now: Reactive Stream Processing with Akka Streams" href="http://info.jetbrains.com/IDEA-Webinar-January2015-registration.html" target="_blank"&gt;Reactive Stream Processing with Akka Streams&lt;/a&gt;&lt;/strong&gt;, featuring Konrad Malawski of Typesafe. Register now and join us&amp;#160;&lt;strong&gt;Tuesday, January 27th, 15:00 &amp;#8211; 16:00 GMT&lt;/strong&gt; (10:00 AM &amp;#8211; 11:00 AM EST).&lt;/p&gt;
&lt;p&gt;In this webinar, Konrad will give an overview of the Reactive Streams specification&amp;#160;(with teams from Netflix, Pivotal, RedHat, Typesafe and the others), the issues it addresses and how all the implementations aim to consolidate on a shared streaming protocol. Also, you&amp;#8217;ll learn how to use Akka Streams for working with streaming data in an&amp;#160;asynchronous type-safe and back-pressured manner.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hurry up and&amp;#160;&lt;a href="http://info.jetbrains.com/IDEA-Webinar-January2015-registration.html"&gt;register now&lt;/a&gt;, space is limited!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;About the presenter&lt;/p&gt;
&lt;img class="alignleft size-full wp-image-2363" alt="Konrad Malawski" src="http://blog.jetbrains.com/wp-content/uploads/2015/01/KM_200x200.jpg" width="110" height="110"&gt;&lt;strong&gt;Konrad Malawski&lt;/strong&gt; is a late-night passionate dev living by the motto, &amp;#8220;Life is Study!&amp;#8221;, hacking on the Akka toolkit at Typesafe. While working on Akka Streams he also implemented the Reactive Streams specifications Technology Compatibility Kit. You can follow him on Twitter &amp;#8211; &lt;a&gt;&lt;/a&gt;&lt;p&gt;is a late-night passionate dev living by the motto, &amp;#8220;Life is Study!&amp;#8221;, hacking on the Akka toolkit at Typesafe. While working on Akka Streams he also implemented the Reactive Streams specifications Technology Compatibility Kit. You can follow him on Twitter &amp;#8211; &lt;a href="https://twitter.com/ktosopl"&gt;@ktosopl&lt;/a&gt; &lt;/p&gt;&lt;p&gt; Follow IntelliJ IDEA on our&amp;#160;&lt;a title="IntelliJ IDEA Blog" href="http://blog.jetbrains.com/idea/" target="_blank"&gt;blog&lt;/a&gt;, Twitter &lt;a title="Follow IntelliJ IDEA on Twitter" href="https://twitter.com/IntelliJIDEA" target="_blank"&gt;@IntellIJIDEA&lt;/a&gt;, and our &lt;a title="IntelliJ IDEA Product Pages" href="https://www.jetbrains.com/idea/" target="_blank"&gt;product pages&lt;/a&gt;.&lt;/p&gt;
											&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:live-webinar-reactive-stream-processing-with-akka-streams.html</guid></item><item><title>Live Webinar: Software Architecture as Code, February 12th</title><link>http://ciandcd.github.io/live-webinar-software-architecture-as-code-february-12th.html</link><description>From:&lt;a href="http://blog.jetbrains.com/blog/2015/01/29/live-webinar-software-architecture-as-code-february-12th/"&gt;http://blog.jetbrains.com/blog/2015/01/29/live-webinar-software-architecture-as-code-february-12th/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p id="fb-root"&gt;&lt;/p&gt;&amp;#13;
 &amp;#13;
&lt;p&gt;&amp;#13;
&lt;/p&gt;&lt;p class="g-plusone"&gt;&lt;/p&gt;
 
&lt;p&gt;&lt;/p&gt;
 
&lt;p class="fb-like"&gt;&lt;/p&gt;&amp;#13;
&amp;#13;
&lt;br clear="all"&gt;&lt;p&gt;We are pleased to invite you to our upcoming webinar, &lt;strong&gt;&lt;a title="Register Now: Software Architecture as Code" href="http://info.jetbrains.com/IDEA-Webinar-February2015-registration.html"&gt;Software Architecture as Code&lt;/a&gt;&lt;/strong&gt;,&amp;#160;featuring Simon Brown. Register now and join us&amp;#160;&lt;strong&gt;Thursday, February 12th, 15:00 &amp;#8211; 16:00 GMT&lt;/strong&gt;&amp;#160;(10:00 AM &amp;#8211; 11:00 AM EST).&lt;/p&gt;
&lt;p&gt;It&amp;#8217;s 2015 and with so much technology at our disposal, we&amp;#8217;re still manually drawing software architecture diagrams in tools like Microsoft Visio. Furthermore, these diagrams often don&amp;#8217;t reflect the implementation in code, and vice versa. This session will look at why this happens and how to resolve the conflict between software architecture and code through the use of architecturally-evident coding styles and the representation of software architecture models as code.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Space is limited; &lt;a title="Register Now: Software Architecture as Code" href="http://info.jetbrains.com/IDEA-Webinar-February2015-registration.html"&gt;learn more and register now&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt;
&lt;img class="alignleft size-full wp-image-2363" alt="Simon Brown" src="http://blog.jetbrains.com/idea/files/2015/01/simonbrown-square.jpg" width="150" height="150"&gt;&lt;strong&gt;&lt;a title="Follow Simon Brown on Twitter" href="https://twitter.com/simonbrown" target="_blank"&gt;Simon Brown&lt;/a&gt;&lt;/strong&gt; is an independent consultant and helps organizations to build better software by adopting a lightweight, pragmatic approach to software architecture. He is the creator of the C4 software architecture model and the author of &amp;#8220;Software Architecture for Developers,&amp;#8221; a developer-friendly guide to software architecture, technical leadership and the balance with agility.&lt;p&gt;is an independent consultant and helps organizations to build better software by adopting a lightweight, pragmatic approach to software architecture. He is the creator of the C4 software architecture model and the author of &amp;#8220;Software Architecture for Developers,&amp;#8221; a developer-friendly guide to software architecture, technical leadership and the balance with agility.&lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:live-webinar-software-architecture-as-code-february-12th.html</guid></item><item><title>Mocking Multiple Interfaces</title><link>http://ciandcd.github.io/mocking-multiple-interfaces.html</link><description>From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/716/mocking-multiple-interfaces-delphi-mocks"&gt;https://www.finalbuilder.com/resources/blogs/postid/716/mocking-multiple-interfaces-delphi-mocks&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Today we updated Delphi Mocks to enable the Mocking of multiple interfaces. This is useful when the interface you wish to Mock is cast to another interface during testing.
For example you could have the following system you wish to test.&lt;/p&gt;
&lt;pre class="brush:delphi; toolbar:true;"&gt;type
  {$M+}
  IVisitor = interface;

  IElement = interface
    ['{A2F4744E-7ED3-4DE3-B1E4-5D6C256ACBF0}']
    procedure Accept(const AVisitor : IVisitor);
  end;

  IVisitor = interface
    ['{0D150F9C-909A-413E-B29E-4B869C6BC309}']
    procedure Visit(const AElement : IElement);
  end;

  IProject = interface
    ['{807AF964-E937-4A8A-A3D2-34074EF66EE8}']
    procedure Save;
    function IsDirty : boolean;
  end;

  TProject = class(TInterfacedObject, IProject, IElement)
  protected
    function IsDirty : boolean;
    procedure Accept(const AVisitor : IVisitor);
  public
    procedure Save;
  end;

  TProjectSaveCheck = class(TInterfacedObject, IVisitor)
  public
    procedure Visit(const AElement : IElement);
  end;
  {$M-}

implementation

  { TProjectSaveCheck }

  procedure TProjectSaveCheck.Visit(const AElement: IElement);
  var
    project : IProject;
  begin
    if not Supports(AElement, IProject, project) then
      raise Exception.Create('Element passed to Visit was not an IProject.');

    if project.IsDirty then
      project.Save;
  end;

&lt;/pre&gt;
&lt;p&gt;The trouble previously was that when testing TProjectSaveCheck a TMock&amp;lt;IElement&amp;gt; would be required, as well as a TMock&amp;lt;IProject&amp;gt;. This is brought about by the Visit procedure requiring the IElement its passed to be an IProject for the work its going to perform.&lt;/p&gt;
&lt;p&gt;This is now very simple with the Implement&amp;lt;I&amp;gt; method available off TMock&amp;lt;T&amp;gt;. For example to test that Save is called when IsDirty returns true, the following test could be written;&lt;/p&gt;
&lt;pre class="brush:delphi; toolbar:true;"&gt;procedure TExample_InterfaceImplementTests.Implement_Multiple_Interfaces;
var
  visitorSUT : IVisitor;
  mockElement : TMock&amp;lt;IElement&amp;gt;;
begin
  //Test that when we visit a project, and its dirty, we save.

  //CREATE - The visitor system under test.
  visitorSUT := TProjectSaveCheck.Create;

  //CREATE - Element mock we require.
  mockElement := TMock&amp;lt;IElement&amp;gt;.Create;

  //SETUP - Add the IProject interface as an implementation for the mock
  mockElement.Implement&amp;lt;IProject&amp;gt;;

  //SETUP - Mock project will show as dirty and will expect to be saved.
  mockElement.Setup&amp;lt;IProject&amp;gt;.WillReturn(true).When.IsDirty;
  mockElement.Setup&amp;lt;IProject&amp;gt;.Expect.Once.When.Save;

  //TEST - Visit the mock element to see if our test works.
  visitorSUT.Visit(mockElement);

  //VERIFY - Make sure that save was indeed called.
  mockElement.VerifyAll;
end;
&lt;/pre&gt;
&lt;br&gt;
&lt;p&gt;The Mock mockElement  "implements" two interfaces IElement, and IProject. IElement is done via the constructor, and IProject is added through the Implement&amp;lt;I&amp;gt; call. The Implement&amp;lt;I&amp;gt; call adds another sub proxy to the mock object. This sub proxy then allows all the mocking functionality to be performed with the IProject interface.&lt;/p&gt;
&lt;p&gt;To access the Setup, and Expects behaviour there are overloaded generic calls on TMock. These return the correct proxy to interact with, and generic type ISetup&amp;lt;I&amp;gt; and IExpect&amp;lt;I&amp;gt;. This is seen in the call to mockElement.Setup&amp;lt;IProject&amp;gt;. This returns a ISetup&amp;lt;IProject&amp;gt; which allows definition of what should occur when IProject is used from the Mock.&lt;/p&gt;
&lt;p&gt;This feature is really useful when there is a great deal of casting of interfaces done in the system you wish to test. It can save having to mock base classes directly where multiple interfaces are implemented.&lt;/p&gt;
&lt;p&gt;The way this works under the hood is fairly straight forward. TVirtualInterfaces are used when an interface is required to be mocked. This allows the capturing of method calls, and the creation of the interface instance when its required.&lt;/p&gt;
&lt;p&gt;The Implement&amp;lt;I&amp;gt; functionality simply extends this so that when a TProxyVirtualInterface (inherited from TVirtualInterface) has QueryInterface called it also looks to its owning Proxy. If any other Proxies implement the requested interface its that TProxyVirtualInterface which is returned.&lt;/p&gt;
&lt;p&gt;In essence this allows us to fake the Mock implementing multiple interfaces, when in fact there are a list of TVirtualInterface's all implementing a single interface.&lt;/p&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:mocking-multiple-interfaces.html</guid></item><item><title>Plugin Settings</title><link>http://ciandcd.github.io/plugin-settings.html</link><description>From:&lt;a href="http://www.go.cd/2015/06/18/plugin-settings.html"&gt;http://www.go.cd/2015/06/18/plugin-settings.html&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Go is continously improving its plugin infrastructure. Starting 15.2.0 Go will support "Plugin Settings" that will allow plugins developers to accept global settings. Currently these configurations had to be supported via system properties or a file that is in specified format in a specified location, which makes it a little haphazard. With this feature "all" plugins will have one approach to accept plugins settings from user &amp;amp; access plugin settings from Go Server.&lt;/p&gt;

&lt;h3&gt;How does it work?&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;On plugin listing page users will see a gear icon (similar to one on the pipeline dashboard) for the plugins that accept plugin settings.&lt;/li&gt;
&lt;/ul&gt;


  &lt;img src="/images/blog/plugin-settings/list-plugin.png" class="has_border full_size" alt="Figure 1: GoCD - Plugin Listing" id="mature_ci_cd_setup" title="GoCD - Plugin Listing"&gt;
  Figure 1: Plugin listing with gear icon &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;Clicking on the gear icon opens a pop-up that renders "Plugin Settings" template that is provided by the plugin.&lt;/li&gt;
&lt;/ul&gt;


  &lt;img src="/images/blog/plugin-settings/configure-plugin.png" class="has_border full_size" alt="Figure 2: GoCD - Configure Plugin" id="mature_ci_cd_setup" title="GoCD - Configure Plugin"&gt;
  Figure 2: Configure plugin pop-up &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;On "Save" the user inputs are validated by plugin.&lt;/li&gt;
&lt;/ul&gt;


  &lt;img src="/images/blog/plugin-settings/configure-plugin-errors.png" class="has_border full_size" alt="Figure 2: GoCD - Configure Plugin Errors" id="mature_ci_cd_setup" title="GoCD - Configure Plugin Errors"&gt;
  Figure 3: Configure plugin pop-up with errors &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;


&lt;p&gt;We hope plugin developers are able to use this feature to provide a better experience to their users.&lt;/p&gt;

&lt;h4&gt;References:&lt;/h4&gt;

 

 

 



&lt;p&gt;As always, Go questions can be asked on the &lt;a href="https://groups.google.com/forum/#!forum/go-cd"&gt;mailing list&lt;/a&gt;.&lt;/p&gt;

&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:plugin-settings.html</guid></item><item><title>Refuge for Automated Build Studio Users</title><link>http://ciandcd.github.io/refuge-for-automated-build-studio-users.html</link><description>From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/708/refuge-for-automated-build-studio-users"&gt;https://www.finalbuilder.com/resources/blogs/postid/708/refuge-for-automated-build-studio-users&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;h1 class="heading"&gt;Refuge for Automated Build Studio Users&lt;/h1&gt; &amp;#13;
					&lt;p&gt;&lt;a href="https://www.finalbuilder.com/resources/blogs/author/vincent-parrett/aid/5"&gt;&amp;#13;
								&lt;img src="https://www.finalbuilder.com/profilepic.ashx?userId=5&amp;amp;h=75&amp;amp;w=75" alt="[Author:displayname]"&gt;By Vincent Parrett&lt;/a&gt;&lt;br&gt;On April 13, 2014&lt;/p&gt;&amp;#13;
							&amp;#13;
						&lt;br&gt;&amp;#13;
                    &lt;p class="content"&gt;&amp;#13;
                        SmartBear recently discontinued development of Automated Build Studio and deleted pretty much all references to it from their website. &lt;br&gt;
&lt;br&gt;
Within hours of the smartbear email going out to ABS users, we started getting questions about crossgrade discounts, and we're more than happy to help. &amp;#160;&lt;br&gt;
&lt;br&gt;
If you are an ABS user, contact us (sales @ finalbuilder.com ) with proof of purchase (invoice) for ABS and we'll provide you with a 50% off discount coupon for FinalBuilder 7 Professional Edition.&amp;#160;&lt;br&gt;
&lt;br&gt;
This is a limited time once only offer, valid until May 15th 2014. &amp;#160;Spread the word to your fellow ABS users.&amp;#160;&lt;br&gt;
&lt;br&gt;
While you you are checking out FinalBuilder, be sure to take a look at our Continuous Integration Server product, Continua CI. It's vastly superior to the CI features in ABS, but still allows you to create your build process using a visual build tool (FinalBuilder). &amp;#160;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;/p&gt;&amp;#13;
                &lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:refuge-for-automated-build-studio-users.html</guid></item><item><title>Sample Go CD Virtualbox based environment</title><link>http://ciandcd.github.io/sample-go-cd-virtualbox-based-environment.html</link><description>From:&lt;a href="http://www.go.cd/2014/09/09/Go-Sample-Virtualbox.html"&gt;http://www.go.cd/2014/09/09/Go-Sample-Virtualbox.html&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;If you're interested in checking out Go but don't want to spend the time automating your
own system, this might be a great option for you.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Edit on 11 November, 2014&lt;/strong&gt; - This box has been updated to Go version 14.3. For information about
what's new in this release please see &lt;a href="http://www.go.cd/releases/"&gt;http://www.go.cd/releases/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;We've created an environment using Vagrant and Virtualbox. Once it's up, you'll have a full
Go installation including several example pipleines. &lt;/p&gt;

&lt;h3&gt;System Requirements&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;In order to run this you'll need &lt;a href="https://www.virtualbox.org/"&gt;Virtualbox&lt;/a&gt; 
and &lt;a href="https://www.vagrantup.com/"&gt;Vagrant&lt;/a&gt;.&lt;/strong&gt; Both of these are available for most operating 
systems.&lt;/p&gt;

&lt;h3&gt;Using the box&lt;/h3&gt;

&lt;p&gt;To get started, open a command prompt in an empty directory and type...&lt;/p&gt;

&lt;blockquote&gt;
vagrant init gocd/gocd-demo
&lt;/blockquote&gt;

&lt;p&gt;This will create a file called Vagrantfile in your current directory. &lt;/p&gt;

&lt;p&gt;Next, type...&lt;/p&gt;

&lt;blockquote&gt;
vagrant up
&lt;/blockquote&gt;

&lt;p&gt;Completion of this (especially the first time) will take quite a while, depending on your
bandwidth. Vagrant will be downloading the full box image (almost 1.4GB) from Vagrantcloud 
while you wait.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; If you have an existing Go installation on the same machine as this virtual machine
you may get a port conflict. Vagrant will automatically map to a new port which will be 
shown in the startup messages. &lt;/p&gt;

&lt;p&gt;After a few minutes, you should be able to navigate to http://localhost:8153/ on your local
machine and see the following...&lt;/p&gt;

&lt;p&gt;&lt;img src="/images/blog/sample-virtualbox/pipelines.png" alt=""&gt;&lt;/p&gt;

&lt;p&gt;These pipelines are all related, as shown in the following value stream map screenshot...&lt;/p&gt;

&lt;p&gt;&lt;img src="/images/blog/sample-virtualbox/vsm.png" alt=""&gt;&lt;/p&gt;

&lt;p&gt;Feel free to play around with the installation and see how everything works. You can always
reset the box to it's orginal state if you need to!&lt;/p&gt;

&lt;h3&gt;What's on the machine?&lt;/h3&gt;

&lt;p&gt;The box will be updated as new things come out, but as of this writing...&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Go 14.3 Server&lt;/li&gt;
&lt;li&gt;Go 14.3 Agent&lt;/li&gt;
&lt;li&gt;3 very small PHP applications&lt;/li&gt;
&lt;li&gt;Basic Capistrano deployment scripts&lt;/li&gt;
&lt;li&gt;Local Git repo using Gitolite to manage permissions&lt;/li&gt;
&lt;li&gt;A couple simple phpunit tests&lt;/li&gt;
&lt;li&gt;A couple simple watir scripts&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;All of the code is on the Virtualbox machine at /home/vagrant/projects. The easiest way
to access this is to type 'vagrant ssh' at the command prompt in the same place you 
started the machine.&lt;/p&gt;

&lt;p&gt;The hope is that using this box you can see how real applications (even if they are small)
are built, tested and deployed with Go. &lt;/p&gt;

&lt;p&gt;As always, Go questions can be asked at &lt;a href="https://groups.google.com/forum/#!forum/go-cd"&gt;https://groups.google.com/forum/#!forum/go-cd&lt;/a&gt;&lt;/p&gt;

&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:sample-go-cd-virtualbox-based-environment.html</guid></item><item><title>Stopping support for Java</title><link>http://ciandcd.github.io/stopping-support-for-java.html</link><description>From:&lt;a href="http://www.go.cd/2014/07/09/stopping-support-for-java-jdk-6.html"&gt;http://www.go.cd/2014/07/09/stopping-support-for-java-jdk-6.html&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;There was a &lt;a href="http://support.thoughtworks.com/entries/23692466-Upgrade-to-Java-7-recommended"&gt;recommendation&lt;/a&gt;, in April 2013, that all users move their Go Server and Go Agent installations to Java 7. Oracle and OpenJDK no longer support Java 6. So it is time for Go to stop supporting it. 14.2.0 will be last Go release which will work with Java 6. Any new Go release beyond 14.2.0 might not work with Java 6.  &lt;/p&gt;

&lt;p&gt;If you have not already moved to Java 7, we request you to do so. Should you face any issues please do write to the &lt;a href="https://groups.google.com/forum/#!forum/go-cd"&gt;community mailing list&lt;/a&gt;. &lt;/p&gt;

&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:stopping-support-for-java.html</guid></item><item><title>Upcoming API Changes</title><link>http://ciandcd.github.io/upcoming-api-changes.html</link><description>From:&lt;a href="http://www.go.cd/2015/06/17/Upcoming-API-Changes.html"&gt;http://www.go.cd/2015/06/17/Upcoming-API-Changes.html&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;With the upcoming release of Go 15.2, we'd like to begin unifying and improving some of the existing APIs that Go supports.&lt;/p&gt;

&lt;p&gt;Go's APIs are fairly old, have &lt;a href="https://github.com/gocd/gocd/issues/572"&gt;inconsistent and unpredictable content types&lt;/a&gt; (csv, xml, json, plain text).&lt;/p&gt;

&lt;p&gt;Going forward, we would like to announce an ongoing effort to improve these APIs to use something that is more modern, easy to discover, learn and build API clients for.&lt;/p&gt;

&lt;p&gt;We would be using the &lt;a href="http://stateless.co/hal_specification.html"&gt;JSON HAL specification&lt;/a&gt;. Our API guidelines are &lt;a href="https://github.com/gocd/gocd/issues/1100"&gt;published on our RFC&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This will give us the opportunity to leverage Ruby and Rails to build these APIs, which should make it easier to incrementally iterate through and improve existing APIs to bring them to parity with our new guidelines.&lt;/p&gt;

&lt;p&gt;We welcome &lt;a href="https://github.com/gocd/gocd/issues/1100"&gt;any feedback&lt;/a&gt; to improve our guidelines and &lt;a href="https://github.com/gocd/gocd/issues?q=is%3Aopen+label%3Aapis+label%3Aenhancement"&gt;contributions&lt;/a&gt; to improve existing APIs.&lt;/p&gt;

&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:upcoming-api-changes.html</guid></item><item><title>Using Skip and Promote Conditions in Continua CI 1.5</title><link>http://ciandcd.github.io/using-skip-and-promote-conditions-in-continua-ci-15.html</link><description>From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/713/using-skip-and-promote-conditions-in-continua-ci-15"&gt;https://www.finalbuilder.com/resources/blogs/postid/713/using-skip-and-promote-conditions-in-continua-ci-15&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;br&gt;
&lt;h2&gt;Skip Conditions&lt;/h2&gt;
Skip Conditions allow you to controll whether a Stage is skipped or run based on expressions. All the expressions must evaluate to true for the stage to run (if there are no expressions then the stage will not be skipped).&amp;#160;&lt;br&gt;
&lt;br&gt;
&lt;img src="/blogimages/vincent/Continua-skip-conditions/skipconditions.png" alt="Skip Conditions"&gt;&lt;br&gt;
&lt;br&gt;
In the above example, we have a Stage called Obfuscate, and we want it to be skipped if you turn off obfuscation (by setting a variable) or if we are not deploying a build (again, controlled by a variable). You can also disable a stage completely so it is always skipped.&lt;br&gt;
&lt;h2&gt;Promote Conditions&lt;/h2&gt;
In Continua CI 1.0, you can chose if the next Stage is automatically run, or the builds stops and requires a manual promotion to continue to the next Stage. In Continua CI 1.5, Promote Conditions allow you control whether to automatically promote or not, based on expressions. &lt;p&gt;&amp;#160;All the expressions must evaluate to true for the build to continue to the next stage (if there are no expressions then the build will stop with a status of waiting for promotion).&amp;#160;&lt;/p&gt;&lt;br&gt;
&lt;br&gt;
&lt;img src="/blogimages/vincent/Continua-skip-conditions/promoteconditions.png" alt="Skip Conditions"&gt;&lt;br&gt;
&lt;br&gt;
In the above example, our build will continue on to the next Stage if the Deploy variable is set to true.&amp;#160;&lt;br&gt;
&lt;br&gt;
Continua CI 1.5 is currently in Beta - you can get it here :&lt;br&gt;
&lt;a https: www.finalbuilder.com downloads continuaci continuaci-beta-version-history title="Get the Continua CI 1.5 Beta"&gt;http://www.finalbuilder.com/downloads/continuaci/continuaci-beta-version-history&lt;/a&gt;&amp;#160;&lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;p&gt;One of the most asked for features in Continua CI 1.0 was the ability to control which stages run, ie the ability to skip stages dynamically, based on what happened earlier in the build, and to be able to control whether the build should continue on to the next stage or wait for user intervention. In Continua CI 1.5, we made this possible with Skip and Promote Conditions.Skip Conditions allow you to controll whether a Stage is skipped or run based on expressions. All the expressions must evaluate to true for the stage to run (if there are no expressions then the stage will not be skipped).In the above example, we have a Stage called Obfuscate, and we want it to be skipped if you turn off obfuscation (by setting a variable) or if we are not deploying a build (again, controlled by a variable). You can also disable a stage completely so it is always skipped.In Continua CI 1.0, you can chose if the next Stage is automatically run, or the builds stops and requires a manual promotion to continue to the next Stage. In Continua CI 1.5, Promote Conditions allow you control whether to automatically promote or not, based on expressions.In the above example, our build will continue on to the next Stage if the Deploy variable is set to true.Continua CI 1.5 is currently in Beta - you can get it here :&lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:using-skip-and-promote-conditions-in-continua-ci-15.html</guid></item><item><title>Using Windows PowerShell tasks</title><link>http://ciandcd.github.io/using-windows-powershell-tasks.html</link><description>From:&lt;a href="http://www.go.cd/2015/06/13/using-windows-powershell-tasks.html"&gt;http://www.go.cd/2015/06/13/using-windows-powershell-tasks.html&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Some things to be aware of when using Windows PowerShell tasks.&lt;/p&gt;

&lt;h3&gt;Go Agent default installation&lt;/h3&gt;

&lt;p&gt;The &lt;a href="http://www.go.cd/documentation/user/current/installation/installing_go_agent.html"&gt;default&lt;/a&gt; installation of a Go
agent will use a 32-bit JRE unless you indicate otherwise. This JRE is embedded in the Go agent installer.&lt;/p&gt;

&lt;p&gt;If you want to use an alternative JRE (must satisfy Go's JRE requirements) after the initial installation, you can alter
the "wrapper.java.command" key's value in the &lt;code&gt;[InstallDirectory]\config\wrapper-agent.conf&lt;/code&gt; file  to point to a
different JRE. You will then need to restart the Go agent service to start using the alternative JRE.&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;[InstallDirectory]&lt;/code&gt; refers to the Go agents installation directory which by default is &lt;code&gt;"C:\Program Files (x86)\Go Agent"&lt;/code&gt;.&lt;/p&gt;

&lt;h3&gt;Pre-requisites for running PowerShell task commands&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;You can only run on Windows based agents&lt;/li&gt;
&lt;li&gt;You should tag the agents if your are also using linux agents&lt;br&gt;&lt;/li&gt;
&lt;li&gt;You probably want to ensure your agents all have the same version of PowerShell&lt;br&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;32-bit Go agent&lt;/h4&gt;

&lt;p&gt;If you are running a default Go agent installation then you will be running a 32-bit JRE.&lt;/p&gt;

&lt;p&gt;The 32-bit JRE will try to run PowerShell tasks in the 32-bit version of PowerShell, even if you give the full path to
the 64-bit PowerShell executable in the task. If you need to execute a PowerShell script then you will need to alter the
execution policy as follows:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Open 32-bit version of PowerShell as an administrator: Start -&amp;gt; All Programs -&amp;gt; Accessories -&amp;gt; Windows Powershell -&amp;gt; Windows Powershell (x86) and type:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class="language-powershell"&gt;&lt;p class="c"&gt;# Alter execution policy&lt;/p&gt;
&lt;p class="nb"&gt;set-executionpolicy&lt;/p&gt; &lt;p class="n"&gt;remotesigned&lt;/p&gt; &lt;p class="n"&gt;-force&lt;/p&gt;  
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This will allow you to run local scripts on the Windows Go agent box.&lt;/p&gt;

&lt;h4&gt;64-bit Go agent&lt;/h4&gt;

&lt;p&gt;If you are running a Go agent using a 64-bit JRE, it will run PowerShell tasks in the 64-bit version of PowerShell.&lt;/p&gt;

&lt;p&gt;If you need to execute a PowerShell script, then you will need to alter the execution policy as follows:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Open 64-bit version of PowerShell as an administrator: Start -&amp;gt; All Programs -&amp;gt; Accessories -&amp;gt; Windows Powershell -&amp;gt;
Windows Powershell and type:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class="language-powershell"&gt;&lt;p class="c"&gt;# Alter execution policy&lt;/p&gt;
&lt;p class="nb"&gt;set-executionpolicy&lt;/p&gt; &lt;p class="n"&gt;remotesigned&lt;/p&gt; &lt;p class="n"&gt;-force&lt;/p&gt;  
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This will allow you to run local scripts on the Windows Go agent box.&lt;/p&gt;

&lt;h3&gt;PowerShell task commands&lt;/h3&gt;

&lt;p&gt;You can configure the task as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-text"&gt;command: powershell  
arg: .\run.ps1 arg1value  
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This assumes that the &lt;code&gt;run.ps1&lt;/code&gt; script is in the task's working directory.&lt;/p&gt;

&lt;p&gt;If you create the &lt;code&gt;run.ps1&lt;/code&gt; file with the following content you can see details of the execution context in the console log for the pipeline:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-powershell"&gt;&lt;p class="k"&gt;param&lt;/p&gt;
&lt;p class="p"&gt;(&lt;/p&gt;
    &lt;p class="no"&gt;[string]&lt;/p&gt; &lt;p class="nv"&gt;$arg1&lt;/p&gt;
&lt;p class="p"&gt;)&lt;/p&gt;
&lt;p class="nb"&gt;write-host&lt;/p&gt; &lt;p class="s2"&gt;"Script:            "&lt;/p&gt; &lt;p class="nv"&gt;$MyInvocation&lt;/p&gt;&lt;p class="p"&gt;.&lt;/p&gt;&lt;p class="n"&gt;MyCommand&lt;/p&gt;&lt;p class="p"&gt;.&lt;/p&gt;&lt;p class="n"&gt;Path&lt;/p&gt;
&lt;p class="nb"&gt;write-host&lt;/p&gt; &lt;p class="s2"&gt;"Pid:               "&lt;/p&gt; &lt;p class="nv"&gt;$pid&lt;/p&gt;
&lt;p class="nb"&gt;write-host&lt;/p&gt; &lt;p class="s2"&gt;"Host.Version:      "&lt;/p&gt; &lt;p class="nv"&gt;$host&lt;/p&gt;&lt;p class="p"&gt;.&lt;/p&gt;&lt;p class="n"&gt;version&lt;/p&gt;
&lt;p class="nb"&gt;write-host&lt;/p&gt; &lt;p class="s2"&gt;"Is 64-bit process: "&lt;/p&gt; &lt;p class="p"&gt;$(&lt;/p&gt;&lt;p class="no"&gt;[Environment]&lt;/p&gt;&lt;p class="p"&gt;::&lt;/p&gt;&lt;p class="n"&gt;Is64BitProcess&lt;/p&gt;&lt;p class="p"&gt;)&lt;/p&gt;
&lt;p class="nb"&gt;write-host&lt;/p&gt; &lt;p class="s2"&gt;"Execution policy:  "&lt;/p&gt; &lt;p class="p"&gt;$(&lt;/p&gt;&lt;p class="nb"&gt;get-executionpolicy&lt;/p&gt;&lt;p class="p"&gt;)&lt;/p&gt;
&lt;p class="nb"&gt;write-host&lt;/p&gt; &lt;p class="s2"&gt;"Arg1:              "&lt;/p&gt; &lt;p class="nv"&gt;$arg1&lt;/p&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;Propagating failures&lt;/h3&gt;

&lt;p&gt;You need to ensure that PowerShell exits with an exit code that is not 0 in the event of a failure, this needs to cater to:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Script errors&lt;/li&gt;
&lt;li&gt;External process calls that indicate failure&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You will need to decide how to handle these failures and if they should indicate the PowerShell task has been successful
or not. This may mean that some script errors and external process calls failing is okay in your context.&lt;/p&gt;

&lt;p&gt;The following script demonstrates a strategy I use where I exit with a non zero code if any script error was encountered
or an external process call fails:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-powershell"&gt;&lt;p class="nb"&gt;set-strictmode&lt;/p&gt; &lt;p class="n"&gt;-version&lt;/p&gt; &lt;p class="n"&gt;latest&lt;/p&gt;
&lt;p class="nv"&gt;$ErrorActionPreference&lt;/p&gt; &lt;p class="p"&gt;=&lt;/p&gt; &lt;p class="s1"&gt;'Stop'&lt;/p&gt;

&lt;p class="k"&gt;function&lt;/p&gt; &lt;p class="n"&gt;execute-externaltool&lt;/p&gt;
&lt;p class="p"&gt;(&lt;/p&gt;
    &lt;p class="no"&gt;[string]&lt;/p&gt; &lt;p class="nv"&gt;$context&lt;/p&gt;&lt;p class="p"&gt;,&lt;/p&gt;
    &lt;p class="no"&gt;[scriptblock]&lt;/p&gt; &lt;p class="nv"&gt;$actionBlock&lt;/p&gt;
&lt;p class="p"&gt;)&lt;/p&gt;
&lt;p class="p"&gt;{&lt;/p&gt;
    &lt;p class="c"&gt;# This function exists to check the exit code for the external tool called within the script block, so we don't have to do this for each call&lt;/p&gt;
    &lt;p class="p"&gt;&amp;amp;&lt;/p&gt; &lt;p class="nv"&gt;$actionBlock&lt;/p&gt;
    &lt;p class="k"&gt;if&lt;/p&gt; &lt;p class="p"&gt;(&lt;/p&gt;&lt;p class="nv"&gt;$LastExitCode&lt;/p&gt; &lt;p class="o"&gt;-gt&lt;/p&gt; &lt;p class="n"&gt;0&lt;/p&gt;&lt;p class="p"&gt;)&lt;/p&gt; &lt;p class="p"&gt;{&lt;/p&gt; &lt;p class="k"&gt;throw&lt;/p&gt; &lt;p class="s2"&gt;"$context : External tool call failed"&lt;/p&gt; &lt;p class="p"&gt;}&lt;/p&gt;
&lt;p class="p"&gt;}&lt;/p&gt;


&lt;p class="k"&gt;try&lt;/p&gt;
&lt;p class="p"&gt;{&lt;/p&gt;
    &lt;p class="nb"&gt;write-host&lt;/p&gt; &lt;p class="s2"&gt;"Script:            "&lt;/p&gt; &lt;p class="nv"&gt;$MyInvocation&lt;/p&gt;&lt;p class="p"&gt;.&lt;/p&gt;&lt;p class="n"&gt;MyCommand&lt;/p&gt;&lt;p class="p"&gt;.&lt;/p&gt;&lt;p class="n"&gt;Path&lt;/p&gt;
    &lt;p class="nb"&gt;write-host&lt;/p&gt; &lt;p class="s2"&gt;"Pid:               "&lt;/p&gt; &lt;p class="nv"&gt;$pid&lt;/p&gt;
    &lt;p class="nb"&gt;write-host&lt;/p&gt; &lt;p class="s2"&gt;"Host.Version:      "&lt;/p&gt; &lt;p class="nv"&gt;$host&lt;/p&gt;&lt;p class="p"&gt;.&lt;/p&gt;&lt;p class="n"&gt;version&lt;/p&gt;
    &lt;p class="nb"&gt;write-host&lt;/p&gt; &lt;p class="s2"&gt;"Execution policy:  "&lt;/p&gt; &lt;p class="p"&gt;$(&lt;/p&gt;&lt;p class="nb"&gt;get-executionpolicy&lt;/p&gt;&lt;p class="p"&gt;)&lt;/p&gt;

    &lt;p class="c"&gt;# Query a service that does not exist, sc.exe will return with a non 0 exit code&lt;/p&gt;
    &lt;p class="n"&gt;execute-externaltool&lt;/p&gt; &lt;p class="s2"&gt;"Query a non existent service, will return with exit code != 0"&lt;/p&gt; &lt;p class="p"&gt;{&lt;/p&gt; &lt;p class="n"&gt;c&lt;/p&gt;&lt;p class="err"&gt;:&lt;/p&gt;&lt;p class="p"&gt;\&lt;/p&gt;&lt;p class="n"&gt;windows&lt;/p&gt;&lt;p class="p"&gt;\&lt;/p&gt;&lt;p class="n"&gt;system32&lt;/p&gt;&lt;p class="p"&gt;\&lt;/p&gt;&lt;p class="n"&gt;sc&lt;/p&gt;&lt;p class="p"&gt;.&lt;/p&gt;&lt;p class="n"&gt;exe&lt;/p&gt; &lt;p class="n"&gt;query&lt;/p&gt; &lt;p class="n"&gt;service_does_not_exist&lt;/p&gt; &lt;p class="p"&gt;}&lt;/p&gt; 
&lt;p class="p"&gt;}&lt;/p&gt;
&lt;p class="k"&gt;catch&lt;/p&gt;
&lt;p class="p"&gt;{&lt;/p&gt;
    &lt;p class="nb"&gt;write-host&lt;/p&gt; &lt;p class="s2"&gt;"$pid : Error caught - $_"&lt;/p&gt;
    &lt;p class="k"&gt;if&lt;/p&gt; &lt;p class="p"&gt;($?&lt;/p&gt; &lt;p class="o"&gt;-and&lt;/p&gt; &lt;p class="p"&gt;(&lt;/p&gt;&lt;p class="nb"&gt;test-path&lt;/p&gt; &lt;p class="n"&gt;variable&lt;/p&gt;&lt;p class="err"&gt;:&lt;/p&gt;&lt;p class="n"&gt;LastExitCode&lt;/p&gt;&lt;p class="p"&gt;)&lt;/p&gt; &lt;p class="o"&gt;-and&lt;/p&gt; &lt;p class="p"&gt;(&lt;/p&gt;&lt;p class="nv"&gt;$LastExitCode&lt;/p&gt; &lt;p class="o"&gt;-gt&lt;/p&gt; &lt;p class="n"&gt;0&lt;/p&gt;&lt;p class="p"&gt;))&lt;/p&gt; &lt;p class="p"&gt;{&lt;/p&gt; &lt;p class="n"&gt;exit&lt;/p&gt; &lt;p class="nv"&gt;$LastExitCode&lt;/p&gt; &lt;p class="p"&gt;}&lt;/p&gt;
    &lt;p class="k"&gt;else&lt;/p&gt; &lt;p class="p"&gt;{&lt;/p&gt; &lt;p class="n"&gt;exit&lt;/p&gt; &lt;p class="n"&gt;1&lt;/p&gt; &lt;p class="p"&gt;}&lt;/p&gt;
&lt;p class="p"&gt;}&lt;/p&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;This script uses a try catch block to handle all errors

&lt;ul&gt;
&lt;li&gt;The $? and $LastExitCode caters to both script and external process calls&lt;/li&gt;
&lt;li&gt;We fall back on an exit code of 1 if we do not have an external process exit code&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;This script uses an execute-externaltool function which takes a script block argument

&lt;ul&gt;
&lt;li&gt;The script will invoke the script block&lt;/li&gt;
&lt;li&gt;It will then check for a non zero exit code (Assumes the script block just calls an external process), if so it will throw an exception.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;See also&lt;/h3&gt;

&lt;p&gt;&lt;a href="https://technet.microsoft.com/en-us/library/hh849812.aspx"&gt;PowerShell execution policy&lt;/a&gt;&lt;br&gt;
&lt;a href="https://blog.netspi.com/15-ways-to-bypass-the-powershell-execution-policy/"&gt;Bypassing PowerShell execution policy&lt;/a&gt;&lt;br&gt;
&lt;a href="https://codelucidate.wordpress.com/powershell/change-execution-policy-in-the-registry/"&gt;Setting execution policy directly in the registry&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/manojlds/gocd-powershell-runner"&gt;Go PowerShell runner plugin&lt;/a&gt; - I believe it can only be configured on Windows based Go servers  &lt;/p&gt;

&lt;h3&gt;About the author&lt;/h3&gt;

&lt;p&gt;This is a guest post by Pat Mc Grath. You can find Pat &lt;a href="https://github.com/pmcgrath"&gt;on GitHub&lt;/a&gt;.&lt;/p&gt;

&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:using-windows-powershell-tasks.html</guid></item><item><title>Webinar Recording: Reactive Stream Processing with Akka Streams</title><link>http://ciandcd.github.io/webinar-recording-reactive-stream-processing-with-akka-streams.html</link><description>From:&lt;a href="http://blog.jetbrains.com/blog/2015/01/29/webinar-recording-reactive-stream-processing-with-akka-streams/"&gt;http://blog.jetbrains.com/blog/2015/01/29/webinar-recording-reactive-stream-processing-with-akka-streams/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p id="fb-root"&gt;&lt;/p&gt;&amp;#13;
 &amp;#13;
&lt;p&gt;&amp;#13;
&lt;/p&gt;&lt;p class="g-plusone"&gt;&lt;/p&gt;
 
&lt;p&gt;&lt;/p&gt;
 
&lt;p class="fb-like"&gt;&lt;/p&gt;&amp;#13;
&amp;#13;
&lt;br clear="all"&gt;&lt;p&gt;On Tuesday we had the pleasure to host a webinar together with Typesafe where Konrad Malawski, a Scala enthusiast who works on the Akka toolkit, gave a very comprehensive overview of the &lt;a href="http://www.reactive-streams.org/"&gt;Reactive Streams&lt;/a&gt; specification and one of its implementations &amp;#8212;&amp;#160;&lt;a href="http://doc.akka.io/docs/akka-stream-and-http-experimental/1.0-M2/scala.html"&gt;Akka Streams&lt;/a&gt;.&amp;#160;The slides from Konrad&amp;#8217;s presentation can be found at &lt;a href="http://www.slideshare.net/ktoso/reactive-stream-processing-with-akka-streams"&gt;SlideShare&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;About the presenter&lt;/strong&gt;&lt;/p&gt;
&lt;img class="alignleft size-full wp-image-2363" alt="Konrad Malawski" src="http://blog.jetbrains.com/idea/files/2015/01/rsz_115271243730_1368918237_o.jpg" width="110" height="110"&gt;&lt;strong&gt;Konrad Malawski&lt;/strong&gt; is a late-night passionate dev living by the motto, &amp;#8220;Life is Study!&amp;#8221;, hacking on the Akka toolkit at Typesafe. While working on Akka Streams he also implemented the Reactive Streams specifications Technology Compatibility Kit. You can follow him on Twitter &amp;#8211; &lt;a&gt;&lt;/a&gt;&lt;p&gt;is a late-night passionate dev living by the motto, &amp;#8220;Life is Study!&amp;#8221;, hacking on the Akka toolkit at Typesafe. While working on Akka Streams he also implemented the Reactive Streams specifications Technology Compatibility Kit. You can follow him on Twitter &amp;#8211; &lt;a href="https://twitter.com/ktosopl"&gt;@ktosopl&lt;/a&gt; &lt;/p&gt;&lt;p&gt;Develop with Pleasure!&lt;/p&gt;
											&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:webinar-recording-reactive-stream-processing-with-akka-streams.html</guid></item><item><title>Webinar Recording: What’s New in TeamCity 9</title><link>http://ciandcd.github.io/webinar-recording-whats-new-in-teamcity-9.html</link><description>From:&lt;a href="http://blog.jetbrains.com/blog/2015/01/26/webinar-recording-whats-new-in-teamcity-9/"&gt;http://blog.jetbrains.com/blog/2015/01/26/webinar-recording-whats-new-in-teamcity-9/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p id="fb-root"&gt;&lt;/p&gt;&amp;#13;
 &amp;#13;
&lt;p&gt;&amp;#13;
&lt;/p&gt;&lt;p class="g-plusone"&gt;&lt;/p&gt;
 
&lt;p&gt;&lt;/p&gt;
 
&lt;p class="fb-like"&gt;&lt;/p&gt;&amp;#13;
&amp;#13;
&lt;br clear="all"&gt;&lt;p&gt;The recording of our recent webinar with Wes Higbee, &lt;strong&gt;What&amp;#8217;s New in TeamCity 9&lt;/strong&gt;,&amp;#160;is now available on &lt;a href="http://youtu.be/q62fHl6lrxY"&gt;JetBrains YouTube Channel&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In this webinar, Wes goes over the new features of TeamCity 9, namely: rearranging projects with Project Import; storing settings in VCS; creating and editing Custom Charts; running builds in Cloud Agents; as well as some other improvements.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;Below are a selection of some of the most frequently asked questions.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;h2&gt;&amp;#160;Versioned Settings:&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Q:&amp;#160;When is this feature going to be available with Perforce?&lt;/strong&gt;&lt;br&gt;
&lt;strong&gt;&lt;/strong&gt;A:&amp;#160;We&amp;#8217;re considering support for Subversion and Perforce in TeamCity 9.1, but can&amp;#8217;t make any guarantees at this point.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q:&amp;#160;What about TFS?&lt;/strong&gt;&lt;br&gt;
A:&amp;#160;TFS might be supported in the future but after Subversion and Perforce.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q:&amp;#160;Given your VCS support priorities for new features, &amp;#160;are Git, Mercurial and TFS your recommended VCS combinations with TeamCity?&lt;/strong&gt;&lt;br&gt;
A:&amp;#160;Apart from storing settings in VCS, Git, Mercurial, Subversion and Perforce, they are all supported greatly with TFS catching up. CVS, Vault and ClearCase support can be a bit limited.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q:&amp;#160;How does TeamCtiy handle it if somebody corrupts the configuration in the repository?&lt;/strong&gt;&lt;br&gt;
A:&amp;#160;If there are errors while applying changes then TeamCity will not change project settings and will show an error.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q:&amp;#160;Is it possible to use branches, e.g. to test a change in the build configuration before making it productive?&lt;/strong&gt;&lt;br&gt;
&lt;strong&gt;&lt;/strong&gt;A: Not yet, but we definitely want to add this feature.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q:&amp;#160;How does the VCS know which branch to use?&lt;/strong&gt;&lt;br&gt;
A:&amp;#160;It uses default branch specified in VCS root.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q:&amp;#160;If you want to revert to an earlier version, you need to find the desired version from within the version control system. &amp;#160;That is, there&amp;#8217;s no GUI way to see the previous version from TeamCity perspective?&lt;/strong&gt;&lt;br&gt;
A:&amp;#160;There is a changelog tab where you can see all the changes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q:&amp;#160;What about parameters? Are they synced too? If not, the new features could replace templates, couldn&amp;#8217;t they?&lt;/strong&gt;&lt;br&gt;
A:&amp;#160;All the settings are synced form the VCS as if you edit the settings right in the TeamCity data directory (or change them in UI).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q: If a have sync on the root project, are all sub-projects synced too? Is it recommended to have VCS for the sub projects, or a VCS for the root project only? Or are both recommended?&lt;/strong&gt;&lt;br&gt;
A: By default sub projects will be placed into the same version control. If you don&amp;#8217;t want it for some projects, you can disable synchronization in them.&lt;/p&gt;
&lt;h2&gt;Project Import&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Q:&amp;#160;Can I import a TC8 backup in TC9? It would make testing easier &lt;img src="http://blog.jetbrains.com/wp-includes/images/smilies/icon_smile.gif" alt=":)" class="wp-smiley"&gt; &lt;/strong&gt;&lt;br&gt;
A:&amp;#160;No, both servers should have the same version. 9.0 and 9.0.x are compatible, but 8.1 and 9.0 not.&lt;/p&gt;
&lt;h2&gt;Cloud Agents&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Q:&amp;#160;How does that work out with the licensing system? I guess the number of agents licensed its the hard limit of active agents, including from the cloud?&lt;/strong&gt;&lt;br&gt;
A: Yes. The total number of agents (real and virtual) connected at any given time should not exceed the total agent licenses limit. When there are enough agent licences, TeamCity automatically authorizes new cloud agents and unauthorizes the stopped ones.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q: How do we create the VM image?Is a build image template available for the Azure VM image?&lt;/strong&gt;&lt;br&gt;
A: There are no templates with TeamCity agents for now&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q: Can we configure the &amp;#8220;on-demand&amp;#8221; agents to use the same VM with more than one agent, until that max out? i.e. 3 agents per Azure VM.&lt;/strong&gt;&lt;br&gt;
A: TeamCity assumes there is a single agent per instance. The recommended setup is to have a single agent per machine.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q: Can the on-demand agents be used with on-premise vCenter?&lt;/strong&gt;&lt;br&gt;
A: Yes we have &lt;a href="http://blog.jetbrains.com/teamcity/2014/12/teamcity-vmware-vsphere-plugin/"&gt;vSphere plugin&lt;/a&gt; doing the same.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q: Does the agent spun up hang around for a while or is it immediately removed?&lt;/strong&gt;&lt;br&gt;
A: There is an idle timeout setting to shutdown the agent instance after. When stopped, the agent is deleted from TeamCity list of agents.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q: EC2 cloud agents auto-shutdown policy is not the best it could be meaning that it doesn&amp;#8217;t take into account that you always get charged for an hour of usage of an EC2 instance. Any plans to improve this?&lt;/strong&gt;&lt;br&gt;
A: Yes, we do have plans to adjust the shut down to the hour limit. You are welcome to vote for &lt;a href="https://youtrack.jetbrains.com/issue/TW-9680"&gt;https://youtrack.jetbrains.com/issue/TW-9680&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Custom Charts&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Q: Is it possible to have time instead of build number on the X axis?&lt;/strong&gt;&lt;br&gt;
A: No, this is not possible&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q: I have a configuration that has different snapshot dependencies, is there any way to show the build time from beginning to end, meaning when the first dependency run to the end?&lt;/strong&gt;&lt;br&gt;
A: No, statistics charts operate per build. Theoretically you can calculate this time and report it as statistic value in the last build of the chain.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q: Can you export the stats data?&lt;/strong&gt;&lt;br&gt;
A: Yes, there is a &amp;#8220;download&amp;#8221; action on the chart. Also available via REST API.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q: Does TeamCity have possibility to show charts with time that took to run every test?&lt;/strong&gt;&lt;br&gt;
A: On the build&amp;#8217;s Tests tab, you can see the duration chart for each test. As well on the Test history page.&lt;/p&gt;
&lt;img class="alignleft  wp-image-2363" alt="Wes McClure" src="http://blog.jetbrains.com/teamcity/files/2015/01/Wes_sq_small.jpg" width="190" height="190"&gt;&lt;strong&gt;&lt;a title="Follow Wes McClure on Twitter" href="https://twitter.com/g0t4" target="_blank"&gt;Wes Higbee&lt;/a&gt;&lt;/strong&gt;&amp;#160;is passionate about helping companies achieve remarkable results with technology and software. He&amp;#8217;s had extensive experience developing software and working with teams to improve how software is developed to meet business objectives. Wes launched &lt;strong&gt;&lt;a title="Full City Tech Co." href="http://www.fullcitytechnology.com/" target="_blank"&gt;Full City Tech&lt;/a&gt;&lt;/strong&gt; to leverage his expertise to help companies rapidly deliver high quality software to delight customers. He has a strong background in using Continuous Integration with TeamCity to bring quality to the table.&lt;p&gt;is passionate about helping companies achieve remarkable results with technology and software. He&amp;#8217;s had extensive experience developing software and working with teams to improve how software is developed to meet business objectives. Wes launchedto leverage his expertise to help companies rapidly deliver high quality software to delight customers. He has a strong background in using Continuous Integration with TeamCity to bring quality to the table.&lt;/p&gt;&lt;p&gt;Follow TeamCity updates on our &lt;a title="TeamCity Blog" href="http://blog.jetbrains.com/teamcity/" target="_blank"&gt;blog&lt;/a&gt;, Twitter &lt;a title="Follow TeamCity on Twitter" href="https://twitter.com/teamcity" target="_blank"&gt;@TeamCity&lt;/a&gt;, and our &lt;a title="TeamCity Product Pages" href="https://www.jetbrains.com/teamcity/" target="_blank"&gt;product pages&lt;/a&gt;.&lt;/p&gt;
											&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:webinar-recording-whats-new-in-teamcity-9.html</guid></item><item><title>Adding custom reports to Continua CI Build Results</title><link>http://ciandcd.github.io/adding-custom-reports-to-continua-ci-build-results.html</link><description>From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/701/adding-custom-reports-to-continua-ci-build-results"&gt;https://www.finalbuilder.com/resources/blogs/postid/701/adding-custom-reports-to-continua-ci-build-results&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;It's not uncommon for tools run during a build process to create log files, xml or html files etc that you might want to keep, in other words &lt;a href="http://wiki.finalbuilder.com/display/continua/Artifacts" title="Artifacts in Continua CI"&gt;Artifacts&lt;/a&gt;. Continua CI already has a mechanism for registering Artifacts, which enables them to be viewed/downloaded from the Build Artifacts page. Continua CI also has another way of viewing those files, Reports. Reports are viewed in an iframe, which allows you to stay within the Continua CI UI, but still naviate within the report files. A typical use of the Report feature is showing exported FinalBuilder html logs, or Code Coverate html reports (for example those produced by OpenCover).&amp;#160;&lt;/p&gt;
&lt;h4&gt;Defining a Report&lt;/h4&gt;
&lt;p&gt;Defining a report is relatively simple. Just point it at a file you expect to appear in the Builds Workspace on the Server.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;
&lt;/p&gt;
&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/vincent/CI-Reports/DefineReport.png" alt="Define Report"&gt;&lt;p&gt;&lt;br&gt;
&lt;/p&gt;
&lt;p&gt;In this case we're expecting our build process to place a file named FinalBuilderReport.html in the $Workspace$\Reports folder. $Workspace$ will be replaced at run time with the builds workspace path on the server.&amp;#160;&lt;/p&gt;
&lt;p&gt;The next step is to make sure that the file actually gets copied to where we said it would be. We define a &lt;a href="http://wiki.finalbuilder.com/display/continua/Workspace+Rules" title="Workspace Rules Help"&gt;Workspace Rule&lt;/a&gt; to copy the file back to the build workspace on the server when the Stage completes.&amp;#160;If your tool generates .css and image files then don't forget to add rules to copy those files into place too.&amp;#160;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;
&lt;/p&gt;
&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/vincent/CI-Reports/WorkspaceRules.png" alt="Workspace Rules"&gt;&lt;p&gt;&lt;br&gt;
&lt;/p&gt;
&lt;p&gt;The final step is to make sure that the report file is actually produced. In this example, we are using an exported &amp;#160;FinalBuilder Log file, which is created in $Workspace$\Output\FB7 - we tell FinalBuilder where the workspace is by setting a FinalBuilder variable (along with a buch of other stuff like version numbering etc) in the &lt;a href="http://wiki.finalbuilder.com/display/continua/FinalBuilder+Action" title="FinalBuilder Action Help"&gt;FinalBuilder Action&lt;/a&gt;.&amp;#160;&lt;/p&gt;
&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/vincent/CI-Reports/FinalBuilderVariable.png" alt="Passing the Workspace folder to FinalBuilder"&gt;&lt;p&gt;&lt;br&gt;
&lt;/p&gt;
&lt;h4&gt;Viewing the Report&lt;/h4&gt;
&lt;p&gt;All thats left to do now is run the build, and view the report, If everything went to plan, then when you click on the builds Report Tab, you should see something like this :&lt;/p&gt;
&lt;img src="http://www.finalbuilder.com/Portals/0/ArticleImages/BlogImages/vincent/CI-Reports/TheReport.png" alt="Viewing the Report"&gt;&lt;p&gt;Notice the Home/Back/Forward Buttons. If your report comprises of multiple pages, and all the links in the html files are relative, then you get full history support in the iframe. FWIW, Open Cover with ReportGenerator does just that. We'll take a look at using Open Cover with Continua CI in a future post.&amp;#160;
&lt;/p&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:adding-custom-reports-to-continua-ci-build-results.html</guid></item><item><title>Adding NTLM SSO to Nancyfx</title><link>http://ciandcd.github.io/adding-ntlm-sso-to-nancyfx.html</link><description>From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/730/adding-ntlm-sso-to-nancyfx"&gt;https://www.finalbuilder.com/resources/blogs/postid/730/adding-ntlm-sso-to-nancyfx&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;a&gt;&lt;/a&gt;&lt;br&gt;
&lt;br&gt;
&lt;span&gt;&lt;a&gt;&lt;/a&gt;&lt;span&gt;&lt;a href="https://github.com/NancyFx/Nancy" target="_blank" title="Nancyfx on Github."&gt;Nancyfx&lt;/a&gt; is a Lightweight, low-ceremony, framework for building HTTP based services on .Net and Mono. It's open source and available on github.&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Nancy supports Forms Authentication, Basic Authentication and Stateless Authentication "out of the box", and it's simple to configure. In my application, I wanted to be able to handle mixed Forms and NTLM Authentication, which is something nancyfx &amp;#160;doesn't support. We have done this before with asp.net on IIS, and it was not a simple task, involving a child site with windows authentication enabled while the main site had forms (IIS doesn't allow both at the same time) and all sorts of redirection. It was painful to develop, and it's painful to install and maintain.&amp;#160;&lt;br&gt;
&lt;br&gt;
Fortunately with Nancy and &lt;a href="http://owin.org/" target="_blank" title="Owin Website"&gt;Owin&lt;/a&gt;, it's a lot simpler. Using Microsoft's implementation of the Owin spec, and Nancy's Owin support, it's actually quite easy, without the need for child websites and redirection etc.&amp;#160;&lt;/p&gt;
&lt;p&gt;I'm not going to explain how to use Nancy or Owin here, just the part needed to hook up NTLM support. In my application, NTLM authentication is invoked by a button on the login page ("Login using my windows account") which causes a specific login url to be hit. We're using Owin for hosting rather than IIS and Owin enables us to get access to the HttpListener, so we can control the authentication scheme for each url. We do this by adding an AuthenticationSchemeSelectorDelegate.&lt;/p&gt;
&lt;pre class="brush:c#; toolbar:true;"&gt;internal class Startup
{
    public void Configuration(IAppBuilder app)
    {
        var listener = (HttpListener)app.Properties["System.Net.HttpListener"];
       //add a delegate to select the auth scheme based on the url 
        listener.AuthenticationSchemeSelectorDelegate = request =&amp;gt;
        {
            //the caller requests we try windows auth by hitting a specific url
            return request.RawUrl.Contains("loginwindows") ? AuthenticationSchemes.IntegratedWindowsAuthentication : AuthenticationSchemes.Anonymous;
        }
        app.UseNancy();
    }
}
&lt;/pre&gt;
&lt;br&gt;
What this achieves is to invoke the NTLM negotiation if the "loginwindows" url is hit on our nancy application. If the negotiation is successful (ie the browser supports NTLM and is able to identify the user), &amp;#160;then the Owin environment will have the details of the user, and this is how we get those details out of Owin (in our bootstrapper class).&lt;br&gt;
&lt;br&gt;
&lt;pre class="brush:c#; toolbar:true;"&gt;protected override void ApplicationStartup(TinyIoCContainer container, IPipelines pipelines)
{
  pipelines.BeforeRequest.AddItemToStartOfPipeline((ctx) =&amp;gt;
  {
      if (ctx.Request.Path.Contains("loginwindows"))
      {
          var env = ((IDictionary&amp;lt;string,&amp;gt;)ctx.Items[Nancy.Owin.NancyOwinHost.RequestEnvironmentKey]);
          var user = (IPrincipal)env["server.User"];
          if (user != null &amp;amp;&amp;amp; user.Identity.IsAuthenticated)
          {
              //remove the cookie if someone tried sending one in a request!
              if (ctx.Request.Cookies.ContainsKey("IntegratedWindowsAuthentication"))
                  ctx.Request.Cookies.Remove("IntegratedWindowsAuthentication");
              //Add the user as a cooking on the request object, so that Nancy can see it.
              ctx.Request.Cookies.Add("IntegratedWindowsAuthentication", user.Identity.Name);
          }
      }
      return null;//ensures normal processing continues. 
  });
}&lt;/pre&gt;
&lt;br&gt;
Note we are adding the user in a cookie on the nancy Request object, which might seem a strange thing to do, but it was the only way I could find to add something to the request that can be accessed inside a nancy module, because everything else on the request object is read only. We don't send this cookie back to the user. So with that done, all that remains is the use that user in our login module&lt;br&gt;
&lt;br&gt;
&lt;pre class="brush:c#; toolbar:true;"&gt; Post["/loginwindows"] = parameters =&amp;gt; 
    {
        string domainUser = "";
        if (this.Request.Cookies.TryGetValue("IntegratedWindowsAuthentication",out domainUser))
        {
            //Now we can check if the user is allowed access to the application and if so, add 
            //our forms auth cookie to the response.             
            ...
        }
    }
&lt;/pre&gt;
&lt;br&gt;
Of course, this will probably only work on Windows, not sure what the current status is for System.Net.HttpListener is on Mono. This code was tested with Nancyfx 1.2 from nuget.&amp;#160;&lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                         &amp;#13;
                    &lt;p&gt;What this achieves is to invoke the NTLM negotiation if the "loginwindows" url is hit on our nancy application. If the negotiation is successful (ie the browser supports NTLM and is able to identify the user), then the Owin environment will have the details of the user, and this is how we get those details out of Owin (in our bootstrapper class).Note we are adding the user in a cookie on the nancy Request object, which might seem a strange thing to do, but it was the only way I could find to add something to the request that can be accessed inside a nancy module, because everything else on the request object is read only. We don't send this cookie back to the user. So with that done, all that remains is the use that user in our login moduleOf course, this will probably only work on Windows, not sure what the current status is for System.Net.HttpListener is on Mono. This code was tested with Nancyfx 1.2 from nuget.&lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:adding-ntlm-sso-to-nancyfx.html</guid></item><item><title>Authentication end-point</title><link>http://ciandcd.github.io/authentication-end-point.html</link><description>From:&lt;a href="http://www.go.cd/2015/06/18/authentication-end-point.html"&gt;http://www.go.cd/2015/06/18/authentication-end-point.html&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Starting 15.2.0 Go Server will expose authentication end-point. What this means is Go users can add "custom" authentication schemes through plugins. With &lt;a href="http://www.go.cd/documentation/developer/writing_go_plugins/plugin_settings/plugin_settings_overview.html"&gt;plugin settings&lt;/a&gt; &amp;amp; &lt;a href="http://www.go.cd/documentation/developer/writing_go_plugins/handling_web_requests.html"&gt;web request handling ability&lt;/a&gt; plugin developers get enough flexibility to write any authentication plugin they intend to write.&lt;/p&gt;

&lt;p&gt;Examples of integrations possible:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;OAuth Login - &lt;a href="https://github.com/srinivasupadhya/gocd-oauth-login"&gt;GitHub&lt;/a&gt;, &lt;a href="https://github.com/srinivasupadhya/gocd-oauth-login"&gt;Google&lt;/a&gt;, Hotmail, Yahoo! etc.&lt;/li&gt;
&lt;li&gt;Single Sign-on (SSO) - LDAP, Okta etc.&lt;/li&gt;
&lt;li&gt;2-factor authentication - SMS verification etc.&lt;/li&gt;
&lt;li&gt;Custom &lt;code&gt;username&lt;/code&gt; &amp;amp; &lt;code&gt;password&lt;/code&gt; authentication&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;How does it work?&lt;/h3&gt;

&lt;p&gt;Below is an explanation of how &lt;a href="https://github.com/srinivasupadhya/gocd-oauth-login"&gt;GitHub OAuth Login plugin&lt;/a&gt; works.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Generate OAuth token on GitHub.&lt;/li&gt;
&lt;/ul&gt;


  &lt;img src="/images/blog/authentication-plugins/generate-oauth-token.png" class="has_border full_size" alt="Figure 1: GitHub - Generate Oauth Token" id="mature_ci_cd_setup" title="GoCD - Generate Oauth Token"&gt;
  Figure 1: Generate oauth token &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;On plugin listing page users will see a gear icon (similar to one on the pipeline dashboard).&lt;/li&gt;
&lt;/ul&gt;


  &lt;img src="/images/blog/authentication-plugins/list-plugin.png" class="has_border full_size" alt="Figure 1: GoCD - Plugin Listing" id="mature_ci_cd_setup" title="GoCD - Plugin Listing"&gt;
  Figure 1: Plugin listing with gear icon &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;Clicking on the gear icon opens a pop-up that renders "Plugin Settings".&lt;/li&gt;
&lt;/ul&gt;


  &lt;img src="/images/blog/authentication-plugins/configure-plugin.png" class="has_border full_size" alt="Figure 2: GoCD - Configure Plugin" id="mature_ci_cd_setup" title="GoCD - Configure Plugin"&gt;
  Figure 2: Configure plugin pop-up &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;Login Page&lt;/li&gt;
&lt;/ul&gt;


  &lt;img src="/images/blog/authentication-plugins/login-page.png" class="has_border full_size" alt="Figure 2: GoCD - Login Page" id="mature_ci_cd_setup" title="GoCD - Login Page"&gt;
  Figure 3: Login Page with GitHub icon &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;Click on GitHub icon&lt;/li&gt;
&lt;/ul&gt;


  &lt;img src="/images/blog/authentication-plugins/github-login.png" class="has_border full_size" alt="Figure 2: GoCD - Authorize Go Server on GitHub" id="mature_ci_cd_setup" title="GoCD - Authorize Go Server on GitHub"&gt;
  Figure 3: Authorize Go Server to access GitHub &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;Successful login&lt;/li&gt;
&lt;/ul&gt;


  &lt;img src="/images/blog/authentication-plugins/successful-login.png" class="has_border full_size" alt="Figure 2: GoCD - On Successful Login" id="mature_ci_cd_setup" title="GoCD - On Successful Login"&gt;
  Figure 3: On successful login &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;Ability to Search &amp;amp; Add users&lt;/li&gt;
&lt;/ul&gt;


  &lt;img src="/images/blog/authentication-plugins/search-user.png" class="has_border full_size" alt="Figure 2: GoCD - Search User" id="mature_ci_cd_setup" title="GoCD - Search User"&gt;
  Figure 3: Search User &lt;p class="click_to_enlarge"&gt;(Click to enlarge)&lt;/p&gt;


&lt;p&gt;We hope plugin developers are able to use this feature to support their organizations authentication mechanism.&lt;/p&gt;

&lt;h4&gt;References:&lt;/h4&gt;

 

 

 



&lt;p&gt;As always, Go questions can be asked on the &lt;a href="https://groups.google.com/forum/#!forum/go-cd"&gt;mailing list&lt;/a&gt;.&lt;/p&gt;

&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:authentication-end-point.html</guid></item><item><title>Automated Builds vs Continuous Integration</title><link>http://ciandcd.github.io/automated-builds-vs-continuous-integration.html</link><description>From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/703/automated-builds-vs-continuous-integration"&gt;https://www.finalbuilder.com/resources/blogs/postid/703/automated-builds-vs-continuous-integration&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;
&lt;a href="http://osherove.com/"&gt;Roy Osherove&lt;/a&gt; posted an interesting video on youtube recently, talking about the difference between Automated Builds and Continuous Integration.&lt;/p&gt;
&lt;p&gt;This is a subject that comes up often in emails from existing and potential customers. Why do I need FinalBuilder if I have Continua CI, or, why haven't we added all the functionality of FinalBuilder to Continua CI?&lt;/p&gt;
&lt;p&gt;Roy sums up the differences and reasoning in this video quite nicely.&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;Roy goes into more detail in his "newish" book , &lt;a href="https://leanpub.com/build"&gt;Beautiful Builds&lt;/a&gt;. Lots of interesting food for thought. Lets face it, most developers probably don't spend too much time "deep thinking" how the build side of things
should be done. Roy's book is full of "deep thinking", but Roy sums it all up quite nicely! It's not a long book, around 40 pages and definitely worth a read. &lt;/p&gt;
&lt;h4&gt;FinalBuilder and Continua CI&lt;/h4&gt;
&lt;p&gt;The workflow functionality in Continua CI is inspired by FinalBuilder (which is probably stating the obvious to FinalBuilder users), but the functionality that is there is fairly high level. Your Continua CI Stage workflow can be as simple as a
single action (for example a FinalBuilder Action or MSBuild, or Rake or Powershell....), or you can make use of the flow control, logic, file operation actions etc and keep your build scripts as simple as your .sln file (or .dproj for delphi developers). That's for you to decide.
Of course our recommendation is to use FinalBuilder (and I say "of course" because I have wages to pay!) but there are obvious benefits to using FinalBuilder for your automated build scripts.&lt;/p&gt;
&lt;h4&gt;Develop and debug your build scripts on your machine&lt;/h4&gt;
&lt;p&gt;Using FinalBuilder, you can develop and debug your build script on your machine. FinalBuilder allows you to step through the build, set breakpoints, see what is happening, how variables are changing etc. The value of this shouldn't be underestimated; developing a FinalBuilder script is fast, easy and provides immediate feedback. No Web based CI Server (is there any other kind?) can give you this level of immediate feedback.&amp;#160;&lt;/p&gt;
&lt;p&gt;This also has the added benefit in that the FinalBuilder project will be runnable on other developers machines (assuming they have the required tools installed)&lt;/p&gt;
&lt;h4&gt;All of your build script is versioned with your source code.&lt;/h4&gt;
&lt;p&gt;If all of your build script functionality is in a FinalBuilder script, and that script is checked into version control (alongside your source code), then if the structure of your source code changes, so can your FinalBuilder script. The CI server will checkout the correct version of the build script for the version of source code it's checking out.&amp;#160;&lt;/p&gt;
&lt;h4&gt;Better Integration&lt;/h4&gt;
&lt;p&gt;We're currently working on better integration between Continua CI and FinalBuilder. Some of our FinalBuilder Server customers have complained that they lose functionality when moving to Continua CI. We understand that, FinalBuilder Server and FinalBuilder are tightly coupled. When we started
working on Continua CI, we made a conscious decision to not do that. That means Continua CI doesn't know about the internals of a FinalBuilder project, doesn't know what variables are declared. I still stand by that decision; it made Continua CI a better product. That said, there is more we can do
to improve how the two products work together. This work will show up in an update over the coming weeks (when it's ready!).
&lt;/p&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:automated-builds-vs-continuous-integration.html</guid></item><item><title>Automated UI Testing Done Right with ContinuaCI</title><link>http://ciandcd.github.io/automated-ui-testing-done-right-with-continuaci.html</link><description>From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/709/automated-ui-testing-done-right-with-continuaci"&gt;https://www.finalbuilder.com/resources/blogs/postid/709/automated-ui-testing-done-right-with-continuaci&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h1&gt;
Automated UI Testing Done Right with ContinuaCI&lt;/h1&gt;
You have just completed an awesomely complex change to your shinny new webapp! &amp;#160;After
running all your unit tests things are in the green and looking clean.&lt;br&gt;
&lt;br&gt;
Very satisfied at the quality of your work you fire up the application to verify
that everything is still working as advertised. &amp;#160;Below is what greets you on
the root path of your app:&amp;#160;&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/404-notfound-ie5.gif" alt="Funny error"&gt;&lt;br&gt;
&lt;br&gt;
We have all been here at some time or another! &amp;#160;What happened! &amp;#160;Perhaps
it was not your code that broke it! &amp;#160;Maybe the issue originated from another
part of your organisation, or maybe it came from somewhere on the "inter-webs".
&amp;#160;&lt;br&gt;
&lt;br&gt;
Its time to look at the underlying problem however ..... &amp;#160;testing web user
interfaces is hard! &amp;#160;Its time consuming and difficult to get right. &amp;#160;Manual
clicks, much typing, cross referencing client specifications etc, surely there must
be an easier way. &amp;#160;At the end of the day we DO need to test our user interfaces
&lt;img alt="" src="/Providers/HtmlEditorProviders/Telerik/images/Emoticons/wink_smile.gif" title="wink_smile"&gt;&lt;br&gt;
&lt;br&gt;
&lt;h4&gt;
Automated Web UI Testing&lt;/h4&gt;
&lt;br&gt;
Thankfully UI testing today can be Automated, running real browsers in real end
to end functional tests, to ensure our results meet (and continue to meet) expectations.
&amp;#160; &amp;#160;&amp;#160;&lt;br&gt;
&lt;p&gt;You have just completed an awesomely complex change to your shinny new webapp! After running all your unit tests things are in the green and looking clean.Very satisfied at the quality of your work you fire up the application to verify that everything is still working as advertised. Below is what greets you on the root path of your app:We have all been here at some time or another! What happened! Perhaps it was not your code that broke it! Maybe the issue originated from another part of your organisation, or maybe it came from somewhere on the "inter-webs".Its time to look at the underlying problem however ..... testing web user interfaces is hard! Its time consuming and difficult to get right. Manual clicks, much typing, cross referencing client specifications etc, surely there must be an easier way. At the end of the day we DO need to test our user interfacesThankfully UI testing today can be Automated, running real browsers in real end to end functional tests, to ensure our results meet (and continue to meet) expectations.&lt;/p&gt;&lt;p&gt;
For the sake of brevity and clarity in this demonstration we will focus on testing
an existing endpoint. &amp;#160;It is considered common place to find functional tests
included as part of a wider build pipeline, which may consist of such steps as:&amp;#160;&lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;Build&lt;/li&gt;
    &lt;li&gt;Unit Test&lt;/li&gt;
    &lt;li&gt;Deploy to Test Environment&lt;/li&gt;
    &lt;li&gt;Perform Functional Tests&lt;/li&gt;
    &lt;li&gt;Deploy to Production&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
In this article we will be focusing on the functional testing component of this
pipeline. &amp;#160;We will proceed on the assumption that your code has already been,
built unit tested and deployed to a Functional Test environment.  Today we
will;&lt;br&gt;
&lt;br&gt;
&lt;p&gt;Add Automated UI testing to an existing endpoint google.com&lt;/p&gt;&lt;br&gt;
&lt;p&gt;Configure ContinuaCI to automatically build our project, and perform the tests&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h4&gt;
Software Requirements:&amp;#160;&lt;/h4&gt;
&lt;br&gt;
&lt;ul&gt;
    &lt;li&gt;Visual Studio 2010 Express Edition SP1 or greater (&lt;a href="http://visualstudio.com/"&gt;visualstudio.com&lt;/a&gt;)&lt;/li&gt;
    &lt;li&gt;Microsoft Dot Net Framework version 4 or greater&lt;/li&gt;
    &lt;li&gt;Java JRE (&lt;a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html"&gt;http://www.oracle.com/technetwork/java/javase/downloads/index.html&lt;/a&gt;)&lt;/li&gt;
    &lt;li&gt;Mercurial (&lt;a href="http://mercurial.selenic.com/"&gt;mercurial.selenic.com&lt;/a&gt;)&lt;/li&gt;
    &lt;li&gt;Mozilla Firefox (&lt;a href="http://getfirefox.com/"&gt;getfirefox.com&lt;/a&gt;)&lt;/li&gt;
    &lt;li&gt;Nuget (&lt;a href="http://docs.nuget.org/docs/start-here/installing-nuget"&gt;docs.nuget.org/docs/start-here/installing-nuget&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;
Step1: Prepare a Selenium endpoint&lt;/h2&gt;
Firstly we will prepare for our UI tests by setting up a Selenium server. &amp;#160;&lt;span&gt;&lt;a&gt;&lt;/a&gt;&lt;span&gt;&lt;a href="http://docs.seleniumhq.org/"&gt;Selenium&lt;/a&gt; is a browser automation framework which will be used to 'remote control' a real browser.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;
&lt;br&gt;
Log into the machine you have chosen for the Selenium server with administrator
privileges&lt;br&gt;
Download and install Mozilla Firefox (getfirefox.com), this will be the browser
that we target as part of this example, however Selenium can target lots of other
browsers. &amp;#160;For a full breakdown please &lt;a&gt;&lt;/a&gt;&lt;br&gt;
Download Selenium Server (&lt;a&gt;&lt;/a&gt;&lt;br&gt;
&lt;br&gt;
Place it into a permanent
location of you choosing, in our example ("C:\Program Files (x86)\SeleniumServer")
&amp;#160; &amp;#160;&amp;#160;&lt;br&gt;
Download NSSM (&lt;a&gt;&lt;/a&gt;&lt;br&gt;
&lt;br&gt;
Ensure that port 4444 is set to allow traffic (this is the default communications&amp;#160;port
for Selenium)&amp;#160;&lt;br&gt;
&lt;br&gt;
Open a console and run the following commands:&amp;#160;&lt;br&gt;
&lt;p&gt;"C:\Program Files (x86)\nssm-2.22\win64\nssm.exe"
install Selenium-Server "java" "-jar \"C:\Program Files (x86)\SeleniumServer\selenium-server-standalone-2.41.0.jar\""&lt;br&gt;
net start Selenium-Server&lt;/p&gt;&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/install-sel-1.png" alt="name project"&gt;
&lt;br&gt;
&amp;#160;&lt;br&gt;
In order to uninstall the Selenium server service, the following commands can be
run:&amp;#160;&lt;br&gt;
&lt;p&gt;net stop Selenium-Server&lt;br&gt;
"C:\Program Files (x86)\nssm-2.22\win64\nssm.exe" remove Selenium-Server &lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/install-sel-2.png" alt="name project"&gt;
&lt;br&gt;
&lt;h2&gt;
Step2: Create a test class and add it to source control&lt;/h2&gt;
Create a new class library project in Visual Studio, &amp;#160;lets call it 'tests'&lt;br&gt;
Open the Nuget Package Manager Console window (tools menu-&amp;gt; library package manager
-&amp;gt; package manager console), select the test project as the default project and
run the following script:&amp;#160;&lt;br&gt;
&lt;br&gt;
Install-Package Selenium.Automation.Framework&lt;br&gt;
Install-Package Selenium.WebDriver&lt;br&gt;
Install-Package Selenium.Support&lt;br&gt;
Install-Package NUnit&lt;br&gt;
Install-Package NUnit.Runners&lt;br&gt;
&lt;br&gt;
Create a new class called within the tests project (lets call it tests) and place
the below code (Note: line 23 should be changed with location to the Selenium-Server
we setup in the previous step):&lt;br&gt;
&lt;br&gt;
&lt;pre class="brush: c#; toolbar:true"&gt;using System;
using System.Text;
using NUnit.Framework;
using OpenQA.Selenium.Firefox;
using OpenQA.Selenium;
using OpenQA.Selenium.Remote;
using OpenQA.Selenium.Support.UI;

namespace SeleniumTests
{
    [TestFixture]
    public class test
    {
        private RemoteWebDriver driver;
       

        [SetUp]
        public void SetupTest()
        {

            // Look for an environment variable
            string server = null;
            server = System.Environment.GetEnvironmentVariable("SELENIUM_SERVER");
            if (server == null)
            {
                server = "http:// *** PUT THE NAME OF YOUR SERVER HERE ***:4444/wd/hub";
            }
            
            // Remote testing
            driver = new RemoteWebDriver(new Uri(server), DesiredCapabilities.Firefox());
        }

        [TearDown]
        public void TeardownTest()
        {
            try
            {
                driver.Quit();
            }
            catch (Exception)
            {
                // Ignore errors if unable to close the browser
            }
        }

        [Test]
        public void FirstSeleniumTest()
        {
            driver.Navigate().GoToUrl("http://www.google.com/");
            IWebElement query = driver.FindElement(By.Name("q"));
            query.SendKeys("a test");
            Assert.AreEqual(driver.Title, "Google"); 
        }
       
    }
}
&lt;/pre&gt;
&lt;h2&gt;Step3: Test the test!&lt;/h2&gt;
Build the solution&amp;#160;&lt;br&gt;
Open NUnit build runner (by default this is located at ~\packages\NUnit.Runners.2.6.3\tools\nunit.exe)
, Select file -&amp;gt; Open Project, and locate the tests dll that you have build in
the previous step&lt;br&gt;
click the run button&lt;br&gt;
~ 15 seconds or so you should have one green test!&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-17.png" alt="name project"&gt;
&lt;br&gt;
&lt;br&gt;
So what just happened? &amp;#160;Behind the scenes an instance of firefox was opened
(on the Selenium Server), perform a simple google search query and undertook a simple
Nunit assertion has verified the name of the window was equal to "Google", very
cool!. &amp;#160;&lt;br&gt;
&lt;br&gt;
Now lets make the test fail, go ahead and change line 78, lets say "zzGoogle", build,
and rerun the test. &amp;#160;We now have a failing test. &amp;#160;Go ahead and change
it back so that we have a single passing test.&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-18.png" alt="name project"&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h4&gt;Create a source control repository&lt;/h4&gt;
&lt;p&gt;In this article we will be focusing on the functional testing component of this pipeline. We will proceed on the assumption that your code has already been, built unit tested and deployed to a Functional Test environment. Today we will;Firstly we will prepare for our UI tests by setting up a Selenium server.This machine will be designated for performing the UI tests against, preferably this will be a machine separate from your ContinuaCI server.Log into the machine you have chosen for the Selenium server with administrator privilegesDownload and install Mozilla Firefox (getfirefox.com), this will be the browser that we target as part of this example, however Selenium can target lots of other browsers. For a full breakdown please &lt;a href="http://docs.seleniumhq.org/about/platforms.jsp"&gt;
see the docs page&lt;/a&gt; : .Download Selenium Server ( &lt;a href="http://docs.seleniumhq.org/download"&gt;docs.seleniumhq.org/download&lt;/a&gt; ), at the time of writing the latest version is 2.41.0.Place it into a permanent location of you choosing, in our example ("C:\Program Files (x86)\SeleniumServer")Download NSSM ( &lt;a href="http://nssm.cc/download"&gt;nssm.cc/download&lt;/a&gt; ), unzip it and place into a permanent location of you choosing "C:\Program Files (x86)\nssm-2.22\"Ensure that port 4444 is set to allow traffic (this is the default communications port for Selenium)Open a console and run the following commands:In order to uninstall the Selenium server service, the following commands can be run:Create a new class library project in Visual Studio, lets call it 'tests'Open the Nuget Package Manager Console window (tools menu-&amp;gt; library package manager -&amp;gt; package manager console), select the test project as the default project and run the following script:Install-Package Selenium.Automation.FrameworkInstall-Package Selenium.WebDriverInstall-Package Selenium.SupportInstall-Package NUnitInstall-Package NUnit.RunnersCreate a new class called within the tests project (lets call it tests) and place the below code (Note: line 23 should be changed with location to the Selenium-Server we setup in the previous step):Build the solutionOpen NUnit build runner (by default this is located at ~\packages\NUnit.Runners.2.6.3\tools\nunit.exe) , Select file -&amp;gt; Open Project, and locate the tests dll that you have build in the previous stepclick the run button~ 15 seconds or so you should have one green test!So what just happened? Behind the scenes an instance of firefox was opened (on the Selenium Server), perform a simple google search query and undertook a simple Nunit assertion has verified the name of the window was equal to "Google", very cool!.Now lets make the test fail, go ahead and change line 78, lets say "zzGoogle", build, and rerun the test. We now have a failing test. Go ahead and change it back so that we have a single passing test.&lt;/p&gt;&lt;p&gt;In this example, we're using mercurial&lt;/p&gt;
&lt;p&gt;open a command prompt at ~\&lt;/p&gt;&lt;br&gt;
&lt;p&gt;type "hg init"&lt;/p&gt;&lt;br&gt;
&lt;p&gt;add a .hgignore file into the directory. &amp;#160;For&amp;#160;convenience&amp;#160;we have
prepared one for you&amp;#160;&lt;/p&gt;&lt;a https: www.finalbuilder.com portals 0 articleimages blogimages peter .hgignore.txt&gt;here&lt;/a&gt;&amp;#160;&lt;br&gt;
&lt;p&gt;type "hg add"&lt;/p&gt;&lt;br&gt;
&lt;p&gt;type "hg commit -m "initial commit""&lt;/p&gt;
&lt;br&gt;
&lt;h2&gt;Step 4: Setting up Automated UI testing in ContinuaCI&lt;/h2&gt;
Navigate to the ContinuaCI web interface
&lt;br&gt;
&lt;br&gt;
&lt;h4&gt;
Create a project&lt;/h4&gt;
&lt;br&gt;
Open ContinuaCI&lt;br&gt;
Select "Create Project" from the top tasks dropdown menu&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-1.png" alt="create project"&gt;&lt;br&gt;
&lt;br&gt;
Name the project something memerable; &amp;#160;In our case: "pete sel test 1"&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-3.png" alt="name project"&gt;&lt;br&gt;
Click the "Save &amp;amp; Complete Wizard" button&lt;br&gt;
&lt;br&gt;
&lt;h4&gt;
Create a configuration for this project&lt;/h4&gt;
&lt;br&gt;
Click "Create a Configuration"&lt;br&gt;
Name the config something memorable; in our case "sel-testconfig-1"&lt;br&gt;
Click save &amp;amp; Continue&lt;br&gt;
Click the 'Enable now' link at the bottom of the page to enable this configuration&lt;br&gt;
&lt;br&gt;
&lt;h4&gt;
Point to our Repository&lt;/h4&gt;
&lt;br&gt;
under the section "Configuration Repositories", select the "Create" link&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-4.png" alt="name project"&gt;&lt;br&gt;
&lt;br&gt;
Name the repository "test_repo"&lt;br&gt;
Select "Mercurial" from the "type" dropdown list&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-6.png" alt="name project"&gt;&lt;br&gt;
&lt;br&gt;
Select the Mercurial" tab from the top of the dialogue box&lt;br&gt;
Enter the repository location under "source path" &amp;#160;in our case '\\machinename\c$\sel-blog-final'&lt;br&gt;
Click validate to ensure all is well&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-8.png" alt="name project"&gt;&lt;br&gt;
&lt;br&gt;
Click save, your repository is now ready to go!&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-9.png" alt="name project"&gt;&lt;br&gt;
&lt;h4&gt;
Add actions to our build&lt;/h4&gt;
&lt;br&gt;
Click on the Stages tab&lt;br&gt;
We will add a nuget restore action, click on the "Nuget" section from the categories
on the left&lt;br&gt;
Drag and drop the action "Nuget Restore" onto the design surface&lt;br&gt;
Enter the location of the solution file: "$Source.test_repo$\tests.sln"&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-11.png" alt="name project"&gt;&lt;br&gt;
&lt;br&gt;
Click Save&lt;br&gt;
&amp;#160;&lt;br&gt;
&lt;h4&gt;
Build our tests&lt;/h4&gt;
&lt;br&gt;
Click on the "Build runners" category from the categories on the left hand menu&lt;br&gt;
Drag and drop a Visual Studio action onto the design surface (note that the same
outcome can be achieved here with an MSBuild action).&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-19.png" alt="name project"&gt;&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-13.png" alt="name project"&gt;&lt;br&gt;
&lt;br&gt;
Enter the name of the solution file: "$Source.test_repo$\tests.sln"&lt;br&gt;
Specify that this should be a 'Release' build under the configuration option&lt;br&gt;
Click save&lt;br&gt;
&lt;br&gt;
&lt;h4&gt;
Setup ContinuaCI to run our Nunit tests&lt;/h4&gt;
&lt;br&gt;
Select the 'unit testing' category from the left hand menu&lt;br&gt;
Drag and drop an NUnit action onto the design surface&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-20.png" alt="name project"&gt;&lt;br&gt;
&lt;br&gt;
Name our action 'run UI tests'&lt;br&gt;
Within the files: option, specify the name of the tests project '$Source.test_repo$\tests\tests.csproj'&lt;br&gt;
Within the Project Configuration section specify 'Release'&lt;br&gt;
Specify which version of NUnit&lt;br&gt;
In order to provide greater configuration flexibility &amp;#160;we can pass in the location
of our Selenium server to the tests at runtime.&amp;#160; This is done within the 'Environments'
tab. &amp;#160;In our case the location of the Selenium server is&lt;p&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;http://SELSERVER:4444/wd/hub&lt;/p&gt;&lt;p&gt;.&lt;/p&gt;&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-24.png" alt="environment tab"&gt;&lt;br&gt;
&lt;br&gt;
Click Save&lt;br&gt;
&lt;br&gt;
Click save and complete Wizard
&lt;br&gt;
We are now ready to build!&lt;br&gt;
&lt;br&gt;
Start a build immediately by clicking the top right hand side fast forward icon&amp;#160;&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-14.png" alt="name project"&gt;&lt;br&gt;
A build will start, and complete!&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-15.png" alt="name project"&gt;&lt;br&gt;
When viewing the build log (this can be done by clicking on the green build number,
then selecting the log tab) we can see that our UI tests have been run successfully.
&amp;#160;They are also visible within the 'Unit Tests' tab which displays further metrics
around the tests.&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-23.png" alt="name project"&gt;&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-22.png" alt="name project"&gt;
&lt;h2&gt;
Step 5: Getting more advanced&lt;/h2&gt;
&lt;p&gt;Navigate to the ContinuaCI web interfaceOpen ContinuaCISelect "Create Project" from the top tasks dropdown menuName the project something memerable; In our case: "pete sel test 1"Click the "Save &amp;amp; Complete Wizard" buttonClick "Create a Configuration"Name the config something memorable; in our case "sel-testconfig-1"Click save &amp;amp; ContinueClick the 'Enable now' link at the bottom of the page to enable this configurationunder the section "Configuration Repositories", select the "Create" linkName the repository "test_repo"Select "Mercurial" from the "type" dropdown listSelect the Mercurial" tab from the top of the dialogue boxEnter the repository location under "source path" in our case '\\machinename\c$\sel-blog-final'Click validate to ensure all is wellClick save, your repository is now ready to go!Click on the Stages tabWe will add a nuget restore action, click on the "Nuget" section from the categories on the leftDrag and drop the action "Nuget Restore" onto the design surfaceEnter the location of the solution file: "$Source.test_repo$\tests.sln"Click SaveClick on the "Build runners" category from the categories on the left hand menuDrag and drop a Visual Studio action onto the design surface (note that the same outcome can be achieved here with an MSBuild action).Enter the name of the solution file: "$Source.test_repo$\tests.sln"Specify that this should be a 'Release' build under the configuration optionClick saveSelect the 'unit testing' category from the left hand menuDrag and drop an NUnit action onto the design surfaceName our action 'run UI tests'Within the files: option, specify the name of the tests project '$Source.test_repo$\tests\tests.csproj'Within the Project Configuration section specify 'Release'Specify which version of NUnitIn order to provide greater configuration flexibility we can pass in the location of our Selenium server to the tests at runtime. This is done within the 'Environments' tab. In our case the location of the Selenium server isClick SaveClick save and complete WizardWe are now ready to build!Start a build immediately by clicking the top right hand side fast forward iconA build will start, and complete!When viewing the build log (this can be done by clicking on the green build number, then selecting the log tab) we can see that our UI tests have been run successfully. They are also visible within the 'Unit Tests' tab which displays further metrics around the tests.&lt;/p&gt;&lt;p&gt;
Lets try a slightly more advanced example. &amp;#160;This time we will examine a common
use case. &amp;#160;A physical visual inspection test needs to be conducted before a
release can progress in the pipeline.&lt;br&gt;
&lt;br&gt;
Place the following code within our test class.&lt;br&gt;
&lt;br&gt;
&lt;/p&gt;
&lt;pre class="brush: c#; toolbar:true"&gt;using System;
using System.Text;
using NUnit.Framework;
using OpenQA.Selenium.Firefox;
using OpenQA.Selenium;
using OpenQA.Selenium.Remote;
using OpenQA.Selenium.Support.UI;

namespace SeleniumTests
{
    [TestFixture]
    public class test
    {
        private RemoteWebDriver driver;
       

        [SetUp]
        public void SetupTest()
        {

            // Look for an environment variable
            string server = null;
            server = System.Environment.GetEnvironmentVariable("SELENIUM_SERVER");
            if (server == null)
            {
                server = "http:// *** PUT THE NAME OF YOUR SERVER HERE ***:4444/wd/hub";
            }
            
            // Remote testing
            driver = new RemoteWebDriver(new Uri(server), DesiredCapabilities.Firefox());
        }

        [TearDown]
        public void TeardownTest()
        {
            try
            {
                driver.Quit();
            }
            catch (Exception)
            {
                // Ignore errors if unable to close the browser
            }
        }

        [Test]
        public void FirstSeleniumTest()
        {
            driver.Navigate().GoToUrl("http://www.google.com/");
            IWebElement query = driver.FindElement(By.Name("q"));
            query.SendKeys("a test");
            Assert.AreEqual(driver.Title, "Google"); 
        }
        [Test]
        public void MySecondSeleniumTest()
        {
            // Navigate to google
            driver.Navigate().GoToUrl("http://www.google.com/");
            IWebElement query = driver.FindElement(By.Name("q"));
            
            // Write a query into the window
            query.SendKeys("a test");

            // wait at maximum ten seconds for results to display
            var wait = new WebDriverWait(driver, TimeSpan.FromSeconds(10));
            IWebElement myDynamicElement = wait.Until&amp;lt; IWebElement &amp;gt;((d) =&amp;gt;
            {
                return d.FindElement(By.Id("ires"));
            });

            // take a screenshot of the result for visual verification
            var fileName = TestContext.CurrentContext.Test.Name + "-" + string.Format("{0:yyyyMMddHHmmss}", DateTime.Now) + ".png";
            driver.GetScreenshot().SaveAsFile(fileName, System.Drawing.Imaging.ImageFormat.Png);

            // perform an code assertion
            Assert.AreEqual(driver.Title, "Google");          
        }
    }
}
&lt;/pre&gt;
&lt;br&gt;
&lt;br&gt;
Build, and run the test. &amp;#160;&lt;br&gt;
&lt;br&gt;
In this example we added an additional test to perform a google search, wait at
maximum 10 seconds for &amp;#160;results to display, take a screenshot (stored it to
disk), and perform an NUnit assertion. &amp;#160;The screenshot output from the test
can be made available as an artifact within Continua!
&lt;br&gt;
&lt;br&gt;
Firstly lets commit our changes; "hg commit -m "added a more advanced test""&lt;br&gt;
&lt;br&gt;
Open the configuration in Continua CI (clicking the pencil icon)&lt;br&gt;
Navigate to the stages section&amp;#160;&lt;br&gt;
Double click on the stage name (which will bring up the edit stage Dialogue box)&amp;#160;&lt;br&gt;
Click on the Workspace rules tab&lt;br&gt;
Add the following line to the bottom of the text area: "/ &amp;lt; $Source.test_repo$/tests/bin/Release/**.png".
&amp;#160;This will tell Continua to return any .png files that we produced from this
test back to the ContinuaCI Server.&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-25.png" alt="name project"&gt;&lt;br&gt;
&lt;br&gt;
Click on the artifacts tab.&lt;br&gt;
Add the following line : **.png" &amp;#160;This will enable any .png files within
the workspace to be picked up and displayed within the Artifacts tab.&lt;br&gt;
**.png&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-26.png" alt="name project"&gt;&lt;br&gt;
&lt;br&gt;
Click save&lt;br&gt;
Click Save &amp;amp; Complete Wizard&lt;br&gt;
Start a new build&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-14.png" alt="name project"&gt;&lt;br&gt;
&lt;br&gt;
Sweet! &amp;#160;A screenshot of our test was produced, and can be seen within the Artifacts
tab! &amp;#160; &amp;#160;&amp;#160;&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-27.png" alt="name project"&gt;&lt;br&gt;
Clicking on 'View' will display the image: &amp;#160;&lt;br&gt;
&lt;br&gt;
&lt;img src="/Portals/0/ArticleImages/BlogImages/peter/create-project-28.png" alt="name project"&gt;&lt;br&gt;
&amp;#160;&lt;br&gt;
&lt;p&gt;We have put the sourcecode of this article up on&amp;#160;&lt;/p&gt;&lt;a href="https://github.com/VSoftTechnologies/Automated-UI-Testing"&gt;Github&lt;/a&gt;&lt;p&gt;.&lt;br&gt;
&lt;/p&gt;
&lt;br&gt;
Please subscribe and comment! &amp;#160;We are very excited to see what you guys come
up with on Continua, happy testing!
&lt;br&gt;
&lt;br&gt;
&lt;h4&gt;
Some additional considerations:&lt;/h4&gt;
&lt;br&gt;
&lt;ul&gt;
    &lt;li&gt;
    &lt;li&gt;The user which the Selenium service runs under should have correct privileges&lt;/li&gt;
    &lt;li&gt;The machine designated as the Selenium server may require access to the internet
    if your webapp has upstream dependencies (eg third party API's like github)&lt;/li&gt;
    &lt;li&gt;
    &lt;li&gt;
    &lt;li&gt;&amp;#160;&amp;#160;&lt;/li&gt;
&lt;/ul&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;p&gt;Build, and run the test.In this example we added an additional test to perform a google search, wait at maximum 10 seconds for results to display, take a screenshot (stored it to disk), and perform an NUnit assertion. The screenshot output from the test can be made available as an artifact within Continua!Firstly lets commit our changes; "hg commit -m "added a more advanced test""Open the configuration in Continua CI (clicking the pencil icon)Navigate to the stages sectionDouble click on the stage name (which will bring up the edit stage Dialogue box)Click on the Workspace rules tabAdd the following line to the bottom of the text area: "/ &lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 23 Jul 2016 05:52:06 +0800</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-23:automated-ui-testing-done-right-with-continuaci.html</guid></item><item><title>Blue Ocean July development update</title><link>http://ciandcd.github.io/blue-ocean-july-development-update.html</link><description>From:&lt;a href="http://feedproxy.google.com/~r/ContinuousBlog/~3/5dLOYMEMF9w/"&gt;http://feedproxy.google.com/~r/ContinuousBlog/~3/5dLOYMEMF9w/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;The team have been hard at work moving the needle forward on the Blue Ocean 1.0 features. Many of the features we have been working on have come a long way in the past few months but here&amp;#8217;s a few highlights:&lt;/p&gt;&lt;p&gt;SSE is a great technology choice for new web apps as it only pushes out events to the client when things have changed on the server. That means there&amp;#8217;s a lot less traffic going between your browser and the Jenkins server when compared to the continuous AJAX polling method that has been typical of Jenkins in the past.&lt;/p&gt;&lt;p&gt;Building upon Tom 's great work on Server Sent Events (SSE) both Cliff and Tom worked on making the all the screens in Blue Ocean update without manual refreshes.&lt;/p&gt;&lt;p&gt;Keith has been working with Vivek to drive out a new set of extension points that allow us to build a new rest reporting UI in Blue Ocean. Today this works for JUnit test reports but can be easily extended to work with other kinds of reports.&lt;/p&gt;&lt;p&gt;Thorsten and Josh have been hard at work breaking down the log into steps and making the live log tailing follow the pipeline execution - which we&amp;#8217;ve lovingly nicknamed the &amp;#8220;karaoke mode&amp;#8221;&lt;/p&gt;&lt;p&gt;Tom has been on allowing users to trigger jobs from Blue Ocean, which is one less reason to go back to the Classic UI :)&lt;/p&gt;&lt;p&gt;Many of you have asked us questions about how you can try Blue Ocean
today and have resorted to building the plugin yourself or running our
Docker image.&lt;/p&gt;
&lt;p&gt;We wanted to make the process of trying Blue Ocean in its unfinished
state by publishing the plugin to the experimental update center - it&amp;#8217;s
available today!&lt;/p&gt;
&lt;p&gt;So what is the Experimental Update Center? It is a mechanism for the
Jenkins developer community to share early previews of new plugins with
the broader user community. Plugins in this update center are
experimental and we strongly advise not running them on production or
Jenkins systems that you rely on for your work.&lt;/p&gt;
&lt;p&gt;That means any plugin in this update center could eat your Jenkins data,
cause slowdowns, degrade security or have their behavior change at no
notice.&lt;/p&gt;
&lt;p&gt;You can learn how to
&lt;a http: feedproxy.google.com blog 2013 09 23 experimental-plugins-update-center /&gt;activate
the experimental update center on this post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Stay tuned for more updates!&lt;/p&gt;
&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Tue, 19 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-19:blue-ocean-july-development-update.html</guid><category>jenkins</category></item><item><title>Sending Notifications in Pipeline</title><link>http://ciandcd.github.io/sending-notifications-in-pipeline.html</link><description>From:&lt;a href="http://feedproxy.google.com/~r/ContinuousBlog/~3/svzD4AgT-Us/"&gt;http://feedproxy.google.com/~r/ContinuousBlog/~3/svzD4AgT-Us/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;I thing we can all agree getting notified when events occur is preferable to
having to constantly monitor them just in case.  I&amp;#8217;m going to continue from
where I left off in my
&lt;a http: feedproxy.google.com blog 2016 07 01 html-publisher-plugin /&gt;previous post&lt;/a&gt; with the
&lt;a href="https://github.com/reiseburo/hermann"&gt;hermann&lt;/a&gt; project.  I added a Jenkins
Pipeline with an HTML publisher for code coverage. This week, I&amp;#8217;d like to make
Jenkins to notify me when builds start and when they succeed or fail.&lt;/p&gt;
&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Mon, 18 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-18:sending-notifications-in-pipeline.html</guid><category>jenkins</category></item><item><title>New packages for Jenkins 2.7.1</title><link>http://ciandcd.github.io/new-packages-for-jenkins-271.html</link><description>From:&lt;a href="http://feedproxy.google.com/~r/ContinuousBlog/~3/w9oVEycgQZU/"&gt;http://feedproxy.google.com/~r/ContinuousBlog/~3/w9oVEycgQZU/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;We created new native packages for Jenkins 2.7.1 today. These replace the existing packages. Due to a release process issue, the packaging (RPM, etc.) was created the same way as Jenkins 1.x LTS, resulting in problems starting Jenkins on some platforms: While we dropped support for AJP in Jenkins 2.0, some 1.x packages had it enabled by default, resulting in an exception during startup.&lt;/p&gt;

&lt;p&gt;These new packages for Jenkins 2.7.1, dated July 14, have the same scripts and parameters as Jenkins 2.x and should allow starting up Jenkins without problems. If you notice any further problems with the packaging, please &lt;a href="https://wiki.jenkins-ci.org/display/JENKINS/How+to+report+an+issue"&gt;report&lt;/a&gt; them in the &lt;code&gt;packaging&lt;/code&gt; component.&lt;/p&gt;

&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Thu, 14 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-14:new-packages-for-jenkins-271.html</guid><category>jenkins</category></item><item><title>Jenkins 2 hits LTS</title><link>http://ciandcd.github.io/jenkins-2-hits-lts.html</link><description>From:&lt;a href="http://feedproxy.google.com/~r/ContinuousBlog/~3/J9Mf0dutW_E/"&gt;http://feedproxy.google.com/~r/ContinuousBlog/~3/J9Mf0dutW_E/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;h1&gt;
&lt;a http: feedproxy.google.com blog 2016 07 07 jenkins-2 title="Jenkins 2 hits LTS"&gt;
Jenkins 2 hits LTS
&lt;/a&gt;
&lt;/h1&gt;
 
&lt;a class="twitter-share-button" href="https://twitter.com/share"&gt;
Tweet
&lt;/a&gt;
&lt;p class="submitted"&gt;
Published on
2016-07-07
by
kohsuke
&lt;/p&gt;
&lt;p&gt;It&amp;#8217;s been almost three months since we&amp;#8217;ve released &lt;a href="https://jenkins.io/2.0/"&gt;Jenkins 2.0&lt;/a&gt;, the first ever major version upgrade for this 10 year old project. The 2.x versions since then has been adopted by more than 20% of the users, but one segment of users who haven&amp;#8217;t seen the benefits of Jenkins 2 is those who has been running LTS releases.&lt;/p&gt;
&lt;p&gt;But that is no more! The new version of Jenkins LTS release we just released is 2.7.1, and now LTS users get to finally enjoy Jenkins 2.&lt;/p&gt;
&lt;p&gt;This release also officially marks the end-of-life for Jenkins 1.x. There won&amp;#8217;t be any future release of Jenkins 1.x beyond this point. If you are worried about the upgrade, don&amp;#8217;t be! The core of Jenkins is still the same, and all the plugins &amp;amp; existing configuration will just work.&lt;/p&gt;
&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Thu, 07 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-07:jenkins-2-hits-lts.html</guid><category>jenkins</category></item><item><title>Publishing HTML Reports in Pipeline</title><link>http://ciandcd.github.io/publishing-html-reports-in-pipeline.html</link><description>From:&lt;a href="http://feedproxy.google.com/~r/ContinuousBlog/~3/WZrkjtfbi7k/"&gt;http://feedproxy.google.com/~r/ContinuousBlog/~3/WZrkjtfbi7k/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Most projects need more that just JUnit result reporting. Rather than writing a custom plugin for each type of report, we can use the HTML Publisher Plugin .&lt;/p&gt;&lt;p&gt;I&amp;#8217;ve found a Ruby project, hermann , I&amp;#8217;d like to build using Jenkins Pipeline. I&amp;#8217;d also like to have the code coverage results published with each build job. I could write a plugin to publish this data, but I&amp;#8217;m in a bit of hurry and the build already creates an HTML report file using SimpleCov when the unit tests run.&lt;/p&gt;&lt;p&gt;Now I just need to add the step to publish the code coverage report. I know that rake spec creates an index.html file in the coverage directory. I&amp;#8217;ve already installed the HTML Publisher Plugin . How do I add the HTML publishing step to the pipeline? The plugin page doesn&amp;#8217;t say anything about it.&lt;/p&gt;&lt;p&gt;I&amp;#8217;m going to use the HTML Publisher Plugin to add the HTML-formatted code coverage report to my builds. Here&amp;#8217;s a simple pipeline for building the hermann project.&lt;/p&gt;&lt;p&gt;Then it shows me a UI similar to the one used in job configuration. I fill in the fields, click "generate", and it shows me snippet of groovy generated from that input.&lt;/p&gt;&lt;p&gt;Documentation is hard to maintain and easy to miss, even more so in a system like Jenkins with hundreds of plugins the each potential have one or more groovy fixtures to add to the Pipeline. The Pipeline Syntax Snippet Generator helps users navigate this jungle by providing a way to generate a code snippet for any step using provided inputs.&lt;/p&gt;&lt;h3 id="html-published"&gt;&lt;a class="anchor" href="#html-published"&gt;&lt;/a&gt;HTML Published&lt;/h3&gt;
&lt;p&gt;I can use that snippet directly or as a template for further customization.
In this case, I&amp;#8217;ll just reformat and copy it in at the end of my
pipeline.  (I ran into a &lt;a href="https://issues.jenkins-ci.org/browse/JENKINS-29711"&gt;minor bug&lt;/a&gt;
in the snippet generated for this plugin step. Typing
error string in my search bar immediately found the bug and a workaround.)&lt;/p&gt;
&lt;pre class="CodeRay highlight nowrap"&gt;&lt;code&gt;  &lt;p&gt;/* ...unchanged... */&lt;/p&gt;

  &lt;p&gt;// Archive the built artifacts&lt;/p&gt;
  archive (&lt;p&gt;includes&lt;/p&gt;: &lt;p&gt;&lt;p&gt;'&lt;/p&gt;&lt;p&gt;pkg/*.gem&lt;/p&gt;&lt;p&gt;'&lt;/p&gt;&lt;/p&gt;)

  &lt;p&gt;// publish html&lt;/p&gt;
  &lt;p&gt;// snippet generator doesn't include "target:"&lt;/p&gt;
  &lt;p&gt;// https://issues.jenkins-ci.org/browse/JENKINS-29711.&lt;/p&gt;
  publishHTML (&lt;p&gt;target&lt;/p&gt;: [
      &lt;p&gt;allowMissing&lt;/p&gt;: &lt;p&gt;false&lt;/p&gt;,
      &lt;p&gt;alwaysLinkToLastBuild&lt;/p&gt;: &lt;p&gt;false&lt;/p&gt;,
      &lt;p&gt;keepAll&lt;/p&gt;: &lt;p&gt;true&lt;/p&gt;,
      &lt;p&gt;reportDir&lt;/p&gt;: &lt;p&gt;&lt;p&gt;'&lt;/p&gt;&lt;p&gt;coverage&lt;/p&gt;&lt;p&gt;'&lt;/p&gt;&lt;/p&gt;,
      &lt;p&gt;reportFiles&lt;/p&gt;: &lt;p&gt;&lt;p&gt;'&lt;/p&gt;&lt;p&gt;index.html&lt;/p&gt;&lt;p&gt;'&lt;/p&gt;&lt;/p&gt;,
      &lt;p&gt;reportName&lt;/p&gt;: &lt;p&gt;&lt;p&gt;"&lt;/p&gt;&lt;p&gt;RCov Report&lt;/p&gt;&lt;p&gt;"&lt;/p&gt;&lt;/p&gt;
    ])

}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When I run this new pipeline I am rewarded with an &lt;code&gt;RCov Report&lt;/code&gt; link on left side,
which I can follow to show the HTML report.&lt;/p&gt;
&lt;img src="/images/post-images/2016-06-30/run-2.png" alt="Job Run With Report Link"&gt;&lt;img src="/images/post-images/2016-06-30/rcov.png" alt="RCov Report"&gt;&lt;p&gt;I even added the &lt;code&gt;keepAll&lt;/code&gt; setting to let I can also go back an look at reports on old jobs as
more come in.  As I said to to begin with, this is not as slick as what I
could do with a custom plugin, but it is much easier and works with any static
HTML.&lt;/p&gt;
&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Fri, 01 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-07-01:publishing-html-reports-in-pipeline.html</guid><category>jenkins</category></item><item><title>External Workspace Manager Plugin alpha version</title><link>http://ciandcd.github.io/external-workspace-manager-plugin-alpha-version.html</link><description>From:&lt;a href="http://feedproxy.google.com/~r/ContinuousBlog/~3/uz3BMcwgrOI/"&gt;http://feedproxy.google.com/~r/ContinuousBlog/~3/uz3BMcwgrOI/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Currently it&amp;#8217;s quite difficult to share and reuse the same workspace between multiple jobs and across nodes.
There are some possible workarounds for achieving this, but each of them has its own drawback,
e.g. stash/unstash pre-made artifacts, Copy Artifacts plugin or advanced job settings.
A viable solution for this problem is the External Workspace Manager plugin, which facilitates workspace share and
reuse across multiple Jenkins jobs and nodes.
It also eliminates the need to copy, archive or move files.
You can learn more about the design and goals of the External Workspace Manager project in
&lt;a http: feedproxy.google.com blog 2016 05 23 external-workspace-manager-plugin /&gt;this introductory blog post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I&amp;#8217;d like to announce that an alpha version of the External Manager Plugin has been released!
It&amp;#8217;s now public available for testing.
To be able to install this plugin, you must follow the steps from the Experimental Plugins Update Center
&lt;a http: feedproxy.google.com blog 2013 09 23 experimental-plugins-update-center /&gt;blog post&lt;/a&gt;.&lt;/p&gt;

&lt;i class="fa icon-note" title="Note"&gt;&lt;/i&gt;


Please be aware that it&amp;#8217;s not recommended to use the Experimental Update Center in production installations of
Jenkins, since it may break it.

&lt;p&gt;The plugin&amp;#8217;s wiki page may be accessed
&lt;a href="https://wiki.jenkins-ci.org/display/JENKINS/External+Workspace+Manager+Plugin"&gt;here&lt;/a&gt;.
The documentation that helps you get started with this plugin may be found on the
&lt;a href="https://github.com/jenkinsci/external-workspace-manager-plugin/blob/master/README.md"&gt;README&lt;/a&gt; page.
To get an idea of what this plugin does, which are the features implemented so far and to see a working demo of it,
you can watch my mid-term presentation that is available &lt;a href="https://youtu.be/u4zhxfUT8P4?t=22m7s"&gt;here&lt;/a&gt;.
The slides for the presentation are shared on
&lt;a href="https://docs.google.com/presentation/d/1ZCYSIR2Tg466Ij1ghH5LSc8DLBCxWjIaD9IJcOyMZwU/edit?usp=sharing"&gt;Google Slides&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;My mentors, &lt;a href="https://github.com/martinda"&gt;Martin&lt;/a&gt; and &lt;a href="https://github.com/oleg-nenashev"&gt;Oleg&lt;/a&gt;,
and I have set up public meetings related to this plugin.
You are invited to join our discussions if you&amp;#8217;d like to get more insight about the project.
The meetings are taking place twice a week on the &lt;a http: feedproxy.google.com hangout&gt;Jenkins hangout&lt;/a&gt;,
every Monday at
&lt;a href="http://www.timeanddate.com/worldclock/fixedtime.html?msg=External+Workspace+Manager+Plugin+(Mondays+weekly+recurring)&amp;amp;iso=20160606T12&amp;amp;p1=1440&amp;amp;ah=1"&gt;12 PM UTC&lt;/a&gt;
and every Thursday at
&lt;a href="http://www.timeanddate.com/worldclock/fixedtime.html?msg=External+Workspace+Manager+Plugin+(Thursdays+weekly+recurring)&amp;amp;iso=20160609T05&amp;amp;p1=1440&amp;amp;ah=1"&gt;5 PM UTC&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you have any issues in setting up or using the plugin, please feel free to ask me on the plugin&amp;#8217;s Gitter
&lt;a href="https://gitter.im/jenkinsci/external-workspace-manager-plugin"&gt;chat&lt;/a&gt;.
The plugin is open-source, having the repository on
&lt;a href="https://github.com/jenkinsci/external-workspace-manager-plugin"&gt;GitHub&lt;/a&gt;, and you may contribute to it.
Any feedback is welcome, and you may provide it either on the Gitter chat, or on
&lt;a href="https://issues.jenkins-ci.org"&gt;Jira&lt;/a&gt; by using the external-workspace-manager-plugin component.&lt;/p&gt;
&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Thu, 30 Jun 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-06-30:external-workspace-manager-plugin-alpha-version.html</guid><category>jenkins</category></item><item><title>Migrating from chained Freestyle jobs to Pipelines</title><link>http://ciandcd.github.io/migrating-from-chained-freestyle-jobs-to-pipelines.html</link><description>From:&lt;a href="http://feedproxy.google.com/~r/ContinuousBlog/~3/w0VIYgV6amg/"&gt;http://feedproxy.google.com/~r/ContinuousBlog/~3/w0VIYgV6amg/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;
&lt;i class="fa icon-note" title="Note"&gt;&lt;/i&gt;


&lt;p&gt;This is a guest post by &lt;a href="https;//github.com/rtyler"&gt;R. Tyler Croy&lt;/a&gt;, who is a
long-time contributor to Jenkins and the primary contact for Jenkins project
infrastructure. He is also a Jenkins Evangelist at
&lt;a href="http://cloudbees.com"&gt;CloudBees, Inc.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;For ages I have used the "Build After" feature in Jenkins to cobble together
what one might refer to as a "pipeline" of sorts. The Jenkins project itself, a
major consumer of Jenkins, has used these daisy-chained Freestyle jobs to drive
a myriad of delivery pipelines in our infrastructure.&lt;/p&gt;
&lt;p&gt;One such "pipeline" helped drive the complex process of generating the pretty
blue charts on
&lt;a href="http://stats.jenkins-ci.org/jenkins-stats/svg/svgs.html"&gt;stats.jenkins-ci.org&lt;/a&gt;.
This statistics generation process primarily performs two major tasks, on rather
large sets of data:&lt;/p&gt;
&lt;ol class="arabic"&gt;&lt;li&gt;
&lt;p&gt;Generate aggregate monthly "census data."&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Process the census data and create trend charts&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;The chained jobs allowed us to resume the independent stages of the pipeline,
and allowed us to run different stages on different hardware (different
capabilities) as needed. Below is a diagram of what this looked like:&lt;/p&gt;
&lt;img src="/images/post-images/freestyle-to-pipeline-2016/freestyle-pipeline.png" alt="freestyle pipeline"&gt;&lt;p&gt;The &lt;code&gt;infra_generate_monthly_json&lt;/code&gt; would run periodically creating the
aggregated census data, which would then be picked up by &lt;code&gt;infra_census_push&lt;/code&gt;
whose sole responsibility was to take census data and publish it to the
necessary hosts inside the project&amp;#8217;s infrastructure.&lt;/p&gt;
&lt;p&gt;The second, semi-independent, "pipeline" would also run periodically. The
&lt;code&gt;infra_statistics&lt;/code&gt; job&amp;#8217;s responsibility was to use the census data, pushed
earlier by &lt;code&gt;infra_census_push&lt;/code&gt;, to generate the myriad of pretty blue charts
before triggering the
&lt;code&gt;infra_checkout_stats&lt;/code&gt; job which would make sure &lt;code&gt;stats.jenkins-ci.org&lt;/code&gt; was
properly updated.&lt;/p&gt;
&lt;p&gt;Suffice it to say, this "pipeline" had grown organically over a period time when
&lt;a http: feedproxy.google.com doc pipeline&gt;more advanced tools&lt;/a&gt; weren&amp;#8217;t quite available.&lt;/p&gt;
&lt;p&gt;When we migrated to newer infrastructure for
&lt;a href="https://ci.jenkins.io"&gt;ci.jenkins.io&lt;/a&gt; earlier this year I took the
opportunity to do some cleaning up. Instead of migrating jobs verbatim, I pruned
stale jobs and refactored a number of others into proper
&lt;a http: feedproxy.google.com solutions pipeline&gt;Pipelines&lt;/a&gt;, statistics generation being an obvious
target!&lt;/p&gt;
&lt;p&gt;Our requirements for statistics generation, in their most basic form, are:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;
&lt;p&gt;Enable a sequence of dependent tasks to be executed as a logical group (a
pipeline)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Enable executing those dependent tasks on various pieces of infrastructure
which support different requirements&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Actually generate those pretty blue charts&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;i class="fa icon-note" title="Note"&gt;&lt;/i&gt;


&lt;p&gt;If you wish to skip ahead, you can jump straight to the
&lt;a href="https://github.com/jenkins-infra/infra-statistics/blob/a6dcaa29fca9a4f61143954fb9e1300c2f995a89/Jenkinsfile"&gt;Jenkinsfile&lt;/a&gt;
which implements our new Pipeline.&lt;/p&gt;

&lt;p&gt;The first iteration of the &lt;code&gt;Jenkinsfile&lt;/code&gt; simply defined the conceptual stages we
would need:&lt;/p&gt;
&lt;pre class="CodeRay highlight nowrap"&gt;&lt;code&gt;node {
    stage &lt;p&gt;&lt;p&gt;'&lt;/p&gt;&lt;p&gt;Sync raw data and census files&lt;/p&gt;&lt;p&gt;'&lt;/p&gt;&lt;/p&gt;

    stage &lt;p&gt;&lt;p&gt;'&lt;/p&gt;&lt;p&gt;Process raw logs&lt;/p&gt;&lt;p&gt;'&lt;/p&gt;&lt;/p&gt;

    stage &lt;p&gt;&lt;p&gt;'&lt;/p&gt;&lt;p&gt;Generate census data&lt;/p&gt;&lt;p&gt;'&lt;/p&gt;&lt;/p&gt;

    stage &lt;p&gt;&lt;p&gt;'&lt;/p&gt;&lt;p&gt;Generate stats&lt;/p&gt;&lt;p&gt;'&lt;/p&gt;&lt;/p&gt;

    stage &lt;p&gt;&lt;p&gt;'&lt;/p&gt;&lt;p&gt;Publish census&lt;/p&gt;&lt;p&gt;'&lt;/p&gt;&lt;/p&gt;

    stage &lt;p&gt;&lt;p&gt;'&lt;/p&gt;&lt;p&gt;Publish stats&lt;/p&gt;&lt;p&gt;'&lt;/p&gt;&lt;/p&gt;
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;How exciting! Although not terrifically useful. When I began actually
implementing the first couple stages, I noticed that the Pipeline might sync
dozens of gigabytes of data every time it ran on a new agent in the cluster.
While this problem will soon be solved by the
&lt;a href="https://github.com/jenkinsci/external-workspace-manager-plugin"&gt;External
Workspace Manager plugin&lt;/a&gt;, which is currently being developed. Until it&amp;#8217;s ready,
I chose to mitigate the issue by pinning the execution to a consistent agent.&lt;/p&gt;
&lt;pre class="CodeRay highlight nowrap"&gt;&lt;code&gt;&lt;p&gt;/* `census` is a node label for a single machine, ideally, which will be
 * consistently used for processing usage statistics and generating census data
 */&lt;/p&gt;
node(&lt;p&gt;&lt;p&gt;'&lt;/p&gt;&lt;p&gt;census &amp;amp;&amp;amp; docker&lt;/p&gt;&lt;p&gt;'&lt;/p&gt;&lt;/p&gt;) {
    &lt;p&gt;/* .. */&lt;/p&gt;
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Restricting a workload which previously used multiple agents to a single one
introduced the next challenge. As an infrastructure administrator, technically
speaking, I could just install all the system dependencies that I want on this
one special Jenkins agent. But what kind of example would that be setting!&lt;/p&gt;
&lt;p&gt;The statistics generation process requires:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;
&lt;p&gt;JDK8&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.groovy-lang.org"&gt;Groovy&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A running &lt;a href="https://www.mongodb.org/"&gt;MongoDB&lt;/a&gt; instance&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Fortunately, with Pipeline we have a couple of useful features at our disposal:
tool auto-installers and the
&lt;a href="https://go.cloudbees.com/docs/cloudbees-documentation/cje-user-guide/chapter-docker-workflow.html"&gt;CloudBees
Docker Pipeline plugin&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="tool-auto-installers"&gt;&lt;a class="anchor" href="#tool-auto-installers"&gt;&lt;/a&gt;Tool Auto-Installers&lt;/h3&gt;
&lt;p&gt;Tool Auto-Installers are exposed in Pipeline through the &lt;code&gt;tool&lt;/code&gt; step and on
&lt;a href="https://ci.jenkins.io"&gt;ci.jenkins.io&lt;/a&gt; we already had JDK8 and Groovy
available. This meant that the &lt;code&gt;Jenkinsfile&lt;/code&gt; would invoke &lt;code&gt;tool&lt;/code&gt; and Pipeline
would automatically install the desired tool on the agent executing the current
Pipeline steps.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;tool&lt;/code&gt; step does not modify the &lt;code&gt;PATH&lt;/code&gt; environment variable, so it&amp;#8217;s usually
used in conjunction with the &lt;code&gt;withEnv&lt;/code&gt; step, for example:&lt;/p&gt;
&lt;pre class="CodeRay highlight nowrap"&gt;&lt;code&gt;node(&lt;p&gt;&lt;p&gt;'&lt;/p&gt;&lt;p&gt;census &amp;amp;&amp;amp; docker&lt;/p&gt;&lt;p&gt;'&lt;/p&gt;&lt;/p&gt;) {
    &lt;p&gt;/* .. */&lt;/p&gt;

    &lt;p&gt;def&lt;/p&gt; javaHome = tool(&lt;p&gt;name&lt;/p&gt;: &lt;p&gt;&lt;p&gt;'&lt;/p&gt;&lt;p&gt;jdk8&lt;/p&gt;&lt;p&gt;'&lt;/p&gt;&lt;/p&gt;)
    &lt;p&gt;def&lt;/p&gt; groovyHome = tool(&lt;p&gt;name&lt;/p&gt;: &lt;p&gt;&lt;p&gt;'&lt;/p&gt;&lt;p&gt;groovy&lt;/p&gt;&lt;p&gt;'&lt;/p&gt;&lt;/p&gt;)

    &lt;p&gt;/* Set up environment variables for re-using our auto-installed tools */&lt;/p&gt;
    &lt;p&gt;def&lt;/p&gt; customEnv = [
        &lt;p&gt;&lt;p&gt;"&lt;/p&gt;&lt;p&gt;PATH+JDK=&lt;/p&gt;&lt;p&gt;&lt;p&gt;${&lt;/p&gt;javaHome&lt;p&gt;}&lt;/p&gt;&lt;/p&gt;&lt;p&gt;/bin&lt;/p&gt;&lt;p&gt;"&lt;/p&gt;&lt;/p&gt;,
        &lt;p&gt;&lt;p&gt;"&lt;/p&gt;&lt;p&gt;PATH+GROOVY=&lt;/p&gt;&lt;p&gt;&lt;p&gt;${&lt;/p&gt;groovyHome&lt;p&gt;}&lt;/p&gt;&lt;/p&gt;&lt;p&gt;/bin&lt;/p&gt;&lt;p&gt;"&lt;/p&gt;&lt;/p&gt;,
        &lt;p&gt;&lt;p&gt;"&lt;/p&gt;&lt;p&gt;JAVA_HOME=&lt;/p&gt;&lt;p&gt;&lt;p&gt;${&lt;/p&gt;javaHome&lt;p&gt;}&lt;/p&gt;&lt;/p&gt;&lt;p&gt;"&lt;/p&gt;&lt;/p&gt;,
    ]

    &lt;p&gt;/* use our auto-installed tools */&lt;/p&gt;
    withEnv(customEnv) {
        sh &lt;p&gt;&lt;p&gt;'&lt;/p&gt;&lt;p&gt;java --version&lt;/p&gt;&lt;p&gt;'&lt;/p&gt;&lt;/p&gt;
    }

    &lt;p&gt;/* .. */&lt;/p&gt;
}&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="cloudbees-docker-pipeline-plugin"&gt;&lt;a class="anchor" href="#cloudbees-docker-pipeline-plugin"&gt;&lt;/a&gt;CloudBees Docker Pipeline plugin&lt;/h3&gt;
&lt;p&gt;Satisfying the MongoDB dependency would still be tricky. If I caved in and installed
MongoDB on a single unicorn agent in the cluster, what could I say the next time
somebody asked for a special, one-off, piece of software installed on our
Jenkins build agents?&lt;/p&gt;
&lt;p&gt;After doing my usual complaining and whining, I discovered that the CloudBees
Docker Pipeline plugin provides the ability to &lt;strong&gt;run containers&lt;/strong&gt; inside of a
&lt;code&gt;Jenkinsfile&lt;/code&gt;. To make things even better, there are
&lt;a href="https://hub.docker.com/_/mongo/"&gt;official MongoDB docker images&lt;/a&gt; readily
available on DockerHub!&lt;/p&gt;
&lt;p&gt;This feature requires that the machine has a running Docker daemon which is
accessible to the user running the Jenkins agent. After that, running a
container in the background is easy, for example:&lt;/p&gt;
&lt;pre class="CodeRay highlight nowrap"&gt;&lt;code&gt;node(&lt;p&gt;&lt;p&gt;'&lt;/p&gt;&lt;p&gt;census &amp;amp;&amp;amp; docker&lt;/p&gt;&lt;p&gt;'&lt;/p&gt;&lt;/p&gt;) {
    &lt;p&gt;/* .. */&lt;/p&gt;

    &lt;p&gt;/* Run MongoDB in the background, mapping its port 27017 to our host's port
     * 27017 so our script can talk to it, then execute our Groovy script with
     * tools from our `customEnv`
     */&lt;/p&gt;
    docker.image(&lt;p&gt;&lt;p&gt;'&lt;/p&gt;&lt;p&gt;mongo:2&lt;/p&gt;&lt;p&gt;'&lt;/p&gt;&lt;/p&gt;).withRun(&lt;p&gt;&lt;p&gt;'&lt;/p&gt;&lt;p&gt;-p 27017:27017&lt;/p&gt;&lt;p&gt;'&lt;/p&gt;&lt;/p&gt;) { container -&amp;gt;
        withEnv(customEnv) {
            sh &lt;p&gt;&lt;p&gt;"&lt;/p&gt;&lt;p&gt;groovy parseUsage.groovy --logs &lt;/p&gt;&lt;p&gt;&lt;p&gt;${&lt;/p&gt;usagestats_dir&lt;p&gt;}&lt;/p&gt;&lt;/p&gt;&lt;p&gt; --output &lt;/p&gt;&lt;p&gt;&lt;p&gt;${&lt;/p&gt;census_dir&lt;p&gt;}&lt;/p&gt;&lt;/p&gt;&lt;p&gt; --incremental&lt;/p&gt;&lt;p&gt;"&lt;/p&gt;&lt;/p&gt;
        }
    }

    &lt;p&gt;/* .. */&lt;/p&gt;
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The beauty, to me, of this example is that you can pass a
&lt;a href="http://www.groovy-lang.org/Closures"&gt;closure&lt;/a&gt; to &lt;code&gt;withRun&lt;/code&gt; which will
execute while the container is running. When the closure is finished executin,
just the &lt;code&gt;sh&lt;/code&gt; step in this case, the container is destroyed.&lt;/p&gt;
&lt;p&gt;With that system requirement satisfied, the rest of the stages of the Pipeline
fell into place. We now have a single source of truth, the
&lt;a href="https://github.com/jenkins-infra/infra-statistics/blob/master/Jenkinsfile"&gt;Jenkinsfile&lt;/a&gt;,
for the sequence of dependent tasks which need to be executed, accounting for
variations in systems requirements, and it actually generates
&lt;a href="http://stats.jenkins-ci.org/jenkins-stats/svg/svgs.html"&gt;those pretty
blue charts&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;Of course, a nice added bonus is the beautiful visualization of our
&lt;a href="https://ci.jenkins.io/job/Infrastructure/job/statistics/"&gt;new Pipeline&lt;/a&gt;!&lt;/p&gt;
&lt;img src="/images/post-images/freestyle-to-pipeline-2016/stats-pipeline.png" alt="The New and Improved Statistics Pipeline"&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Wed, 29 Jun 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-06-29:migrating-from-chained-freestyle-jobs-to-pipelines.html</guid><category>jenkins</category></item><item><title>Continua CI and FinalBuilder integration improvements</title><link>http://ciandcd.github.io/continua-ci-and-finalbuilder-integration-improvements.html</link><description>From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/747/continua-ci-and-finalbuilder-integration-improvements"&gt;https://www.finalbuilder.com/resources/blogs/postid/747/continua-ci-and-finalbuilder-integration-improvements&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;br&gt;&lt;br&gt;&lt;h3&gt;Continua CI 1.8&lt;/h3&gt;
&lt;p&gt;Continua CI 1.8.0.176 and FinalBuilder 8.0.0.1817 (both released today) provide somewhat better integration between the two products.&lt;/p&gt;&lt;p&gt;
The FinalBuilder Action in Continua CI now produces an xml file that is consumed by FinalBuilder when run under Continua CI. This xml file contains all the useful information about a build, such as version numbers, changesets, variables etc.&amp;#160;&lt;br&gt;&lt;br&gt;
There is also a new option on the action that will automatically apply Continua CI variable values to matching FinalBuilder variables. What this means is, if you have a variable declared in both FinalBuilder and Continua CI with the same name, FinalBuilder's variable will automatically get the value of the Continua CI variable at runtime. This option is only available for FinalBuilder 8, if you select FinalBuilder 7 the option will not be visible. If the version of FinalBuilder 8 you are running does not support this integration, a warning will appear in the Continua CI build log.&amp;#160;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;
&lt;img alt="" src="/blogimages/vincent/continua-fb-integration/continua-fbaction.png"&gt;&lt;/p&gt;
&lt;h3&gt;FinalBuilder 8&lt;/h3&gt;
FinalBuilder 8 has two new actions. &lt;br&gt;&lt;br&gt;
The "Is Running Under Continua" action is an If Then style action, i.e. the children of this action will only run if FinalBuilder is running under Continua CI. &amp;#160;&lt;br&gt;&lt;br&gt;&lt;p&gt;FinalBuilder 8 has two new actions.The "Is Running Under Continua" action is an If Then style action, i.e. the children of this action will only run if FinalBuilder is running under Continua CI.&lt;/p&gt;&lt;p&gt;
&lt;img alt="" src="/blogimages/vincent/continua-fb-integration/isrunningcontinua.png"&gt;&lt;/p&gt;
&lt;br&gt;&lt;p&gt;The other action is the Continua CI - Get Version Info action - this action will take the version info from Continua CI and apply it to a version info property set in your FinalBuilder project.;&lt;/p&gt;
&lt;p&gt;&amp;#160;&lt;/p&gt;
&lt;p&gt;
&lt;img alt="" src="/blogimages/vincent/continua-fb-integration/getversioninfo.png"&gt;&lt;/p&gt;
&lt;p&gt;The action is smart enough to use the correct version info scheme depending on whether the propertyset is a win32 or dotnet propertyset. This greatly simplifies getting the version info from Continua into FinalBuilder, no need to declare 4 variables on both sides and set them in the FinalBuilder Action in Continua CI.&lt;/p&gt;
&lt;h3&gt;Scripting&lt;/h3&gt;
That xml file I mentioned above is loaded into a Continua object model that is available in action script events. If you do make use of it, you should be sure to check the Continua.IsRunningUnderContinua property before using the rest of the object model (the script editor provides intellisense for the model.&lt;br&gt;&lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;p&gt;That xml file I mentioned above is loaded into a Continua object model that is available in action script events. If you do make use of it, you should be sure to check the Continua.IsRunningUnderContinua property before using the rest of the object model (the script editor provides intellisense for the model.&lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Wed, 22 Jun 2016 06:35:25 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-06-22:continua-ci-and-finalbuilder-integration-improvements.html</guid><category>finalbuilder</category></item><item><title>GSoC: Mid-term presentations by students on June 23 and 24</title><link>http://ciandcd.github.io/gsoc-mid-term-presentations-by-students-on-june-23-and-24.html</link><description>From:&lt;a href="http://feedproxy.google.com/~r/ContinuousBlog/~3/Sos1yGo_VtY/"&gt;http://feedproxy.google.com/~r/ContinuousBlog/~3/Sos1yGo_VtY/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;As you probably know, on this year Jenkins projects participates in
&lt;a href="https://developers.google.com/open-source/gsoc/"&gt;Google Summer of Code 2016&lt;/a&gt;.
You can find more information about the accepted projects &lt;a http: feedproxy.google.com projects gsoc /&gt;on the GSoC subproject page&lt;/a&gt; and in the
&lt;a href="https://groups.google.com/forum/#!topic/jenkinsci-dev"&gt;Jenkins Developer&lt;/a&gt; mailing list.&lt;/p&gt;
&lt;p&gt;On &lt;strong&gt;this week&lt;/strong&gt; GSoC students are going to present their projects as a part of mid-term evaluation,
which covers one month of community bonding and one month of coding.&lt;/p&gt;
&lt;p&gt;We would like to invite Jenkins developers to attend these meetings.
There are two additional months of coding ahead for successful students, so any feedback from Jenkins contributors and users will be appreciated.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;
&lt;p&gt;Jenkins WebUI: Improving Job Creation/Configuration by &lt;a href="https://github.com/samatdav"&gt;Samat Davletshin&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;
&lt;p&gt;&lt;a http: feedproxy.google.com blog 2016 05 26 gsoc-jenkins-web-ui-project&gt;Intro blogpost&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Q&amp;amp;A session&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://plus.google.com/events/cj09ur9ikphda1r5dmqu1cse9q8"&gt;Meeting link&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Both meetings will be conducted and recorded via &lt;strong&gt;Hangouts on Air&lt;/strong&gt;.
The recorded sessions will be made public after the meetup.
The agenda may change a bit.&lt;/p&gt;
&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Tue, 21 Jun 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-06-21:gsoc-mid-term-presentations-by-students-on-june-23-and-24.html</guid><category>jenkins</category></item><item><title>Faster Pipelines with the Parallel Test Executor Plugin</title><link>http://ciandcd.github.io/faster-pipelines-with-the-parallel-test-executor-plugin.html</link><description>From:&lt;a href="http://feedproxy.google.com/~r/ContinuousBlog/~3/bwPY9EQtqlA/"&gt;http://feedproxy.google.com/~r/ContinuousBlog/~3/bwPY9EQtqlA/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;code&gt;node { &lt;p&gt;/* ...unchanged... */&lt;/p&gt; }

&lt;p&gt;void&lt;/p&gt; runTests(&lt;p&gt;def&lt;/p&gt; args) {
  &lt;p&gt;/* Request the test groupings.  Based on previous test results. */&lt;/p&gt;
  &lt;p&gt;/* see https://wiki.jenkins-ci.org/display/JENKINS/Parallel+Test+Executor+Plugin and demo on github
  /* Using arbitrary parallelism of 4 and "generateInclusions" feature added in v1.8. */&lt;/p&gt;
  &lt;p&gt;def&lt;/p&gt; splits = splitTests &lt;p&gt;parallelism&lt;/p&gt;: [&lt;p&gt;$&lt;/p&gt;&lt;p&gt;class&lt;/p&gt;: &lt;p&gt;&lt;p&gt;'&lt;/p&gt;&lt;p&gt;CountDrivenParallelism&lt;/p&gt;&lt;p&gt;'&lt;/p&gt;&lt;/p&gt;, &lt;p&gt;size&lt;/p&gt;: &lt;p&gt;4&lt;/p&gt;], &lt;p&gt;generateInclusions&lt;/p&gt;: &lt;p&gt;true&lt;/p&gt;

  &lt;p&gt;/* Create dictionary to hold set of parallel test executions. */&lt;/p&gt;
  &lt;p&gt;def&lt;/p&gt; testGroups = [:]

  &lt;p&gt;for&lt;/p&gt; (&lt;p&gt;int&lt;/p&gt; i = &lt;p&gt;0&lt;/p&gt;; i &amp;lt; splits.size(); i++) {
    &lt;p&gt;def&lt;/p&gt; split = splits[i]

    &lt;p&gt;/* Loop over each record in splits to prepare the testGroups that we'll run in parallel. */&lt;/p&gt;
    &lt;p&gt;/* Split records returned from splitTests contain { includes: boolean, list: List&amp;lt;String&amp;gt; }. */&lt;/p&gt;
    &lt;p&gt;/*     includes = whether list specifies tests to include (true) or tests to exclude (false). */&lt;/p&gt;
    &lt;p&gt;/*     list = list of tests for inclusion or exclusion. */&lt;/p&gt;
    &lt;p&gt;/* The list of inclusions is constructed based on results gathered from */&lt;/p&gt;
    &lt;p&gt;/* the previous successfully completed job. One additional record will exclude */&lt;/p&gt;
    &lt;p&gt;/* all known tests to run any tests not seen during the previous run.  */&lt;/p&gt;
    testGroups[&lt;p&gt;&lt;p&gt;"&lt;/p&gt;&lt;p&gt;split-&lt;/p&gt;&lt;p&gt;&lt;p&gt;${&lt;/p&gt;i&lt;p&gt;}&lt;/p&gt;&lt;/p&gt;&lt;p&gt;"&lt;/p&gt;&lt;/p&gt;] = {  &lt;p&gt;// example, "split3"&lt;/p&gt;
      node {
        checkout scm

        &lt;p&gt;/* Clean each test node to start. */&lt;/p&gt;
        mvn &lt;p&gt;&lt;p&gt;'&lt;/p&gt;&lt;p&gt;clean&lt;/p&gt;&lt;p&gt;'&lt;/p&gt;&lt;/p&gt;

        &lt;p&gt;def&lt;/p&gt; mavenInstall = &lt;p&gt;&lt;p&gt;'&lt;/p&gt;&lt;p&gt;install -DMaven.test.failure.ignore=true&lt;/p&gt;&lt;p&gt;'&lt;/p&gt;&lt;/p&gt;

        &lt;p&gt;/* Write includesFile or excludesFile for tests.  Split record provided by splitTests. */&lt;/p&gt;
        &lt;p&gt;/* Tell Maven to read the appropriate file. */&lt;/p&gt;
        &lt;p&gt;if&lt;/p&gt; (split.includes) {
          writeFile &lt;p&gt;file&lt;/p&gt;: &lt;p&gt;&lt;p&gt;"&lt;/p&gt;&lt;p&gt;target/parallel-test-includes-&lt;/p&gt;&lt;p&gt;&lt;p&gt;${&lt;/p&gt;i&lt;p&gt;}&lt;/p&gt;&lt;/p&gt;&lt;p&gt;.txt&lt;/p&gt;&lt;p&gt;"&lt;/p&gt;&lt;/p&gt;, &lt;p&gt;text&lt;/p&gt;: split.list.join(&lt;p&gt;&lt;p&gt;"&lt;/p&gt;&lt;p&gt;\n&lt;/p&gt;&lt;p&gt;"&lt;/p&gt;&lt;/p&gt;)
          mavenInstall += &lt;p&gt;&lt;p&gt;"&lt;/p&gt;&lt;p&gt; -Dsurefire.includesFile=target/parallel-test-includes-&lt;/p&gt;&lt;p&gt;&lt;p&gt;${&lt;/p&gt;i&lt;p&gt;}&lt;/p&gt;&lt;/p&gt;&lt;p&gt;.txt&lt;/p&gt;&lt;p&gt;"&lt;/p&gt;&lt;/p&gt;
        } &lt;p&gt;else&lt;/p&gt; {
          writeFile &lt;p&gt;file&lt;/p&gt;: &lt;p&gt;&lt;p&gt;"&lt;/p&gt;&lt;p&gt;target/parallel-test-excludes-&lt;/p&gt;&lt;p&gt;&lt;p&gt;${&lt;/p&gt;i&lt;p&gt;}&lt;/p&gt;&lt;/p&gt;&lt;p&gt;.txt&lt;/p&gt;&lt;p&gt;"&lt;/p&gt;&lt;/p&gt;, &lt;p&gt;text&lt;/p&gt;: split.list.join(&lt;p&gt;&lt;p&gt;"&lt;/p&gt;&lt;p&gt;\n&lt;/p&gt;&lt;p&gt;"&lt;/p&gt;&lt;/p&gt;)
          mavenInstall += &lt;p&gt;&lt;p&gt;"&lt;/p&gt;&lt;p&gt; -Dsurefire.excludesFile=target/parallel-test-excludes-&lt;/p&gt;&lt;p&gt;&lt;p&gt;${&lt;/p&gt;i&lt;p&gt;}&lt;/p&gt;&lt;/p&gt;&lt;p&gt;.txt&lt;/p&gt;&lt;p&gt;"&lt;/p&gt;&lt;/p&gt;
        }

        &lt;p&gt;/* Call the Maven build with tests. */&lt;/p&gt;
        mvn mavenInstall

        &lt;p&gt;/* Archive the test results */&lt;/p&gt;
        step([&lt;p&gt;$&lt;/p&gt;&lt;p&gt;class&lt;/p&gt;: &lt;p&gt;&lt;p&gt;'&lt;/p&gt;&lt;p&gt;JUnitResultArchiver&lt;/p&gt;&lt;p&gt;'&lt;/p&gt;&lt;/p&gt;, &lt;p&gt;testResults&lt;/p&gt;: &lt;p&gt;&lt;p&gt;'&lt;/p&gt;&lt;p&gt;**/target/surefire-reports/TEST-*.xml&lt;/p&gt;&lt;p&gt;'&lt;/p&gt;&lt;/p&gt;])
      }
    }
  }
  parallel testGroups
}

&lt;p&gt;/* Run Maven */&lt;/p&gt;
&lt;p&gt;void&lt;/p&gt; mvn(&lt;p&gt;def&lt;/p&gt; args) { &lt;p&gt;/* ... */&lt;/p&gt; }&lt;/code&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Thu, 16 Jun 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-06-16:faster-pipelines-with-the-parallel-test-executor-plugin.html</guid><category>jenkins</category></item><item><title>Jenkins Pipeline Scalability in the Enterprise</title><link>http://ciandcd.github.io/jenkins-pipeline-scalability-in-the-enterprise.html</link><description>From:&lt;a href="http://feedproxy.google.com/~r/ContinuousBlog/~3/Jmt7It6o5TY/"&gt;http://feedproxy.google.com/~r/ContinuousBlog/~3/Jmt7It6o5TY/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Implementing a CI/CD solution based on Jenkins has become very easy. Dealing with hundreds of jobs? Not so much. Having to scale to thousands of jobs? Now this is a real challenge.&lt;/p&gt;&lt;p&gt;This is the story of a journey to get out of the jungle of jobs&amp;#8230;&amp;#8203;&lt;/p&gt;&lt;h4 id="start-of-the-journey"&gt;&lt;a class="anchor" href="#start-of-the-journey"&gt;&lt;/a&gt;Start of the journey&lt;/h4&gt;
&lt;p&gt;At the beginning of the journey there were several projects using roughly the same
technologies. Those projects had several
branches, for maintenance of releases, for new features.&lt;/p&gt;
&lt;p&gt;In turn, each of those branches had to be carefully built, deployed on different
platforms and versions, promoted so they could be tested for functionalities,
performances and security, and then promoted again for actual delivery.&lt;/p&gt;
&lt;p&gt;Additionally, we had to offer the test teams the means to deploy any version of
their choice on any supported platform in order to carry out some manual tests.&lt;/p&gt;
&lt;p&gt;This represented, for each branch, around 20 jobs. Multiply this by the number of
branches and projects, and there you are: more than two years after the start
of the story, we had more than 3500 jobs.&lt;/p&gt;
&lt;p&gt;3500 jobs. Half a dozen people to manage them all&amp;#8230;&amp;#8203;&lt;/p&gt;
&lt;img src="/images/post-images/jenkins-pipeline-scalability/thousands.png" alt="Thousands of jobs for a small team"&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Wed, 15 Jun 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-06-15:jenkins-pipeline-scalability-in-the-enterprise.html</guid><category>jenkins</category></item><item><title>Jenkins World Agenda is Live!</title><link>http://ciandcd.github.io/jenkins-world-agenda-is-live.html</link><description>From:&lt;a href="http://feedproxy.google.com/~r/ContinuousBlog/~3/QycUsTgE6ew/"&gt;http://feedproxy.google.com/~r/ContinuousBlog/~3/QycUsTgE6ew/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;The objective of this session is to help you assess your level of readiness for
the certification exam - either the Certified Jenkins Engineer (CJE/open source)
certification or the Certified CloudBees Jenkins Platform Engineer
(CCJPE/CloudBees-specific) certification. After an overview about the
certification program, a Jenkins expert from CloudBees will walk you through the
various sections of the exam, highlighting the important things to master ahead
of time, not only from a pure knowledge perspective but also in terms of
practical experience. This will be an interactive session.&lt;/p&gt;
&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Tue, 14 Jun 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-06-14:jenkins-world-agenda-is-live.html</guid><category>jenkins</category></item><item><title>Support Core Plugin Improvements</title><link>http://ciandcd.github.io/support-core-plugin-improvements.html</link><description>From:&lt;a href="http://feedproxy.google.com/~r/ContinuousBlog/~3/QGNUNOMUA4Q/"&gt;http://feedproxy.google.com/~r/ContinuousBlog/~3/QGNUNOMUA4Q/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;li&gt;
&lt;p&gt;Automatic bundles: Bundles which are generated and get saved in $JENKINS_HOME/support once per hour starting 15 seconds after Jenkins starts the plugin.
The automatic bundles are retained using an exponential aging strategy. Therefore it&amp;#8217;s possible to have a bunch of them over the entire lifetime after the plugin installing the plugin.&lt;/p&gt;
&lt;/li&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Tue, 14 Jun 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-06-14:support-core-plugin-improvements.html</guid><category>jenkins</category></item><item><title>Upcoming June Jenkins Events</title><link>http://ciandcd.github.io/upcoming-june-jenkins-events.html</link><description>From:&lt;a href="http://feedproxy.google.com/~r/ContinuousBlog/~3/UkC6ZbWPxX0/"&gt;http://feedproxy.google.com/~r/ContinuousBlog/~3/UkC6ZbWPxX0/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;It is hard to believe that the first half of 2016 is almost over and summer is
just around the corner.  As usual, there are plenty of educational Jenkins
events planned for this month. Below lists what&amp;#8217;s happening in your neck of the
woods:&lt;/p&gt;
&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Mon, 13 Jun 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-06-13:upcoming-june-jenkins-events.html</guid><category>jenkins</category></item><item><title>Usage Statistics Analysis</title><link>http://ciandcd.github.io/usage-statistics-analysis.html</link><description>From:&lt;a href="http://feedproxy.google.com/~r/ContinuousBlog/~3/f3Cqs4raeOc/"&gt;http://feedproxy.google.com/~r/ContinuousBlog/~3/f3Cqs4raeOc/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;This method is based on a properties or the content of the item for example
recommending items that are similar to the those that a user liked in the past
or examining in the present based upon some properties. Here, we are utilizing
&lt;a href="http://stats.jenkins-ci.org/jenkins-stats/jenkinsgraph.html?filter=kohsuke"&gt;Jenkins
plugin dependency graph&lt;/a&gt; to learn about the properties of a plugin. This graph
tells us about dependent plugins on a given plugin as well as its dependencies
on others. Here is an example to show, how this graph is use for content based
filetring, suppose if a user is using &amp;#8220;CloudBees Cloud Connector&amp;#8221;, then we can
recommend them for &amp;#8220;CloudBees Registration Plugin&amp;#8221; as both plugins are dependent
on &amp;#8220;CloudBees Credentials Plugin&amp;#8221;.&lt;/p&gt;
&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Mon, 13 Jun 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-06-13:usage-statistics-analysis.html</guid><category>jenkins</category></item><item><title>Save up to 90% of CI cost on AWS with Jenkins and EC2 Spot Fleet</title><link>http://ciandcd.github.io/save-up-to-90-of-ci-cost-on-aws-with-jenkins-and-ec2-spot-fleet.html</link><description>From:&lt;a href="http://feedproxy.google.com/~r/ContinuousBlog/~3/OO07WUzjFas/"&gt;http://feedproxy.google.com/~r/ContinuousBlog/~3/OO07WUzjFas/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;After you have finished the previous step, you can view the &lt;strong&gt;EC2 Fleet Status&lt;/strong&gt; in the left hand navigation pane on
the Jenkins dashboard. Now, as you submit more jobs, Jenkins will automatically scale your Spot fleet to add more
nodes. You can view these new nodes executing jobs under the Build Executor Status.
After the jobs are done, if the nodes remain free for the specified idle time (configured in the previous step),
then Jenkins releases the nodes, automatically scaling down your Spot fleet nodes.&lt;/p&gt;
&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Fri, 10 Jun 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-06-10:save-up-to-90-of-ci-cost-on-aws-with-jenkins-and-ec2-spot-fleet.html</guid><category>jenkins</category></item><item><title>Automatic Plugin Documentation</title><link>http://ciandcd.github.io/automatic-plugin-documentation.html</link><description>From:&lt;a href="http://feedproxy.google.com/~r/ContinuousBlog/~3/hzDOw1V-x1g/"&gt;http://feedproxy.google.com/~r/ContinuousBlog/~3/hzDOw1V-x1g/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;I am Cynthia Anyango from Nairobi, Kenya. I am a second year student at Maseno University. I am currently specializing on Ruby on Rails and trying to learn Python. I recently started contributing to Open source projects.My major contribution was at Mozilla, where I worked with the QA for Cloud services. I did manual and automated tests for various cloud services. I wrote documentation too. Above that, I am competent and I am always passionate about what I get my hands on.&lt;/p&gt;&lt;h3 id="project-summary"&gt;&lt;a class="anchor" href="#project-summary"&gt;&lt;/a&gt;Project summary&lt;/h3&gt;
&lt;p&gt;Currently Jenkins plugin documentation is being stored in Confluence. Sometimes
the documentation is scattered and outdated. In order to improve the situation we
would like to follow the documentation-as-code approach and to put docs to
plugin repositories and then publish them on the project website using the
awestruct engine. The project aims an implementation of a documentation
continuous deployment flow powered by Jenkins and Pipeline Plugin.&lt;/p&gt;
&lt;p&gt;The idea is to automatically pull in the README and other docs from GitHub, show
changelogs with versions and releases dates. I will be designing file templates
that will contain most of the  docs information that will be required from
plugin developers. Initially the files will be written in
&lt;a href="http://asciidoctor.org/"&gt;AsciiDoc&lt;/a&gt;. Plugin developers will get a chance to
review the templates. The templates will be prototyped by various plugin
developers.&lt;/p&gt;
&lt;p&gt;The docs that will be automatically pulled from github and will be published on
&lt;a href="https://jenkins.io/"&gt;Jenkins.io&lt;/a&gt; under the Documentation section.&lt;/p&gt;
&lt;p&gt;My mentors are &lt;a href="https://github.com/rtyler"&gt;R.Tyler&lt;/a&gt; and
&lt;a href="https://github.com/batmat"&gt;Baptiste Mathus&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I hope to achieve this by 25th June when we will be having our mid-term
evaluations.&lt;/p&gt;
&lt;p&gt;I will update more on the progress.&lt;/p&gt;
&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Wed, 01 Jun 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-06-01:automatic-plugin-documentation.html</guid><category>jenkins</category></item><item><title>New display of Pipeline’s "snippet generator"</title><link>http://ciandcd.github.io/new-display-of-pipelines-snippet-generator.html</link><description>From:&lt;a href="http://feedproxy.google.com/~r/ContinuousBlog/~3/s9rS1mBGz8g/"&gt;http://feedproxy.google.com/~r/ContinuousBlog/~3/s9rS1mBGz8g/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Those of you updating the &lt;a href="https://wiki.jenkins-ci.org/display/JENKINS/Pipeline+Groovy+Plugin"&gt;Pipeline Groovy plugin&lt;/a&gt;
to 2.3 or later will notice a change to the appearance of the configuration form.
The Snippet Generator tool is no longer a checkbox enabled inside the configuration page.
Rather, there is a link Pipeline Syntax which opens a separate page with several options.
(The link appears in the project&amp;#8217;s sidebar; Jenkins 2 users will not see the sidebar from the configuration screen,
so as of 2.4 there is also a link beneath the Pipeline definition.)&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/post-images/jenkins2-snippetizer-demo.png" alt="Snippet Generator"&gt;&lt;/p&gt;
&lt;p&gt;Snippet Generator continues to be available for learning the available
Pipeline steps and creating sample calls given various configuration options.
The new page also offers clearer links to static reference documentation, online
Pipeline documentation resources, and an IntelliJ IDEA code completion file
(Eclipse support is unfinished).&lt;/p&gt;
&lt;p&gt;One motivation for this change
(&lt;a href="https://issues.jenkins-ci.org/browse/JENKINS-31831"&gt;JENKINS-31831&lt;/a&gt;) was to
give these resources more visual space and more prominence.  But another
consideration was that people using multibranch projects or organization folders
should be able to use Snippet Generator when setting up the project, before
any code is committed.&lt;/p&gt;
&lt;p&gt;Those using
&lt;a href="https://wiki.jenkins-ci.org/display/JENKINS/Pipeline+Multibranch+Plugin"&gt;Pipeline
Multibranch plugin&lt;/a&gt; or organization folder plugins should upgrade to 2.4 or
later to see these improvements as well.&lt;/p&gt;
&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Tue, 31 May 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-05-31:new-display-of-pipelines-snippet-generator.html</guid><category>jenkins</category></item><item><title>a new user experience for Jenkins</title><link>http://ciandcd.github.io/a-new-user-experience-for-jenkins.html</link><description>From:&lt;a href="http://feedproxy.google.com/~r/ContinuousBlog/~3/ulSArRaMfCo/"&gt;http://feedproxy.google.com/~r/ContinuousBlog/~3/ulSArRaMfCo/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;In recent years developers have become rapidly attracted to tools that are not
only functional but are designed to fit into their workflow seamlessly and are
a joy to use. This shift represents a higher standard of design and user
experience that Jenkins needs to rise to meet.&lt;/p&gt;
&lt;p&gt;We are excited to share and invite the community to join us on a project we&amp;#8217;ve
been thinking about over the last few months called Blue Ocean.&lt;/p&gt;
&lt;p&gt;Blue Ocean is a project that rethinks the user experience of Jenkins, modelling
and presenting the process of software delivery by surfacing information that&amp;#8217;s
important to development teams with as few clicks as possible, while still
staying true to the extensibility that is core to Jenkins.&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/post-images/blueocean/pipeline-run.png" alt="Pipeline execution"&gt;&lt;/p&gt;
&lt;p&gt;While this project is in the alpha stage of development, the intent is that
Jenkins users can install Blue Ocean side-by-side with the Jenkins Classic UI
via a plugin.&lt;/p&gt;
&lt;p&gt;Not all the features listed on this blog are complete but we will be hard at
work over the next few months preparing Blue Ocean for general use. We intend
to provide regular updates on this blog as progress is made.&lt;/p&gt;
&lt;p&gt;Blue Ocean is &lt;a href="https://github.com/cloudbees/blueocean"&gt;open source today&lt;/a&gt;
and we invite you to give us feedback and to contribute to the project.&lt;/p&gt;



&lt;p&gt;Blue Ocean will provide development teams:&lt;/p&gt;
&lt;h4 id="new-modern-user-experience"&gt;&lt;a class="anchor" href="#new-modern-user-experience"&gt;&lt;/a&gt;New modern user experience&lt;/h4&gt;
&lt;p&gt;The UI aims to improve clarity, reduce clutter and navigational depth to make
the user experience very concise. A modern visual design gives developers much
needed relief throughout their daily usage and screens respond instantly to
changes on the server making manual page refreshes a thing of the past.&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/post-images/blueocean/pipeline-dashboard.png" alt="Project dashboard"&gt;&lt;/p&gt;
&lt;h4 id="advanced-pipeline-visualisations-with-built-in-failure-diagnosis"&gt;&lt;a class="anchor" href="#advanced-pipeline-visualisations-with-built-in-failure-diagnosis"&gt;&lt;/a&gt;Advanced Pipeline visualisations with built-in failure diagnosis&lt;/h4&gt;
&lt;p&gt;&lt;a http: feedproxy.google.com solutions pipeline&gt;Pipelines&lt;/a&gt; are visualised on screen along with the
steps and logs to allow simplified comprehension of the continuous delivery
pipeline &amp;#8211; from the simple to the most sophisticated scenarios.&lt;/p&gt;
&lt;p&gt;Scrolling through 10,000 line log files is a thing of the past. Blue Ocean
breaks down your log per step and calls out where your build failed.&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/post-images/blueocean/failing-pipeline.png" alt="Failing Pipeline"&gt;&lt;/p&gt;
&lt;h4 id="branch-and-pull-request-awareness"&gt;&lt;a class="anchor" href="#branch-and-pull-request-awareness"&gt;&lt;/a&gt;Branch and Pull Request awareness&lt;/h4&gt;
&lt;p&gt;Modern pipelines make use of multiple Git branches, and Blue Ocean is designed
with this in mind. Drop a &lt;a http: feedproxy.google.com doc pipeline&gt;&lt;code&gt;Jenkinsfile&lt;/code&gt; into your Git
repository&lt;/a&gt; that defines your pipeline and Jenkins will automatically discover
and start automating any &amp;#160;Branches and validating Pull Requests.&lt;/p&gt;
&lt;p&gt;Jenkins will report the status of your pipeline right inside Github or
Bitbucket on all your commits, branches or pull requests.&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/post-images/blueocean/pr-view.png" alt="Pull request view"&gt;&lt;/p&gt;
&lt;h4 id="personalised-view"&gt;&lt;a class="anchor" href="#personalised-view"&gt;&lt;/a&gt;Personalised View&lt;/h4&gt;
&lt;p&gt;Favourite any pipelines, branches or pull requests and see them appear on your
personalised dashboard. Intelligence is being built into the dashboard. Jobs
that need your attention, say a Pipeline waiting for approval or a failing job
that you have recently changed, appear on the top of the dashboard.&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/post-images/blueocean/personalized-dashboard.png" alt="Personalized dashboard"&gt;&lt;/p&gt;
&lt;p&gt;You can read more about Blue Ocean and its goals on the
&lt;a http: feedproxy.google.com projects blueocean&gt;project page&lt;/a&gt; and developers should watch the
&lt;a http: feedproxy.google.com content mailing-lists&gt;Developers list&lt;/a&gt; for more information.&lt;/p&gt;
&lt;p&gt;For Jenkins developers and plugin authors:&lt;/p&gt;
&lt;h4 id="jenkins-design-language"&gt;&lt;a class="anchor" href="#jenkins-design-language"&gt;&lt;/a&gt;Jenkins Design &amp;#8220;Language&amp;#8221;&lt;/h4&gt;
&lt;p&gt;The Jenkins Design Language (JDL) is a set of standardised React components and
a style guide that help developers create plugins that retain the look and feel
of Blue Ocean in an effortless way. We will be publishing more on the JDL,
including the style guide and developer documentation, over the next few weeks.&lt;/p&gt;
&lt;h4 id="modern-javascript-toolchain"&gt;&lt;a class="anchor" href="#modern-javascript-toolchain"&gt;&lt;/a&gt;Modern JavaScript toolchain&lt;/h4&gt;
&lt;p&gt;The Jenkins plugin tool chain has been extended so that developers can use
&lt;a href="https://medium.com/@rajaraodv/5-javascript-bad-parts-that-are-fixed-in-es6-c7c45d44fd81"&gt;ES6&lt;/a&gt;,
&lt;a href="https://facebook.github.io/react/"&gt;React&lt;/a&gt;, &lt;a href="https://www.npmjs.com/"&gt;NPM&lt;/a&gt;
in their plugins without endless yak-shaving. Jenkins
&lt;a href="https://github.com/jenkinsci/js-modules"&gt;js-modules&lt;/a&gt; are already in use in
Jenkins today, and this builds on this, using the same tooling.&lt;/p&gt;
&lt;h4 id="client-side-extension-points"&gt;&lt;a class="anchor" href="#client-side-extension-points"&gt;&lt;/a&gt;Client side Extension points&lt;/h4&gt;
&lt;p&gt;Client Side plugins use Jenkins plugin infrastructure. The Blue Ocean libraries
built on ES6 and React.js provide an extensible client side component model
that looks familiar to developers who have built Jenkins plugins before. Client
side extension points can help isolate failure, so one bad plugin doesn&amp;#8217;t take
a whole page down.&lt;/p&gt;
&lt;h4 id="server-sent-events"&gt;&lt;a class="anchor" href="#server-sent-events"&gt;&lt;/a&gt;Server Sent Events&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events"&gt;Server Sent Events&lt;/a&gt;
(SSE) allow plugin developers to tap into changes of state on the server and make
their UI update in real time (&lt;a href="https://www.youtube.com/watch?v=EttzK5OOpv0"&gt;watch this for a
demo&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;To make Blue Ocean a success, we&amp;#8217;re asking for help and support from Jenkins
developers and plugin authors. Please join in our Blue Ocean discussions on the
&lt;a href="http://groups.google.com/forum/#!forum/jenkinsci-dev"&gt;Jenkins Developer
mailing list&lt;/a&gt; and the &lt;code&gt;#jenkins-ux&lt;/code&gt; IRC channel on Freenode!&lt;/p&gt;
&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Thu, 26 May 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-05-26:a-new-user-experience-for-jenkins.html</guid><category>jenkins</category></item><item><title>GSoC Project Intro: Improving Job Creation</title><link>http://ciandcd.github.io/gsoc-project-intro-improving-job-creation.html</link><description>From:&lt;a href="http://feedproxy.google.com/~r/ContinuousBlog/~3/vq_a-JXFsJI/"&gt;http://feedproxy.google.com/~r/ContinuousBlog/~3/vq_a-JXFsJI/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Jenkins has a lot of windows reloads that may time consuming. The creation of new job is a simple process requiring only job name and job type. This way UI may be improved by reducing page reloads and putting new job creation interface in a dialog window. Such popup would likely consist of three steps of implementation: rendering a dialog window, receiving JSON with job types, sending a POST request to create the job.&lt;/p&gt;&lt;p&gt;Initially, job validation was unresponsive, job creation was still allowed with an invalid name, and some allowed characters even crashed Jenkins. Happily, two of this problems were fixed in recent improvements and I plan add only a real time name check for invalid characters.&lt;/p&gt;&lt;h4 id="configuration-page"&gt;&lt;a class="anchor" href="#configuration-page"&gt;&lt;/a&gt;Configuration page&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Changing help information&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/post-images/gsoc-job-config/changing-help.gif" alt="Changing help information"&gt;&lt;/p&gt;
&lt;p&gt;As reported by some users, it would be useful to have the functionality to
change help information. Installation administrators would be able to change the
help info and choose editing rights for other users. That would likely require a
creation of extension points and a plugin using them. I also would like to
include the ability to style the help information using markdown as shown above.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;[Optional] The functionality is extended to creation of crowd sourced "wiki like" documentation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As in
&lt;a href="https://wiki.jenkins-ci.org/display/JENKINS/Translation+Assistance+Plugin"&gt;localization
plugin&lt;/a&gt; the changes are gathered and applied beyond installation of a particular
user.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;More intuitive configuration page.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Pursuing to solve &lt;a href="https://issues.jenkins-ci.org/browse/JENKINS-32578"&gt;this  issue&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Although there are a lot improvements in new configuration page, there is always
a room for improvements. An advanced job still has a very complicated and hard
to read configuration page. It is still open to discussion, but I may approach
it by better division of configuration parts such as an accordion based
navigation.&lt;/p&gt;
&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Thu, 26 May 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-05-26:gsoc-project-intro-improving-job-creation.html</guid><category>jenkins</category></item><item><title>Refactoring a Jenkins plugin for compatibility with Pipeline jobs</title><link>http://ciandcd.github.io/refactoring-a-jenkins-plugin-for-compatibility-with-pipeline-jobs.html</link><description>From:&lt;a href="http://feedproxy.google.com/~r/ContinuousBlog/~3/GH2vCWRAagA/"&gt;http://feedproxy.google.com/~r/ContinuousBlog/~3/GH2vCWRAagA/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;In this blog post, I&amp;#8217;m going to attempt to provide some step-by-step notes on how to refactor an existing Jenkins plugin to make it compatible with the new Jenkins Pipeline jobs. Before we get to the fun stuff, though, a little background.&lt;/p&gt;&lt;p&gt;Spoiler: if you&amp;#8217;re just interested in looking at the individual git commits that I made on may way to getting the plugin working with Pipeline, have a look at this github branch .&lt;/p&gt;&lt;p&gt;Eventually, I got it all sorted out. So, in hopes of saving the next person a little time, and encouraging plugin authors to invest the time to get their plugins working with Pipeline, here are some notes about what I learned.&lt;/p&gt;&lt;p&gt;As best as I could tell from my Googling, the plugin was probably going to require some modifications in order to be able to be used with Pipeline jobs. However, I wasn&amp;#8217;t able to find any really cohesive documentation that definitively confirmed that or explained how everything fits together.&lt;/p&gt;&lt;p&gt;So everything&amp;#8217;s going GREAT up to this point. I&amp;#8217;m really happy with how it&amp;#8217;s all shaping up. But then&amp;#8230;&amp;#8203; (you knew there was a "but" coming, right?) I started trying to figure out how to add the Gatling Jenkins plugin to the Pipeline jobs, and kind of ran into a wall.&lt;/p&gt;&lt;p&gt;Over the last few days I&amp;#8217;ve been putting some effort into getting things more automated and repeatable so that we can really maximize the value that we&amp;#8217;re getting out of the performance tests. With some encouragement from the fine folks in the #jenkins IRC channel , I ended up exploring the JobDSL plugin and the new Pipeline jobs . Combining those two things with some Puppet code to provision a Jenkins server via the jenkins puppet module gave me a really nice way to completely automate my Jenkins setup and get a seed job in place that would create my perf testing jobs. And the Pipeline job format is just an awesome fit for what I wanted to do in terms of being able to easily monitor the stages of my performance tests, and to make the job definitions modular so that it would be really easy to create new performance testing jobs with slight variations.&lt;/p&gt;&lt;p&gt;Recently, I started working on a project to automate some performance tests for my company&amp;#8217;s products. We use the awesome Gatling load testing tool for these tests, but we&amp;#8217;ve largely been handling the testing very manually to date, due to a lack of bandwidth to get them automated in a clean, maintainable, extensible way. We have a years-old Jenkins server where we use the gatling jenkins plugin to track the history of certain tests over time, but the setup of the Jenkins instance was very delicate and not easy to reproduce, so it had fallen into a state of disrepair.&lt;/p&gt;&lt;h3 id="creating-a-pipeline-step"&gt;&lt;a class="anchor" href="#creating-a-pipeline-step"&gt;&lt;/a&gt;Creating a pipeline step&lt;/h3&gt;
&lt;p&gt;The main task that the Gatling plugin performs is to archive Gatling reports
after a run.  I figured that the end game for this exercise was that I was going
to end up with a Pipeline "step" that I could include in my Pipeline scripts, to
trigger the archiving of the reports.  So my first thought was to look for an
existing plugin / Pipeline "step" that was doing something roughly similar, so
that I could use it as a model.  The Pipeline "Snippet Generator" feature
(create a pipeline job, scroll down to the "Definition" section of its
configuration, and check the "Snippet Generator" checkbox) is really helpful for
figuring out stuff like this; it is automatically populated with all of the
steps that are valid on your server (based on which plugins you have installed),
so you can use it to verify whether or not your custom "step" is recognized, and
also to look at examples of existing steps.&lt;/p&gt;
&lt;p&gt;Looking through the list of existing steps, I figured that the &lt;code&gt;archive&lt;/code&gt; step
was pretty likely to be similar to what I needed for the gatling plugin:&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/post-images/update-plugin-for-pipeline-tutorial/05_snippet_generator_archive.png" alt="archive snippet"&gt;&lt;/p&gt;
&lt;p&gt;So, I started poking around to see what magic it was that made that &lt;code&gt;archive&lt;/code&gt;
step show up there.  There are some mentions of this in the
&lt;a href="https://github.com/jenkinsci/pipeline-plugin/blob/6cffbecd874b924677ce3b3c5b1e0e2f45689cc5/DEVGUIDE.md#build-steps"&gt;pipeline-plugin
DEVGUIDE.md&lt;/a&gt; and the
&lt;a href="https://github.com/jenkinsci/workflow-step-api-plugin/blob/ee8f181c5561d70207a6b84b4d91ca24312c8a39/README.md"&gt;workflow-step-api-plugin
README.md&lt;/a&gt;, but the real breakthrough for me was finding the &lt;a href="https://github.com/jenkinsci/workflow-basic-steps-plugin/blob/300fe6c02b41f072e50a501cfec3e2f425048446/src/main/java/org/jenkinsci/plugins/workflow/steps/ArtifactArchiverStep.java#L37-L53"&gt;definition of the
&lt;code&gt;archive&lt;/code&gt; step in the &lt;code&gt;workflow-basic-steps-plugin&lt;/code&gt; source
code&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;With that as an example, I was able to start poking at getting a
&lt;code&gt;gatlingArchive&lt;/code&gt; step to show up in the Snippet Generator.  The first thing that
I needed to do was to &lt;a href="https://github.com/cprice404/gatling-plugin/commit/b321192bc635eee529ff70e4795591c4594f3664"&gt;update the &lt;code&gt;gatling-plugin&lt;/code&gt; project&amp;#8217;s &lt;code&gt;pom.xml&lt;/code&gt; to depend
on a recent enough version of Jenkins, as well as specify dependencies on the
appropriate pipeline
plugins&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Once that was out of the way, I noticed that the &lt;code&gt;archive&lt;/code&gt; step had some tests
written for it, using what looks to be a pretty awesome test API for pipeline
jobs and plugins.  Based on &lt;a href="https://github.com/jenkinsci/workflow-basic-steps-plugin/blob/300fe6c02b41f072e50a501cfec3e2f425048446/src/test/java/org/jenkinsci/plugins/workflow/steps/ArtifactArchiverStepTest.java#L26-L44"&gt;those &lt;code&gt;archive&lt;/code&gt;
tests&lt;/a&gt;,
I added
&lt;a href="https://github.com/cprice404/gatling-plugin/commit/ed9df4b54c36cee467b3a82e42cb2111e93f9df5"&gt;a
skeleton for a test for the &lt;code&gt;gatlingArchive&lt;/code&gt; step&lt;/a&gt; that I was about to write.&lt;/p&gt;
&lt;p&gt;Then, I moved on to
&lt;a href="https://github.com/cprice404/gatling-plugin/commit/3de3485be591c7b750ec2671e74558a79efc4319"&gt;actually
creating the step&lt;/a&gt;.  The meat of the code was this:&lt;/p&gt;
&lt;pre class="CodeRay highlight nowrap"&gt;&lt;code&gt;&lt;p&gt;public&lt;/p&gt; &lt;p&gt;class&lt;/p&gt; &lt;p&gt;GatlingArchiverStep&lt;/p&gt; &lt;p&gt;extends&lt;/p&gt; AbstractStepImpl {
    &lt;p&gt;@DataBoundConstructor&lt;/p&gt;
    &lt;p&gt;public&lt;/p&gt; GatlingArchiverStep() {}

    &lt;p&gt;@Extension&lt;/p&gt;
    &lt;p&gt;public&lt;/p&gt; &lt;p&gt;static&lt;/p&gt; &lt;p&gt;class&lt;/p&gt; &lt;p&gt;DescriptorImpl&lt;/p&gt; &lt;p&gt;extends&lt;/p&gt; AbstractStepDescriptorImpl {
        &lt;p&gt;public&lt;/p&gt; DescriptorImpl() { &lt;p&gt;super&lt;/p&gt;(GatlingArchiverStepExecution.class); }

        &lt;p&gt;@Override&lt;/p&gt;
        &lt;p&gt;public&lt;/p&gt; &lt;p&gt;String&lt;/p&gt; getFunctionName() {
            &lt;p&gt;return&lt;/p&gt; &lt;p&gt;&lt;p&gt;"&lt;/p&gt;&lt;p&gt;gatlingArchive&lt;/p&gt;&lt;p&gt;"&lt;/p&gt;&lt;/p&gt;;
        }

        &lt;p&gt;@Nonnull&lt;/p&gt;
        &lt;p&gt;@Override&lt;/p&gt;
        &lt;p&gt;public&lt;/p&gt; &lt;p&gt;String&lt;/p&gt; getDisplayName() {
            &lt;p&gt;return&lt;/p&gt; &lt;p&gt;&lt;p&gt;"&lt;/p&gt;&lt;p&gt;Archive Gatling reports&lt;/p&gt;&lt;p&gt;"&lt;/p&gt;&lt;/p&gt;;
        }
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that in that commit I also added a &lt;code&gt;config.jelly&lt;/code&gt; file.  This is how you
define the UI for your step, which will show up in the Snippet Generator.  In
the case of this Gatling step there&amp;#8217;s really not much to configure, so my
&lt;code&gt;config.jelly&lt;/code&gt; is basically empty.&lt;/p&gt;
&lt;p&gt;With that (and the rest of the code from that commit) in place, I was able to
fire up the development Jenkins server (via &lt;code&gt;mvn hpi:run&lt;/code&gt;, and note that you
need to go into the "Manage Plugins" screen on your development server and
install the Pipeline plugin once before any of this will work) and visit the
Snippet Generator to see if my step showed up in the dropdown:&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/post-images/update-plugin-for-pipeline-tutorial/10_snippet_generator.png" alt="gatlingArchive snippet"&gt;&lt;/p&gt;
&lt;p&gt;GREAT SUCCESS!&lt;/p&gt;
&lt;p&gt;This step doesn&amp;#8217;t actually &lt;strong&gt;do&lt;/strong&gt; anything yet, but it&amp;#8217;s recognized by Jenkins and
can be included in your pipeline scripts at that point, so, we&amp;#8217;re on our way!&lt;/p&gt;
&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Wed, 25 May 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-05-25:refactoring-a-jenkins-plugin-for-compatibility-with-pipeline-jobs.html</guid><category>jenkins</category></item><item><title>.NET 4.6.1, WCF and self signed X509 certificates</title><link>http://ciandcd.github.io/net-461-wcf-and-self-signed-x509-certificates.html</link><description>From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/746/net-461-wcf-and-self-signed-x509-certificates"&gt;https://www.finalbuilder.com/resources/blogs/postid/746/net-461-wcf-and-self-signed-x509-certificates&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;br&gt;&lt;br&gt;
If you use self signed X509 certificates and target the .net framework 4.6.1 then you are in some fun, especially if you used makecert to generate the certificate. There is a change in behaviour in the way certificates are validated, which will leave you pulling you hair out for hours. The error you may encounter will look something like this :&amp;#160;&lt;br&gt;&lt;br&gt;
"The Identity check failed for the outgoing message. The remote endpoint did not provide a domain name system (DNS) claim and therefore did not satisfied DNS identity 'localhost'. This may be caused by lack of DNS or CN name in the remote endpoint X.509 certificate's distinguished name."&lt;br&gt;&lt;br&gt;
If you google the error message, you will find plenty of references to using&amp;#160; a DnsEndpointIdentity, only in our case, we were already doing exactly as the answers on stackoverflow were suggesting! Since we were migrating from .net 4.0 to .net 4.6.1, I started looking for info on the changes in each version of the .net framework. Eventually, I came across this page :&lt;br&gt;&lt;br&gt;&lt;a class="moz-txt-link-freetext" href="https://msdn.microsoft.com/en-us/library/mt620030%28v=vs.110%29.aspx"&gt;https://msdn.microsoft.com/en-us/library/mt620030(v=vs.110).aspx&lt;/a&gt;&lt;br&gt;&lt;br&gt;
This was the only mention of X509 certificates I could find in the change history, but it seems like it could be related, so I tried what it suggested, and low and behold, problem solved! With some further investigation of this work around, I found some issueson the wcf github repo with several references to the behaviour of certificate validation.&lt;br&gt;&lt;br&gt;&lt;a class="moz-txt-link-freetext" href="https://github.com/dotnet/wcf/issues/321"&gt;https://github.com/dotnet/wcf/issues/321&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;a class="moz-txt-link-freetext" href="https://github.com/dotnet/wcf/pull/603"&gt;https://github.com/dotnet/wcf/pull/603&lt;/a&gt;&lt;br&gt;&lt;br&gt;
So it turns out, in .NET 4.6.1 they broke the certificate validation, by only looking at the Subject Alternate Name (SAN) extension, and not falling back to the Subject Name CN field as it should. The pull request I linked to above, is for the WCF for .NET core, not 4.6.1 - so I have no way of knowing if this will be fixed for 4.6.x. &amp;#160;&lt;br&gt;&lt;br&gt;
Whilst an app.config change can work around the issue, the real fix is to generate certificates that include SAN extension.&lt;br&gt;&lt;br&gt;&lt;h3&gt;Generating a certificate without MakeCert&lt;/h3&gt;
&lt;p&gt;Makecert.exe, which is commonly used (on windows at least) does not support the SAN extension, M&lt;/p&gt;akecert is deprecated, so it's unlikely there will be an update to make it able to generate certificates with the SAN certificate extension. &amp;#160;Windows 8/Server 2012R2 &amp;amp; later versions of Windows include a new powershell cmdlet to generate certificates. For Windows 7 the best option is this :&lt;br&gt;&lt;br&gt;&lt;a class="moz-txt-link-freetext" href="https://gallery.technet.microsoft.com/scriptcenter/Self-signed-certificate-5920a7c6"&gt;https://gallery.technet.microsoft.com/scriptcenter/Self-signed-certificate-5920a7c6&lt;/a&gt;&lt;br&gt;&lt;br&gt;
This appears to what the Windows 8 &amp;amp; later cmdlet is based on, it's relatively simple to use and generates certificates that validate properly with WCF on .NET 4.6.1&lt;br&gt;&lt;br&gt;&lt;pre class="brush:powershell; toolbar:true;"&gt;New-SelfSignedCertificateEx -Subject "CN=MyServer" -KeySpec Exchange 
-KeyUsage "DataEncipherment, KeyEncipherment, DigitalSignature" 
-Path c:\certs\example.pfx -Exportable -SAN "MyServer" -SignatureAlgorithm sha256 
-AllowSMIME -Password (ConvertTo-SecureString "abc123dontuseme" -AsPlainText -Force) 
-NotAfter (get-date).AddYears(20)&lt;/pre&gt;
&lt;br&gt;
Note the above command is on multiple lines to make it easier to read, it can be on one line.
&lt;br&gt;&lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;p&gt;We have been working on moving Continua CI to .net 4.6.1 for a future release, and during this conversion (so far, mostly just updating nuget packages), we discovered an issue that turned out to be caused by a change to .net certificate validation.If you use self signed X509 certificates and target the .net framework 4.6.1 then you are in some fun, especially if you used makecert to generate the certificate. There is a change in behaviour in the way certificates are validated, which will leave you pulling you hair out for hours. The error you may encounter will look something like this :"The Identity check failed for the outgoing message. The remote endpoint did not provide a domain name system (DNS) claim and therefore did not satisfied DNS identity 'localhost'. This may be caused by lack of DNS or CN name in the remote endpoint X.509 certificate's distinguished name."If you google the error message, you will find plenty of references to using a DnsEndpointIdentity, only in our case, we were already doing exactly as the answers on stackoverflow were suggesting! Since we were migrating from .net 4.0 to .net 4.6.1, I started looking for info on the changes in each version of the .net framework. Eventually, I came across this page :This was the only mention of X509 certificates I could find in the change history, but it seems like it could be related, so I tried what it suggested, and low and behold, problem solved! With some further investigation of this work around, I found some issueson the wcf github repo with several references to the behaviour of certificate validation.So it turns out, in .NET 4.6.1 they broke the certificate validation, by only looking at the Subject Alternate Name (SAN) extension, and not falling back to the Subject Name CN field as it should. The pull request I linked to above, is for the WCF for .NET core, not 4.6.1 - so I have no way of knowing if this will be fixed for 4.6.x.Whilst an app.config change can work around the issue, the real fix is to generate certificates that include SAN extension.akecert is deprecated, so it's unlikely there will be an update to make it able to generate certificates with the SAN certificate extension. Windows 8/Server 2012R2 &amp;amp; later versions of Windows include a new powershell cmdlet to generate certificates. For Windows 7 the best option is this :This appears to what the Windows 8 &amp;amp; later cmdlet is based on, it's relatively simple to use and generates certificates that validate properly with WCF on .NET 4.6.1Note the above command is on multiple lines to make it easier to read, it can be on one line.&lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sun, 15 May 2016 05:34:50 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-05-15:net-461-wcf-and-self-signed-x509-certificates.html</guid><category>finalbuilder</category></item><item><title>Continua CI 1.8 Released</title><link>http://ciandcd.github.io/continua-ci-18-released.html</link><description>From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/745/continua-ci-18-released"&gt;https://www.finalbuilder.com/resources/blogs/postid/745/continua-ci-18-released&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;
&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;We are pleased to announce that Continua CI 1.8 has been released. It was actually released a couple of days ago, but for anyone who missed it, here is a heads up with and overview of the new features. We'd also like to thank all those who downloaded the beta - the time and effort spent reporting issues helped us to fix some important bugs and is most appreciated.&lt;/p&gt;
&lt;p&gt;Version 1.8 adds the following features which build upon all the improvements and fixes made to version 1.7.1.&lt;/p&gt;
&lt;h2&gt;Dashboard Filtering&lt;/h2&gt;
&lt;br&gt;&lt;p&gt;We've added a new filter box to the dashboard so you can quickly find the configuration (or project) that you are looking for as you type. Use the shortcut key F on the dashboard pages to focus on the filter box and start typing.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Dashboard filtering" src="/blogimages/daves/v1.8/DashboardFiltering.png"&gt;&lt;/p&gt;
&lt;br&gt;&lt;h2&gt;Shared Resources&lt;/h2&gt;
&lt;br&gt;&lt;p&gt;Many of you have requested more control over the number of builds which can run concurrently for some configurations. This may be to restrict the number of times a particular tool is run due to a license, memory or processor limit, or to prevent concurrency issues with multiple build stages simultaneously writing to the same file, folder or network resource.&lt;br&gt;
You can now allocate quotas to named Shared Resources and specify that builds and stages must acquire a lock on the Shared Resource before running. If all locks are allocated, then the build or stage will wait on the queue until a lock is released.&lt;/p&gt;
&lt;p&gt;Shared resources can be associated with the server or a particular agent in the Administration pages.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Agent shared resources" src="/blogimages/daves/v1.8/AgentSharedResources.png"&gt;&lt;/p&gt;
&lt;p&gt;Agent shared resources are acquired when selecting an agent to run a stage. Continua will select the agent with the largest available quota of each shared resource.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Stage shared resource locks" src="/blogimages/daves/v1.8/StageSharedResourceLocks.png"&gt;&lt;/p&gt;
&lt;p&gt;Server shared resources can also be acquired when selecting an agent, or while on the build queue after evaluating configuration conditions.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Shared resource lock configuration condition" src="/blogimages/daves/v1.8/SharedResourceLockCondition.png"&gt;&lt;/p&gt;
&lt;p&gt;We hope you find that shared resources can provide many different ways to control the build process.&lt;/p&gt;
&lt;br&gt;&lt;h2&gt;Requeue Build&lt;/h2&gt;
&lt;br&gt;&lt;p&gt;Sometimes a build may fail due to an offline network resource, or some logical error in the stage workflow. Up until now, your only option was to re-run a build for the same branch heads. If any new changesets had been committed to the branch since that build, then you are out of luck.&lt;/p&gt;
The new Requeue Build button on the Build View page allows you to requeue an existing build using the same changesets, variables and queue options. Any changes to the configuration such as stage actions or repositories are taken into account and used for the new build.
&lt;p&gt;The new Requeue Build button on the Build View page allows you to requeue an existing build using the same changesets, variables and queue options. Any changes to the configuration such as stage actions or repositories are taken into account and used for the new build.&lt;/p&gt;&lt;p&gt;&lt;img alt="Requeue build button" src="/blogimages/daves/v1.8/RequeueBuildButton.png"&gt;&lt;/p&gt;
&lt;p&gt;You can also change the priority, comment and variables before requeuing the build.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Requeue build options menu item" src="/blogimages/daves/v1.8/RequeueBuildOptionsMenuItem.png"&gt;&lt;/p&gt;
&lt;p&gt;Clicking on the &amp;#8220;Build requeue options&amp;#8221; menu item will open the Queue Options dialog.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Requeue options dialog" src="/blogimages/daves/v1.8/RequeueOptions.png"&gt;&lt;/p&gt;
&lt;br&gt;&lt;h2&gt;Persist Build Variables&lt;/h2&gt;
&lt;br&gt;&lt;p&gt;Another common request has been to persist variable values from one build to another build. This may be to keep a count of builds on a particular branch or to flag that some actions have been completed in one build and do not need to be repeated.&lt;/p&gt;
Continua CI takes a copy of configuration and project variables at the start of each build. These copies are referred to as build variables. Any changes to build variables are normally discarded when the build finishes and cannot be used by other builds.
&lt;p&gt;Continua CI takes a copy of configuration and project variables at the start of each build. These copies are referred to as build variables. Any changes to build variables are normally discarded when the build finishes and cannot be used by other builds.&lt;/p&gt;&lt;p&gt;&lt;img alt="First tab of Persist Build Variable build event handler dialog " src="/blogimages/daves/v1.8/PersistBuildVariable1.png"&gt;&lt;/p&gt;
&lt;p&gt;The new Persist Build Variable build event handler allows you to save the value of the build variables when specific events happen in the build timeline. This is stored as the value of the configuration variable. Subsequent builds will then pick up this revised value and use it as the initial value of the build variable.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Second tab of Persist Build Variable build event handler dialog " src="/blogimages/daves/v1.8/PersistBuildVariable2.png"&gt;&lt;/p&gt;
&lt;p&gt;As Continua CI allows multiple builds to run concurrently, it is important to control when the variables are overwritten. A later build may run faster and finish before a build which started earlier, causing unexpected results. &amp;#160;You can optionally state that a variable should not be persisted if the configuration variable has been modified (e.g. by another build) since a specified build event, such the build start.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Options tab of Persist Build Variable build event handler dialog " src="/blogimages/daves/v1.8/PersistBuildVariable3.png"&gt;&lt;/p&gt;
&lt;p&gt;You can also prevent concurrency issues by using this feature in conjunction with shared resource locks.&lt;/p&gt;
&lt;br&gt;&lt;h2&gt;Other New Features&lt;/h2&gt;
&lt;br&gt;&lt;ul&gt;&lt;li&gt;You can now set the Variables display order of variable prompts on the Queue Options dialog.&lt;/li&gt;
    &lt;li&gt;We have provided buttons for cloning Triggers, Repositories and Build Event Handlers.&lt;/li&gt;
    &lt;li&gt;Configuration Conditions can now be disabled.&lt;/li&gt;
    &lt;li&gt;All actions which run external processes now have a Timeout (in seconds) setting.&lt;/li&gt;
    &lt;li&gt;We have also added a new &lt;a href="http://cakebuild.net/" target="_blank"&gt;Cake &lt;/a&gt;build runner action and a new &lt;a href="https://msdn.microsoft.com/en-us/library/jj155796.aspx" target="_blank"&gt;VSTest&lt;/a&gt; unit testing action.&lt;/li&gt;
&lt;/ul&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Fri, 15 Apr 2016 04:07:29 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-04-15:continua-ci-18-released.html</guid><category>finalbuilder</category></item><item><title>Automise 5 Released!</title><link>http://ciandcd.github.io/automise-5-released.html</link><description>From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/744/automise-5-released"&gt;https://www.finalbuilder.com/resources/blogs/postid/744/automise-5-released&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Today we are delighted to release the Automise 5, which now includes a gift. Automise Run-time is now free.&lt;/p&gt;
&lt;p&gt;As explained in the Beta announcement, our continuous delivery cycle has worked well for Automise 4. Producing constant stream of updates and fixes. Now, with significant updates to the internal workings for Automise today we are releasing Automise 5. &lt;/p&gt;
&lt;h2&gt;What's new in Automise 5&lt;/h2&gt;
&lt;h3&gt;Stepping Engine&lt;/h3&gt;
&lt;p&gt;We have undertaken a major rewrite of the internal stepping engine for Automise 5. This has reduced the moving parts, while also enabling extra features to be implemented. In the end this will mean your projects will run faster, consume less resources, and also providing some extra tools for debugging projects.&lt;/p&gt;
&lt;h3&gt;Action List Dependencies&lt;/h3&gt;
&lt;p&gt;Action Lists can now list other action lists that they depend on. For example this allows specifying a UploadAndClean Action List that depends on the Clean and Upload Action Lists. When UploadAndClean is run, if the Clean and Upload Action Lists have not been run they will be. &lt;/p&gt;
&lt;p&gt;&lt;img alt="Action List Dependencies" src="/blogimages/jason/Automise5-beta-release/at5_actionlist_dependencies.png"&gt;&lt;/p&gt;
&lt;h3&gt;Step into included projects&lt;/h3&gt;
&lt;p&gt;Previously, debugging include project actions meant running the entire included project when stepping over the action. In Automise 5, debugging allows for stepping into the included project. This will open the included project, if is not already open, and start to debug that project. &lt;/p&gt;
&lt;h3&gt;Breakpoint Conditions&lt;/h3&gt;
&lt;p&gt;We have also added to the debugging experience with breakpoint conditions. These work like break point conditions in Visual Studio. They present options for stopping the executing of a script when variables have certain values, or a condition specified becomes true. Conditions can also be the number of passes over the breakpoint.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Action List Dependencies" src="https://www.finalbuilder.com/blogimages/jason/Automise5-beta-release/at5_breakpoint_properties.png"&gt;&lt;/p&gt;
&lt;h3&gt;IDE Themes (Light and Dark)&lt;/h3&gt;
&lt;p&gt;After five years we thought it was time Automise got a new coat of paint. We have implemented two new themes, a light and dark theme (defaulting to the dark on first run up). Choose your side wisely&amp;#8230;&lt;/p&gt;

            &lt;img alt="Action List Dependencies" src="https://www.finalbuilder.com/blogimages/jason/Automise5-beta-release/at5_dark_theme.png"&gt;
            
            &lt;img alt="Action List Dependencies" src="https://www.finalbuilder.com/blogimages/jason/Automise5-beta-release/at5_light_theme.png"&gt;
        &lt;h3&gt;Action List Out Parameters&lt;/h3&gt;
&lt;p&gt;Action Lists parameters can now be defined as an out parameter. These parameters can have their value set inside the action list. On exiting the action list the calling Run Action List action will set the variable assigned as the out variable with that value. This effectively adds the ability to have action lists work as functions and return values calculated in the action list.&lt;/p&gt;
&lt;h3&gt;Project Formats&lt;/h3&gt;
&lt;p&gt;Let&amp;#8217;s face it, xml files are difficult to diff. To make diffs easier Automise 5 has introduce two major updates to the Automise project file structure.&lt;/p&gt;
&lt;p&gt;&amp;#160; &amp;#160;1. A new DSL project file format (the new default format) (atp5)&lt;/p&gt;
&lt;p&gt;&amp;#160; &amp;#160;2. A new XML project file format (atx5)&lt;/p&gt;
&lt;p&gt;New Actions&lt;/p&gt;
&lt;p&gt;We have done some major work to bring new Azure and Amazon S3 actions to you. Some of these being:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Amazon S3 - Added bucket delete object, bucket list objects, bucket list, upload directory, and download folder actions.&lt;/li&gt;
    &lt;li&gt;Azure Actions - Added Login, Logout, Config Mode actions.&lt;/li&gt;
    &lt;li&gt;Azure Group Actions - Added Group Create, Group Delete, Group List, Group Log Show, Group Set, Group Show actions.&lt;/li&gt;
    &lt;li&gt;Azure VM - Added VM Capture, VM Create, VM Deallocate, VM Delete, VM List, VM List, VM Quick Create, VM Restart, VM Start, VM Stop actions.&lt;/li&gt;
    &lt;li&gt;Azure Storage - Added Storage File Copy Show, Storage File Copy Start, Storage File Copy Stop, Storage File Delete, Storage File Download, Storage File List, Storage File Upload actions.&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;New License Manager&lt;/h3&gt;
&lt;p&gt;Automise 5 introduces a new license manager that allows you to download licenses directly from the store. It will be presented to you on first load, or when no valid license has been found. You can also get to it from the Help menu.&lt;/p&gt;
&lt;p&gt;All that you will require to download a license from the store is your store credentials. It will then log in for you, and download a list of licenses that will work for the current version of Automise. If you had a current Automise 4 subscription as of 28 March 2016, you will already have an Automise 5 license waiting for you in your store account.&lt;/p&gt;
&lt;p&gt;In addition there is a simpler way to get Trial license, all that you require is a valid email address to receive a verification code on.&lt;/p&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Tue, 29 Mar 2016 06:32:13 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-03-29:automise-5-released.html</guid><category>finalbuilder</category></item><item><title>Introducing Continua CI Version 1.8 Beta</title><link>http://ciandcd.github.io/introducing-continua-ci-version-18-beta.html</link><description>From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/743/introducing-continua-ci-version-18-beta"&gt;https://www.finalbuilder.com/resources/blogs/postid/743/introducing-continua-ci-version-18-beta&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;
&lt;br&gt;&lt;br&gt;&lt;/p&gt;
This version adds several new features which build upon all the improvements and fixes made to version 1.7.1.&lt;br&gt;&lt;br&gt;&lt;h2&gt;Dashboard Filtering&lt;/h2&gt;
&lt;br&gt;&lt;p&gt;This version adds several new features which build upon all the improvements and fixes made to version 1.7.1.&lt;/p&gt;&lt;p&gt;We've added a new filter box to the dashboard so you can quickly find the configuration (or project) that you are looking for as you type. Use the shortcut key F on the dashboard pages to focus on the filter box and start typing.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Dashboard filtering" src="/blogimages/daves/v1.8/DashboardFiltering.png"&gt;&lt;/p&gt;
&lt;br&gt;&lt;h2&gt;Shared Resources&lt;/h2&gt;
&lt;br&gt;&lt;p&gt;Many of you have requested more control over the number of builds which can run concurrently for some configurations. This may be to restrict the number of times a particular tool is run due to a license, memory or processor limit, or to prevent concurrency issues with multiple build stages simultaneously writing to the same file, folder or network resource.&lt;br&gt;
You can now allocate quotas to named Shared Resources and specify that builds and stages must acquire a lock on the Shared Resource before running. If all locks are allocated, then the build or stage will wait on the queue until a lock is released.&lt;/p&gt;
&lt;p&gt;Shared resources can be associated with the server or a particular agent in the Administration pages.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Agent shared resources" src="/blogimages/daves/v1.8/AgentSharedResources.png"&gt;&lt;/p&gt;
&lt;p&gt;Agent shared resources are acquired when selecting an agent to run a stage. Continua will select the agent with the largest available quota of each shared resource.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Stage shared resource locks" src="/blogimages/daves/v1.8/StageSharedResourceLocks.png"&gt;&lt;/p&gt;
&lt;p&gt;Server shared resources can also be acquired when selecting an agent, or while on the build queue after evaluating configuration conditions.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Shared resource lock configuration condition" src="/blogimages/daves/v1.8/SharedResourceLockCondition.png"&gt;&lt;/p&gt;
&lt;p&gt;We hope you find that shared resources can provide many different ways to control the build process.&lt;/p&gt;
&lt;br&gt;&lt;h2&gt;Requeue Build&lt;/h2&gt;
&lt;br&gt;&lt;p&gt;Sometimes a build may fail due to an offline network resource, or some logical error in the stage workflow. Up until now, your only option was to re-run a build for the same branch heads. If any new changesets had been committed to the branch since that build, then you are out of luck.&lt;/p&gt;
The new Requeue Build button on the Build View page allows you to requeue an existing build using the same changesets, variables and queue options. Any changes to the configuration such as stage actions or repositories are taken into account and used for the new build.
&lt;p&gt;The new Requeue Build button on the Build View page allows you to requeue an existing build using the same changesets, variables and queue options. Any changes to the configuration such as stage actions or repositories are taken into account and used for the new build.&lt;/p&gt;&lt;p&gt;&lt;img alt="Requeue build button" src="/blogimages/daves/v1.8/RequeueBuildButton.png"&gt;&lt;/p&gt;
&lt;p&gt;You can also change the priority, comment and variables before requeuing the build.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Requeue build options menu item" src="/blogimages/daves/v1.8/RequeueBuildOptionsMenuItem.png"&gt;&lt;/p&gt;
&lt;p&gt;Clicking on the &amp;#8220;Build requeue options&amp;#8221; menu item will open the Queue Options dialog.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Requeue options dialog" src="/blogimages/daves/v1.8/RequeueOptions.png"&gt;&lt;/p&gt;
&lt;br&gt;&lt;h2&gt;Persist Build Variables&lt;/h2&gt;
&lt;br&gt;&lt;p&gt;Another common request has been to persist variable values from one build to another build. This may be to keep a count of builds on a particular branch or to flag that some actions have been completed in one build and do not need to be repeated.&lt;/p&gt;
Continua CI takes a copy of configuration and project variables at the start of each build. These copies are referred to as build variables. Any changes to build variables are normally discarded when the build finishes and cannot be used by other builds.
&lt;p&gt;Continua CI takes a copy of configuration and project variables at the start of each build. These copies are referred to as build variables. Any changes to build variables are normally discarded when the build finishes and cannot be used by other builds.&lt;/p&gt;&lt;p&gt;&lt;img alt="First tab of Persist Build Variable build event handler dialog " src="/blogimages/daves/v1.8/PersistBuildVariable1.png"&gt;&lt;/p&gt;
&lt;p&gt;The new Persist Build Variable build event handler allows you to save the value of the build variables when specific events happen in the build timeline. This is stored as the value of the configuration variable. Subsequent builds will then pick up this revised value and use it as the initial value of the build variable.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Second tab of Persist Build Variable build event handler dialog " src="/blogimages/daves/v1.8/PersistBuildVariable2.png"&gt;&lt;/p&gt;
&lt;p&gt;As Continua CI allows multiple builds to run concurrently, it is important to control when the variables are overwritten. A later build may run faster and finish before a build which started earlier, causing unexpected results. &amp;#160;You can optionally state that a variable should not be persisted if the configuration variable has been modified (e.g. by another build) since a specified build event, such the build start.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Options tab of Persist Build Variable build event handler dialog " src="/blogimages/daves/v1.8/PersistBuildVariable3.png"&gt;&lt;/p&gt;
&lt;p&gt;You can also prevent concurrency issues by using this feature in conjunction with shared resource locks.&lt;/p&gt;
&lt;br&gt;&lt;h2&gt;Other New Features&lt;/h2&gt;
&lt;br&gt;&lt;ul&gt;&lt;li&gt;You can now set the Variables display order of variable prompts on the Queue Options dialog.&lt;/li&gt;
    &lt;li&gt;We have provided buttons for cloning Triggers, Repositories and Build Event Handlers.&lt;/li&gt;
    &lt;li&gt;Configuration Conditions can now be disabled.&lt;/li&gt;
    &lt;li&gt;We have also added a new &lt;a href="http://cakebuild.net/"&gt;Cake &lt;/a&gt;build runner action&lt;/li&gt;
&lt;/ul&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Wed, 09 Mar 2016 03:10:00 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-03-09:introducing-continua-ci-version-18-beta.html</guid><category>finalbuilder</category></item><item><title>Automise 5 Beta</title><link>http://ciandcd.github.io/automise-5-beta.html</link><description>From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/741/automise-5-beta"&gt;https://www.finalbuilder.com/resources/blogs/postid/741/automise-5-beta&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Today we are delighted to release the Automise 5 BETA, which contains our new Stepping Engine and Action List Dependencies as the headline features. &lt;/p&gt;
&lt;p&gt;For five years we have updated and improved Automise 4 through our continuous delivery cycle.&amp;#160;This has worked well. Allowing for improvements to actions (like FTP\SFTP\FTPS suite) to come out gradually and consistently. Allowing everyone to pick and choose at which point to take feature updates.&lt;/p&gt;
&lt;p&gt;The Automise 5 signals a major "tick" to this regular flow of updates. The majority of these updates are at the core of what Automise does to solve your automation challenges.&lt;/p&gt;
&lt;h2&gt;What's new in Automise 5&lt;/h2&gt;
&lt;h3&gt;Stepping Engine&lt;/h3&gt;
&lt;p&gt;We have undertaken a major rewrite of the internal stepping engine for Automise 5. This has reduced the moving parts, while also enabled extra features to be implemented. In the end this will mean your projects will run faster, consume less resources, while also providing some extra tools for debugging projects.&lt;/p&gt;
&lt;h3&gt;Action List Dependencies&lt;/h3&gt;
&lt;p&gt;Action Lists now allow for listing of other Actions Lists they are dependent on. Dependencies are always run before the action lists which depend on them. For example this allows specifying a UploadAndClean Action List that depends on the Clean and Upload Action List. When UploadAndClean is run, if the Clean and Upload Action Lists have not been run they will be.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Action List Dependencies" src="/blogimages/jason/Automise5-beta-release/at5_actionlist_dependencies.png"&gt;&lt;/p&gt;
&lt;h3&gt;Step into included projects&lt;/h3&gt;
&lt;p&gt;Due to the previous version of the stepping engine stepping into included projects was not possible. Instead the user had to wait for the included project to complete before continuing with debugging. Stepping into included projects with Automise 5 will now open the included project, and continue stepping from inside the included project.&lt;/p&gt;
&lt;h3&gt;Breakpoint Conditions&lt;/h3&gt;
&lt;p&gt;Another addition to the debugging experience is breakpoint conditions. These allow stopping the executing of a script at a certain point in time. Conditions can be a number of passes over the breakpoint, or when a variable equals a certain value.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Action List Dependencies" src="https://www.finalbuilder.com/blogimages/jason/Automise5-beta-release/at5_breakpoint_properties.png"&gt;&lt;/p&gt;
&lt;h3&gt;IDE Themes (Light and Dark)&lt;/h3&gt;
&lt;p&gt;After five years we thought it was time Automise got a new coat of paint. We have implemented two new themes, a light and dark theme (defaulting to the dark on first run up).&lt;/p&gt;

            &lt;img alt="Action List Dependencies" src="https://www.finalbuilder.com/blogimages/jason/Automise5-beta-release/at5_dark_theme.png"&gt;
            
            &lt;img alt="Action List Dependencies" src="https://www.finalbuilder.com/blogimages/jason/Automise5-beta-release/at5_light_theme.png"&gt;
        &lt;h3&gt;Action List Out Parameters&lt;/h3&gt;
&lt;p&gt;Action Lists now allow for retrieving any number of values from them. A variable assigned to the out parameter on the Action List will be given the value of that parameter when the Action List has completed. This will allow for more Action Lists that generate values for use else where in the Automise Project.&lt;/p&gt;
&lt;h3&gt;Project Formats&lt;/h3&gt;
&lt;p&gt;Since the start of Automise the project files have used XML for their structure. As Automise has grown, so too have the elements in the projects XML file. This has placed more strain on those left to diff versions of Automise projects.&lt;/p&gt;
&lt;p&gt;To aleavate this challenge Automise 5 has introduce two major updates to the Automise project file structure.&lt;/p&gt;
&lt;p&gt;&amp;#160; &amp;#160;1. A new DSL project file format (the new default format)&lt;/p&gt;
&lt;p&gt;&amp;#160; &amp;#160;2. A new XML project file format&lt;/p&gt;
&lt;p&gt;The new Automise DSL structure is concise, and very simple to diff.&lt;/p&gt;
&lt;pre class="brush:delphi; toolbar:true;"&gt;project
begin
    projectid = {04710B72-066E-46E7-84C7-C04A0D8BFE18}
    Action List
    begin
        name = Default
        Action Listid = {E6DE94D6-5484-45E9-965A-DB69885AA5E2}
        rootaction
        begin
            action.group
            begin
                id = {D860420B-DE46-4806-959F-8A92A0C86429}
            end
        end
    end
end
&lt;/pre&gt;
The new Automise XML structure is a great deal less verbose than the older format.
&lt;pre class="brush:xml; toolbar:true;"&gt;&amp;lt;?xml version="1.0" encoding="UTF-8"?&amp;gt;
&amp;lt;Automise&amp;gt;
    &amp;lt;project&amp;gt;
        &amp;lt;projectid&amp;gt;{6A717C24-D00F-4983-9FD0-148B2C609634}&amp;lt;/projectid&amp;gt;
        &amp;lt;Action List&amp;gt;
            &amp;lt;name&amp;gt;Default&amp;lt;/name&amp;gt;
            &amp;lt;Action Listid&amp;gt;{E6DE94D6-5484-45E9-965A-DB69885AA5E2}&amp;lt;/Action Listid&amp;gt;
            &amp;lt;rootaction&amp;gt;
                &amp;lt;action.group&amp;gt;
                    &amp;lt;id&amp;gt;{D860420B-DE46-4806-959F-8A92A0C86429}&amp;lt;/id&amp;gt;
                &amp;lt;/action.group&amp;gt;
            &amp;lt;/rootaction&amp;gt;
        &amp;lt;/Action List&amp;gt;
    &amp;lt;/project&amp;gt;
&amp;lt;/Automise&amp;gt;
&lt;/pre&gt;
&lt;p&gt;The new Automise XML structure is a great deal less verbose than the older format.&lt;/p&gt;&lt;p&gt;&amp;#160;&lt;/p&gt;
&lt;h3&gt;New Actions&lt;/h3&gt;
&lt;p&gt;Not much to report here, most of the focus has been on the Stepping engine and the IDE. We do have some updates to AWS EC2 and Azure in progress, they will most likely be added in an update when they are ready.&amp;#160;&lt;/p&gt;
&lt;h3&gt;How do I get the Beta?&lt;/h3&gt;
&lt;p&gt;Links to the beta downloads will be published to the&amp;#160;&lt;/p&gt;&lt;a href="https://www.finalbuilder.com/downloads/automise"&gt;Automise Downloads&lt;/a&gt;&lt;p&gt;&amp;#160;page.&amp;#160;&lt;/p&gt;
&lt;h3&gt;What if I find a bug?&lt;/h3&gt;
&lt;p&gt;Email support (please added Beta to the subject). When reporting an issue, be sure to include the beta build number and details about your environment. Please test with the latest beta build before reporting bugs.&amp;#160;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;We are particularly keen for people to load up their existing projects from older (ie 4 or earlier) versions of Automise, save them in AT5 format, and load them again and confirm that everything loaded ok.&amp;#160;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;h3&gt;When will it be released?&lt;/h3&gt;
&lt;h3&gt;&lt;/h3&gt;
&lt;p&gt;When it's ready ;) Seriously, though, we expect the release to happen in the next few weeks. Automise 5 is based on FinalBuilder 8, which has been out for several months now and is quite stable.&amp;#160;&lt;/p&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Thu, 21 Jan 2016 06:06:13 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-01-21:automise-5-beta.html</guid><category>finalbuilder</category></item><item><title>Code Signing Changes for 2016</title><link>http://ciandcd.github.io/code-signing-changes-for-2016.html</link><description>From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/742/code-signing-changes-for-2016"&gt;https://www.finalbuilder.com/resources/blogs/postid/742/code-signing-changes-for-2016&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;a&gt;&lt;/a&gt;&lt;br&gt;&lt;h3&gt; What do I need to do?&lt;/h3&gt;
First things first, check your code signing certificate. If it's current, and uses SHA1, contact your certificate issuer for a replacement SHA256 certificate. Most issuers have a formal process for this since this is something they have known about for a while and should not charge extra (KSoftware/Comodo do not charge). In our case, our certificate was renewed in Nov 2014 and was already an SHA256 certificate.&amp;#160;&lt;br&gt;&lt;br&gt;&lt;h3&gt; What if I need to support Windows XP/Server 2003?&lt;/h3&gt;
Windows XP &amp;amp; Server 2003 do not support SHA256, so this deprecation of SHA1 does not apply to those versions of windows. If you sign with your SHA256 certificate using the SHA256 digest algorithm, you will find you code is not trusted on those versions of windows. The trick is to use the SHA1 digest algorithm.&amp;#160; &amp;#160; &lt;br&gt;&lt;br&gt;&lt;h3&gt;So do I need separate installers for XP and Windows 7+ ? &lt;/h3&gt;
Well that's one way to do it, but you can support XP and windows 7+ with a single installer or exe, by signing twice, with SHA1 and SHA256.&amp;#160; &lt;br&gt;&lt;br&gt;
NOTE: If you are a long time FinalBuilder user and still using the Authenticode action, then don't, it's been deprecated for some time as it uses the &lt;a&gt;&lt;/a&gt;&lt;br&gt;&lt;br&gt;
Recent versions of &lt;a&gt;&lt;/a&gt;&lt;br&gt;&lt;br&gt;
In my experiments, I found that you need to sign with SHA1 first, then SHA256. The reason for this is that WinXP only looks at the first signature and would not recognise the timestamps from any RFC3161 timestamp servers that I tried. The signtool options that allow adding additional signatures (/as for signing, /tp for timestamping) only work with RFC3161 compliant timestamp servers, so the SHA1 signature and timestamp must be done first since we can't use /as or /tp with a non RFC3161 timestamp server.&amp;#160;&lt;br&gt;&lt;br&gt;&lt;h3&gt; Sign, then TimeStamp&lt;/h3&gt;
Whilst signtool can sign and timestamp in a single operation (and the &lt;a&gt;&lt;/a&gt;&lt;br&gt;&lt;br&gt;
By doing the timestamp operation separately, we can retry if timestamping fails. Often, just a few seconds between retries is enough (unless your internet connection is down), and there is always the option of using a different timestamp server. &amp;#160; &lt;br&gt;&lt;br&gt;
So the order of events is :&lt;br&gt;&lt;br&gt;
Sign SHA1.&lt;br&gt;
Sign SHA256 (with append signature /as).&lt;br&gt;
Timestamp SHA1 - using older style authenticode timestamp server.&lt;br&gt;
Timestamp SHA256 (/tp &lt;p&gt;with index 1&amp;#160;&lt;/p&gt;) - using an RFC3161 compliant timestamp server.&lt;br&gt;&lt;br&gt;&lt;h3&gt;Show me how!&lt;/h3&gt;
I have created an examples repository on github : &lt;a&gt;&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;h3&gt;
References&lt;/h3&gt;
&lt;a href="https://www.comodo.com/e-commerce/SHA-2-transition.php" target="_blank"&gt;https://www.comodo.com/e-commerce/SHA-2-transition.php&lt;/a&gt;&lt;br&gt;&lt;a class="moz-txt-link-freetext" href="http://social.technet.microsoft.com/wiki/contents/articles/32288.windows-enforcement-of-authenticode-code-signing-and-timestamping.aspx" target="_blank"&gt;http://social.technet.microsoft.com/wiki/contents/articles/32288.windows-enforcement-of-authenticode-code-signing-and-timestamping.aspx&lt;/a&gt;\&amp;#13;
                        &lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;p&gt;Microsoft announced some time ago that windows 7 &amp;amp; higher would no longer trust anything that is code signed with an SHA1 ( &lt;a class="moz-txt-link-freetext" href="https://en.wikipedia.org/wiki/SHA-1"&gt;https://en.wikipedia.org/wiki/SHA-1&lt;/a&gt; ) certificate as of 1st Jan 2016. The reason for this is well documented, SHA1 has become increasingly vulnerable and is no longer secure enough to be trusted.First things first, check your code signing certificate. If it's current, and uses SHA1, contact your certificate issuer for a replacement SHA256 certificate. Most issuers have a formal process for this since this is something they have known about for a while and should not charge extra (KSoftware/Comodo do not charge). In our case, our certificate was renewed in Nov 2014 and was already an SHA256 certificate.Windows XP &amp;amp; Server 2003 do not support SHA256, so this deprecation of SHA1 does not apply to those versions of windows. If you sign with your SHA256 certificate using the SHA256 digest algorithm, you will find you code is not trusted on those versions of windows. The trick is to use the SHA1 digest algorithm.Well that's one way to do it, but you can support XP and windows 7+ with a single installer or exe, by signing twice, with SHA1 and SHA256.NOTE: If you are a long time FinalBuilder user and still using the Authenticode action, then don't, it's been deprecated for some time as it uses the &lt;a href="http://blogs.msdn.com/b/karinm/archive/2009/01/19/capicom-dll-removed-from-windows-sdk-for-windows-7.aspx" target="_blank" title="Capicom deprecated blog post."&gt;deprecated capicom.dll api&lt;/a&gt; . The only reason we haven't removed it is to avoid errors when you load your old projects. The correct actions to use for code signing are the SignTool actions.Recent versions of &lt;a href="https://msdn.microsoft.com/en-us/library/8s9b9yaz(v=vs.110).aspx" target="_blank" title="Signtool documentation."&gt;Signtool.exe&lt;/a&gt; include a switch (/as) to append a signature ( the default operation is to replace the primary signature). I believe the windows 8.1 sdk was the first version to include this option (and other related options).In my experiments, I found that you need to sign with SHA1 first, then SHA256. The reason for this is that WinXP only looks at the first signature and would not recognise the timestamps from any RFC3161 timestamp servers that I tried. The signtool options that allow adding additional signatures (/as for signing, /tp for timestamping) only work with RFC3161 compliant timestamp servers, so the SHA1 signature and timestamp must be done first since we can't use /as or /tp with a non RFC3161 timestamp server.Whilst signtool can sign and timestamp in a single operation (and the &lt;a href="http://wiki.finalbuilder.com/display/FB8/Signtool+Sign+Files+Action" target="_blank" title="Signtool Sign Action help."&gt;SignTool Sign&lt;/a&gt; action in FinalBuilder can too), I prefer to do the timestamp step separately. The reason for this is that signing rarely fails (typically only when the certificate has expired or you get the password wrong!), but timestamping fails often, because the timestamp server may be unreachable or it just has some issue and doesn't respond correctly.By doing the timestamp operation separately, we can retry if timestamping fails. Often, just a few seconds between retries is enough (unless your internet connection is down), and there is always the option of using a different timestamp server.So the order of events is :Sign SHA1.Sign SHA256 (with append signature /as).Timestamp SHA1 - using older style authenticode timestamp server.Timestamp SHA256 (/tp) - using an RFC3161 compliant timestamp server.I have created an examples repository on github : &lt;a href="https://github.com/VSoftTechnologies/FinalBuilder.Examples" target="_blank"&gt;FinalBuilder Examples&lt;/a&gt; - you can find a nice example there showing how to double (optionally) sign and then timestamp (with retries). This example requires FinalBuilder 8.0.0.1490 or later (added support for /tp option on timestamp action).&lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Wed, 20 Jan 2016 05:18:10 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2016-01-20:code-signing-changes-for-2016.html</guid><category>finalbuilder</category></item><item><title>VSoft.CommandLineParser for Delphi</title><link>http://ciandcd.github.io/vsoftcommandlineparser-for-delphi.html</link><description>From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/740/vsoftcommandlineparser-for-delphi-updated"&gt;https://www.finalbuilder.com/resources/blogs/postid/740/vsoftcommandlineparser-for-delphi-updated&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;A while back I published the VSoft.CommandLineParser library on github, which makes it simple to handle command line options in delphi applications. The first version only did enough to satisfy the needs I had in DUnitX. &lt;/p&gt;
&lt;p&gt;In another project I&amp;#8217;m working on, I needed a command mode, where each command had a unique set of options, but keeping the ability to have global options.&amp;#160; I have tried to implement the command mode in a backwards compatable manner, and so far the only change I had to make to an existing project was adding a const to a parameter. &lt;/p&gt;
&lt;h3&gt;Adding Commands&lt;/h3&gt;
&lt;p&gt;Adding commands is quite simple, using TOptionsRegistry.RegisterCommand. &lt;/p&gt;
&lt;pre class="brush:delphi; toolbar:true;"&gt;cmd := TOptionsRegistry.RegisterCommand('help','h','get some help','','commandsample help [command]'); 
option := cmd.RegisterUnNamedOption&amp;lt;string&amp;gt;('The command you need help for', 
  procedure(const value : string) 
  begin 
    THelpOptions.HelpCommand := value; 
  end);&lt;/pre&gt;
&lt;p&gt;Note: this method returns a TCommandDefinition record that you can add options to. The reason for using a record rather than an interface here, is because delphi interfaces do not suport generic methods. Records do, so we use the record type as a wrapper around the ICommandDefinition interface.&lt;/p&gt;
&lt;p&gt;The helpstring parameter allows you to specify a longer help message that can be displayed when showing command usage.&lt;/p&gt;
&lt;h3&gt;Handling Commands&lt;/h3&gt;
&lt;p&gt;The ICommandLineParseResult interface has a new Command property (string) which is used to determine the selected command. It&amp;#8217;s up to you how to actually run the commands. &lt;/p&gt;
&lt;h3&gt;Showing Usage&lt;/h3&gt;
&lt;p&gt;The PrintUsage method now has some overloads and has some formatting improvements, and TOptionsRegistry also has new EnumerateCommands and EmumerateCommandOptions methods which make it relatively simple to handle showing usage etc yourself if you want to. &lt;/p&gt;
&lt;h3&gt;Where is it?&lt;/h3&gt;
&lt;p&gt;The source with samples is available on GitHub - &lt;a title="https://github.com/VSoftTechnologies/VSoft.CommandLineParser" href="https://github.com/VSoftTechnologies/VSoft.CommandLineParser" target="_blank"&gt;https://github.com/VSoftTechnologies/VSoft.CommandLineParser&lt;/a&gt;&lt;/p&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Fri, 11 Dec 2015 04:24:20 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2015-12-11:vsoftcommandlineparser-for-delphi.html</guid><category>finalbuilder</category></item><item><title>Modifying XML Manifest files with FinalBuilder</title><link>http://ciandcd.github.io/modifying-xml-manifest-files-with-finalbuilder.html</link><description>From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/739/modifying-xml-manifest-files-with-finalbuilder"&gt;https://www.finalbuilder.com/resources/blogs/postid/739/modifying-xml-manifest-files-with-finalbuilder&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;br&gt;&lt;br&gt;
So lets define our XML Document by adding an &lt;a&gt;&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;This topic is something that I pulled from our support system, it's something we get asked about more that once a year, that is, how do I modify the xml manifest file using FinalBuilder. Typically its the assembly version attribute that users want to modify, so that's what I'll show here, but you can use the same technique to edit other parts of the manifest file.So lets define our XML Document by adding an &lt;a href="http://wiki.finalbuilder.com/display/FB8/XML+Document+Define+Action" target="_blank" title="XML Document Define Action Documentation"&gt;XML Document Define Action&lt;/a&gt; , and point it at our manifest file.&lt;/p&gt;&lt;p&gt;
&lt;img src="/blogimages/vincent/manifest/manifest-xml-doc.png" alt="Define XML Document"&gt;&lt;/p&gt;
&lt;br&gt;
If you open your manifest file in notpad, you will notice assembly element looks something like this :&lt;br&gt;&lt;br&gt;&lt;pre class="brush:xml; toolbar:true;"&gt;&amp;lt;assembly xmlns="urn:schemas-microsoft-com:asm.v1"  manifestVersion="1.0" &amp;gt;
&lt;/pre&gt;
&lt;br&gt;
Note the xmlns attribute, this is what causes users problems with the xml actions in FinalBuilder, XML Namespaces. The MXSML Parser is very strict when it comes to namespaces, and it requires that we make use of them when using XPath to select nodes.&amp;#160;On the XML Document action, switch to the MSXML Parser tab and in the Extra Namespaces grid, add the following.&amp;#160;&lt;br&gt;&lt;br&gt;&lt;p&gt;If you open your manifest file in notpad, you will notice assembly element looks something like this :Note the xmlns attribute, this is what causes users problems with the xml actions in FinalBuilder, XML Namespaces. The MXSML Parser is very strict when it comes to namespaces, and it requires that we make use of them when using XPath to select nodes. On the XML Document action, switch to the MSXML Parser tab and in the Extra Namespaces grid, add the following.&lt;/p&gt;&lt;p&gt;
&lt;img src="/blogimages/vincent/manifest/manifest-xml-doc2.png" alt="Namespace Prefix"&gt;&lt;/p&gt;
&lt;br&gt;
What we are doing here is assigning a prefix (x in this case) to the namespace. This prefix will be used in our XPath statements.&lt;br&gt;&lt;br&gt;
Add an&lt;a&gt;&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;What we are doing here is assigning a prefix (x in this case) to the namespace. This prefix will be used in our XPath statements.Add an &lt;a href="http://wiki.finalbuilder.com/display/FB8/Edit+XML+File+Action" target="_blank" title="Edit XML File Action documentation"&gt; Edit XML File action&lt;/a&gt; - set the XML File to use an XML Document and select the document we defined with the previous action. Now we need to define the XPath statement to the version attribute that we are going to modify.&lt;/p&gt;&lt;p&gt;
&lt;img src="/blogimages/vincent/manifest/manifest-xml-edit-version.png" alt="Edit XML"&gt;&lt;/p&gt;
&lt;br&gt;
And finally, add a Save XML Document Action to save our changes to the file. Note that if you are editing other parts of the manifest file, make sure you add the namespaces and different prefixes, and use this prefixes appropriately in your XPath statements.&lt;br&gt;&lt;br&gt;
Note, all of this could be done in a single Edit XML File action, however, if you want to make more than one modification to the manifest file then it's more efficient to use the xml document define action to avoid loading/parsing/saving the document for each edit.&amp;#160;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;p&gt;And finally, add a Save XML Document Action to save our changes to the file. Note that if you are editing other parts of the manifest file, make sure you add the namespaces and different prefixes, and use this prefixes appropriately in your XPath statements.Note, all of this could be done in a single Edit XML File action, however, if you want to make more than one modification to the manifest file then it's more efficient to use the xml document define action to avoid loading/parsing/saving the document for each edit.&lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Tue, 08 Dec 2015 04:37:47 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2015-12-08:modifying-xml-manifest-files-with-finalbuilder.html</guid><category>finalbuilder</category></item><item><title>Delphi Code Coverage with Continua CI</title><link>http://ciandcd.github.io/delphi-code-coverage-with-continua-ci.html</link><description>From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/738/delphi-code-coverage-with-continua-ci"&gt;https://www.finalbuilder.com/resources/blogs/postid/738/delphi-code-coverage-with-continua-ci&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;
Testing code is something we all do. Whether it be manual usability testing, unit testing, or integration testing, knowing how much of the application is covered by the tests is important. Without knowing what parts of the application are covered, there is no way to know if key features are tested.&lt;br&gt;&lt;br&gt;
When performing unit testing there is an analytical way to determine what parts of the source code are covered by the tests. This is typically call source code coverage. Working with Delphi, one of the tools that performs this task is called DelphiCodeCoverage (open source). It can be located on &lt;a href="https://github.com/NeonGraal/DelphiCodeCoverage"&gt;GitHub&lt;/a&gt;&amp;#160;(more recent fork)&amp;#160;and &lt;a href="http://sourceforge.net/projects/delphicodecoverage"&gt;SourceForge&lt;/a&gt;. Under the hood this tool simply marks each line of source code as "hit" when the application calls it at least once. From there it can generate a detailed report giving the overall coverage statistics for the project, as well as the individual lines not hit in the testing.
&lt;/p&gt;
&lt;p&gt;
&lt;img alt="" src="https://www.finalbuilder.com/blogImages/jason/DelphiCodeCoverage/CodeCoverage_ContinuaCoverageReport.png"&gt;&lt;/p&gt;
&lt;h2&gt;Code Coverage&lt;/h2&gt;
What I will go through below is how to setup code coverage on a unit test project, and hook that into a continuous integration process using Continua CI. I will assume that if you require knowledge on how to setup a project on Continua CI you will refer to the &lt;a&gt;&lt;/a&gt;&lt;br&gt;&lt;br&gt;
The code that I would like to get a code coverage report on is the &lt;a&gt;&lt;/a&gt;&lt;a&gt;&lt;/a&gt;&lt;br&gt;&lt;br&gt;
An extra consideration to have with a unit testing project is to make sure it can run under continuous integration. This means that it should run to completion and produce an output file that is able to be imported into the build summary. With this in mind I have created a "CI" &lt;a&gt;&lt;/a&gt;&lt;br&gt;&lt;br&gt;
All this code and other related scripts are located in the &lt;a&gt;&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;h2&gt;DelphiCodeCoverage&lt;/h2&gt;
To generate a code coverage report I decided to use DelphiCodeCoverage. The tool has a number of command line options, all of which are spelt out on the GitHub page. Some of the options are a little overwhelming in the effort they require. An example of this is passing a file that contains all the source directories to search for classes to include in the code coverage report. Thankfully there is a wizard supplied with DelphiCodeCoverage that will help generate a batch file containing the correct parameters to pass to DelphiCodeCoverage.&amp;#160;&lt;br&gt;&lt;br&gt;
In my project I have placed DelphiCodeCoverage into a sub-folder call "CodeCoverage" and included it into source control. There are two reasons I am doing this;&lt;br&gt;
1. The code coverage executable is now available everywhere the source is pulled to.&amp;#160;&lt;br&gt;
2. It simplifies the script I will need for the CI Server.&amp;#160;&lt;br&gt;
If your uncomfortable with placing binaries into your source control, this can be altered without affecting the produced report.&amp;#160;&lt;br&gt;&lt;br&gt;
Running the code coverage wizard your presented with a page to enter the executable, map file, source, and output directory locations. Below are the settings I have used:
&lt;p&gt;What I will go through below is how to setup code coverage on a unit test project, and hook that into a continuous integration process using Continua CI. I will assume that if you require knowledge on how to setup a project on Continua CI you will refer to the &lt;a href="http://wiki.finalbuilder.com/display/continua/Part+1%3A+Create+your+First+Project"&gt;Create your First Project&lt;/a&gt; wiki page.The code that I would like to get a code coverage report on is the &lt;a href="https://github.com/VSoftTechnologies/DelphiCodeCoverageExample/blob/master/Core/Core.Card.pas" target="_blank"&gt;Core.Card.pas&lt;/a&gt; unit. The unit tests for this class are located in the tests folder and have a corresponding name of &lt;a href="https://github.com/VSoftTechnologies/DelphiCodeCoverageExample/blob/master/Tests/Core.CardTests.pas" target="_blank"&gt;Core.CardTests.pas&lt;/a&gt; . You may have noticed that some of the code paths are not fully covered in my unit tests. This is intentional, and something that we will come to a little later on.An extra consideration to have with a unit testing project is to make sure it can run under continuous integration. This means that it should run to completion and produce an output file that is able to be imported into the build summary. With this in mind I have created a "CI" &lt;a href="http://wiki.finalbuilder.com/display/continua/Configurations" target="_blank"&gt;configuration&lt;/a&gt; on my unit testing project. This conditionally compiles the unit testing project so that it does not wait for user input (something my debug configuration does) and generates an XML output file.All this code and other related scripts are located in the &lt;a href="https://github.com/VSoftTechnologies/DelphiCodeCoverageExample"&gt;VSoftTechnologies/DelphiCodeCoverageExample&lt;/a&gt; GitHub repository. Feel free to clone it to get a better sense of code coverage and the project structure I am using.To generate a code coverage report I decided to use DelphiCodeCoverage. The tool has a number of command line options, all of which are spelt out on the GitHub page. Some of the options are a little overwhelming in the effort they require. An example of this is passing a file that contains all the source directories to search for classes to include in the code coverage report. Thankfully there is a wizard supplied with DelphiCodeCoverage that will help generate a batch file containing the correct parameters to pass to DelphiCodeCoverage.In my project I have placed DelphiCodeCoverage into a sub-folder call "CodeCoverage" and included it into source control. There are two reasons I am doing this;1. The code coverage executable is now available everywhere the source is pulled to.2. It simplifies the script I will need for the CI Server.If your uncomfortable with placing binaries into your source control, this can be altered without affecting the produced report.Running the code coverage wizard your presented with a page to enter the executable, map file, source, and output directory locations. Below are the settings I have used:&lt;/p&gt;&lt;p&gt;
&lt;br&gt;&lt;br&gt;&lt;img alt="" src="https://www.finalbuilder.com/blogImages/jason/DelphiCodeCoverage/CodeCoverageWizard_Executable.png"&gt;&lt;br&gt;&lt;br&gt;&lt;img alt="" src="https://www.finalbuilder.com/blogImages/jason/DelphiCodeCoverage/CodeCoverageWizard_Source.png"&gt;&lt;br&gt;&lt;br&gt;&lt;img alt="" src="https://www.finalbuilder.com/blogImages/jason/DelphiCodeCoverage/CodeCoverageWizard_Output.png"&gt;&lt;br&gt;&lt;br&gt;&lt;img alt="" src="https://www.finalbuilder.com/blogImages/jason/DelphiCodeCoverage/CodeCoverageWizard_Settings.png"&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
The last option for the wizard allows for making all paths relative. This is exactly what we require to have our generated batch file run on any system, however at the time of writing it does not work correctly. This meant that I had to manually change all paths to a version that was relative to the folder in which DelphiCodeCoverage was located.
&lt;h4&gt;dcov_execute.bat before&lt;/h4&gt;
&lt;pre class="brush:delphi; toolbar:true;"&gt;"I:\Examples\DUnitX_CodeCoverage\CodeCoverage\CodeCoverage.exe" 
-e "I:\Examples\DUnitX_CodeCoverage\Win32\Debug\DUnitX_And_CodeCoverage.exe" 
-m "I:\Examples\DUnitX_CodeCoverage\Win32\Debug\DUnitX_And_CodeCoverage.map" 
-uf dcov_units.lst -spf dcov_paths.lst 
-od "I:\Examples\DUnitX_CodeCoverage\CodeCoverage\Output\" -lt -html
&lt;/pre&gt;
&lt;h4&gt;dcov_execute.bat after&lt;/h4&gt;
&lt;pre class="brush:delphi; toolbar:true;"&gt;"CodeCoverage.exe" 
-e "..\Win32\CI\DUnitX_And_CodeCoverage.exe" 
-m "..\Win32\CI\DUnitX_And_CodeCoverage.map" 
-ife -uf dcov_units.lst -spf dcov_paths.lst -od ".\Output\" -lt -html
&lt;/pre&gt;
Note: Line breaks are only included above for readability. There are none in the resulting batch files.
&lt;br&gt;&lt;br&gt;
Another alteration that I have made to the batch file is to include the "-ife" option. The option will include file extensions. This means that it will stop a unit like "Common.Encoding" being 'converted' to "Common". As in my project I have unit called "Core.Cards.pas" this option is required to have it included in generated code coverage report.&amp;#160;&lt;br&gt;&lt;br&gt;
Next the relative path change should be applied to the two generated list files &lt;a&gt;&lt;/a&gt;&lt;a&gt;&lt;/a&gt;&lt;br&gt;&lt;br&gt;
Now that the batch file and list files have been corrected running the dcov_executable.bat should produce summary out similar to that below. Note that the unit test project needs to be compiled as DelphiCodeCoverage runs the unit test executable.&lt;br&gt;&lt;pre class="brush:delphi; toolbar:true;"&gt;**********************************************************************
*              DUnitX - (c) 2013 Vincent Parrett                     *
*                    vincent@finalbuilder.com                        *
*                                                                    *
*        License - http://www.apache.org/licenses/LICENSE-2.0        *
**********************************************************************
  Fixture : Core
  -------------------------------------------------
     Fixture : Core.CardTests
     -------------------------------------------------
        Fixture : Core.CardTests.TCardTest
        -------------------------------------------------
          Test : Core.CardTests.TCardTest.A_Card_FacingUp_Once_Flipped_Is_Facing_Down
          -------------------------------------------------
          Executing Test : A_Card_FacingUp_Once_Flipped_Is_Facing_Down
            Success.
         Running Fixture Teardown Method : Destroy

         Done testing.
         Tests Found   : 1
         Tests Ignored : 0
         Tests Passed  : 1
         Tests Leaked  : 0
         Tests Failed  : 0
         Tests Errored : 0

Summary:
+-----------+-----------+-----------+
|   Lines   |  Covered  | Covered % |
+-----------+-----------+-----------+
|        15 |        11 |      73 % |
+-----------+-----------+-----------+
&lt;/pre&gt;
&lt;h2&gt;Continuous Integration&lt;/h2&gt;
With the code coverage batch file we are now able to run code coverage on any system, include on a continuous integration system. Our goal with the continuous integration is to have the unit tests built and run each time a set of code is checked into source control. This will allow us to then track if any unit tests fail, and changes in the code coverage.&amp;#160;&lt;br&gt;&lt;br&gt;
To achieve this I have create a&amp;#160;&lt;a&gt;&lt;/a&gt;&lt;br&gt;&lt;p&gt;The last option for the wizard allows for making all paths relative. This is exactly what we require to have our generated batch file run on any system, however at the time of writing it does not work correctly. This meant that I had to manually change all paths to a version that was relative to the folder in which DelphiCodeCoverage was located.Note: Line breaks are only included above for readability. There are none in the resulting batch files.Another alteration that I have made to the batch file is to include the "-ife" option. The option will include file extensions. This means that it will stop a unit like "Common.Encoding" being 'converted' to "Common". As in my project I have unit called "Core.Cards.pas" this option is required to have it included in generated code coverage report.Next the relative path change should be applied to the two generated list files &lt;a href="https://github.com/VSoftTechnologies/DelphiCodeCoverageExample/blob/master/CodeCoverage/dcov_paths.lst"&gt;dcov_paths.lst&lt;/a&gt; and &lt;a href="https://github.com/VSoftTechnologies/DelphiCodeCoverageExample/blob/master/CodeCoverage/dcov_units.lst"&gt;dcov_units.lst&lt;/a&gt; . The paths file should be the only one that has path in need of altering to be relative. Both however need to be checked to make sure they contain everything to be covered in the report. If there are source folders missing they need to be added to the dcov_paths.lst file. If there are unit names missing they need to be added to the dcov_units.lst file.Now that the batch file and list files have been corrected running the dcov_executable.bat should produce summary out similar to that below. Note that the unit test project needs to be compiled as DelphiCodeCoverage runs the unit test executable.With the code coverage batch file we are now able to run code coverage on any system, include on a continuous integration system. Our goal with the continuous integration is to have the unit tests built and run each time a set of code is checked into source control. This will allow us to then track if any unit tests fail, and changes in the code coverage.To achieve this I have create a &lt;a href="http://wiki.finalbuilder.com/display/continua/Configurations" target="_blank"&gt;Continua CI configuration&lt;/a&gt; that builds my unit test project, runs the unit tests under code coverage, and then import the unit test results into the build summary.&lt;/p&gt;&lt;p&gt;
&lt;br&gt;&lt;img alt="" src="https://www.finalbuilder.com/blogImages/jason/DelphiCodeCoverage/CodeCoverage_ContinuaActions.png"&gt;&lt;/p&gt;
The FinalBuilder action calls the FinalBuilder project responsible for compiling the DUnitX unit test project. It uses the CI configuration so that the unit tests executable will run to completion, and will produce an NUnit XML results file in the same directory as the executable. It is important to build the unit tests each time as the source code for our project would have changed each time we run the continuous integration. Note that you do not have to use FinalBuilder, you can also use MSBuild to build your DUnitX Project - see&amp;#160;&lt;a&gt;&lt;/a&gt;&lt;br&gt;&lt;br&gt;
The &lt;a&gt;&lt;/a&gt;&lt;br&gt;&lt;p&gt;The FinalBuilder action calls the FinalBuilder project responsible for compiling the DUnitX unit test project. It uses the CI configuration so that the unit tests executable will run to completion, and will produce an NUnit XML results file in the same directory as the executable. It is important to build the unit tests each time as the source code for our project would have changed each time we run the continuous integration. Note that you do not have to use FinalBuilder, you can also use MSBuild to build your DUnitX Project - see &lt;a href="https://www.finalbuilder.com/resources/blogs/postid/699/integrating-dunitx-unit-testing-with-continua-ci" target="_blank"&gt;Integrating DUnitX Unit Testing with Continua CI&lt;/a&gt; The &lt;a href="http://wiki.finalbuilder.com/display/continua/Execute+Program+Action" target="_blank"&gt;execute program action&lt;/a&gt; simply runs the code coverage batch file generated above. This batch file will run the unit test project we compiled and log code coverage information as it does. The result will be a summary written out to our build log while also html files written to the report folder we specified in the batch file. It is these html files which we will attach to the continuous build report a little later.&lt;/p&gt;&lt;p&gt;
&lt;br&gt;&lt;img alt="" src="https://www.finalbuilder.com/blogImages/jason/DelphiCodeCoverage/CodeCoverage_ContinuaExecuteProgram.png"&gt;&lt;/p&gt;
&lt;br&gt;
Lastly we want to import the actual unit test results. These are written out by DUnitX as a NUnit compatible XML file which we can import with the "Import NUnit Tests" action. The results from the XML file will be attached to the build report presented by Continua CI.&lt;br&gt;&lt;p&gt;Lastly we want to import the actual unit test results. These are written out by DUnitX as a NUnit compatible XML file which we can import with the "Import NUnit Tests" action. The results from the XML file will be attached to the build report presented by Continua CI.&lt;/p&gt;&lt;p&gt;
&lt;br&gt;&lt;img alt="" src="https://www.finalbuilder.com/blogImages/jason/DelphiCodeCoverage/CodeCoverage_ContinuaImportNUnit.png"&gt;&lt;/p&gt;
As all builds for Continua CI are run on agents, and all build reports come from the server, we need to transfer the code coverage report back to the server. This is done through &lt;a&gt;&lt;/a&gt;&lt;p&gt;\Output\CodeCoverage\" the report should appear in "Source\Output\CodeCoverage\Output" (Note that $Source.DelphiCodeCoverage.Path$ was mapped to the \Source\ folder on the agent). Workspace rules use the greater than symbol to signal the files should be copied from the server to the agent, and the less than symbol to copy from the agent to the server. This therefore leaves use the workspace rule of "&amp;#8220;/Output/CodeCoverage/ &amp;lt; \Source\CodeCoverage\Output\*.html" to get all code coverage report files back to the server.&amp;#160;&lt;/p&gt;&lt;br&gt;&lt;p&gt;As all builds for Continua CI are run on agents, and all build reports come from the server, we need to transfer the code coverage report back to the server. This is done through &lt;a href="http://wiki.finalbuilder.com/display/continua/Workspace+Rules" target="_blank"&gt;workspace rules&lt;/a&gt; on the build stage. In this example DelphiCodeCoverage writes out all html report files to a relative directory of ".\Output\". This means if we run the DelphiCodeCoverage batch file from "Source&lt;/p&gt;&lt;p&gt;
&lt;br&gt;&lt;img alt="" src="https://www.finalbuilder.com/blogImages/jason/DelphiCodeCoverage/CodeCoverage_ContinuaWorkspaceRules.png"&gt;&lt;/p&gt;
Now that the html reports are on the server, we need to show them against the Continua CI build. To achieve this we use the &lt;a&gt;&lt;/a&gt;&lt;br&gt;&lt;p&gt;Now that the html reports are on the server, we need to show them against the Continua CI build. To achieve this we use the &lt;a href="http://wiki.finalbuilder.com/display/continua/Reports" target="_blank"&gt;reports section&lt;/a&gt; of our Continua CI configuration. The reports section allows us to specify a file to attach to the build as a report to be displayed or offered as a download. In this case we want to display the report summary html file. All reports work from the server point of view, and each build has it own workspace on the server. To this end the report we want to be display would have been copied to "$Workspace$\Output\CodeCoverage\CodeCoverage_summary.html".&lt;/p&gt;&lt;p&gt;
&lt;br&gt;&lt;img alt="" src="https://www.finalbuilder.com/blogImages/jason/DelphiCodeCoverage/CodeCoverage_ContinuaCreateReport.png"&gt;&lt;/p&gt;
&lt;h2&gt;The Code Coverage Report&lt;/h2&gt;
The end report appearing in the report section of the Continua CI build summary.&amp;#160;&lt;br&gt;&lt;p&gt;The end report appearing in the report section of the Continua CI build summary.&lt;/p&gt;&lt;p&gt;
&lt;br&gt;&lt;img alt="" src="https://www.finalbuilder.com/blogImages/jason/DelphiCodeCoverage/CodeCoverage_ContinuaCoverageReport.png"&gt;&lt;/p&gt;
As shown in the report the example project has some code that is not covered during unit testing. This reduces the overall coverage to 73%. If I had more than one unit each would have their own code coverage summary. In addition I could click on each file and get a line by line report to see what section of the unit is not covered.&amp;#160;&lt;br&gt;&lt;p&gt;As shown in the report the example project has some code that is not covered during unit testing. This reduces the overall coverage to 73%. If I had more than one unit each would have their own code coverage summary. In addition I could click on each file and get a line by line report to see what section of the unit is not covered.&lt;/p&gt;&lt;p&gt;
&lt;br&gt;&lt;img alt="" src="https://www.finalbuilder.com/blogImages/jason/DelphiCodeCoverage/CodeCoverage_ContinuaCoverageMissing.png"&gt;&lt;/p&gt;
&lt;h2&gt;
Final Notes
&lt;/h2&gt;
It is worth mentioning that code coverage is only one arrow in a software testing quiver. In my example I purposely chose to include code that was not covered. This showed the power of code coverage in picking up where unit testing should potentially be directed to next. I also included code where the unit tests cover the code, however not fully. The code testing Core.Card.Flip only tests one path through the code, not all the possible paths. Currently the test sees if the code works when going from face up to face down, not from face down to face up. Although in this example it might be benign, it shows that other tools are needed to help cover this gap.&amp;#13;
                        &lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;p&gt;It is worth mentioning that code coverage is only one arrow in a software testing quiver. In my example I purposely chose to include code that was not covered. This showed the power of code coverage in picking up where unit testing should potentially be directed to next. I also included code where the unit tests cover the code, however not fully. The code testing Core.Card.Flip only tests one path through the code, not all the possible paths. Currently the test sees if the code works when going from face up to face down, not from face down to face up. Although in this example it might be benign, it shows that other tools are needed to help cover this gap.&lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Mon, 09 Nov 2015 05:35:12 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2015-11-09:delphi-code-coverage-with-continua-ci.html</guid><category>finalbuilder</category></item><item><title>Delphi-Mocks Parameter Matchers</title><link>http://ciandcd.github.io/delphi-mocks-parameter-matchers.html</link><description>From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/737/delphi-mocks-parameter-matchers"&gt;https://www.finalbuilder.com/resources/blogs/postid/737/delphi-mocks-parameter-matchers&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;
We recently updated Delphi Mocks to allow for better parameter matching on Expectations registered with the Mock. This allows the developer to place tighter controls on verifying that a mocked interface/object method is called.
Below is a simple example of when the parameter matchers can be used.
&lt;/p&gt;
&lt;pre class="brush:delphi; toolbar:true;  highlight:[14,15,16,17]"&gt;procedure TExample_InterfaceImplementTests.Implement_Multiple_Interfaces;
var
  sutProjectSaver : IProjectSaveCheck;
  mockProject : TMock&amp;lt;IProject&amp;gt;;
begin
  //Test that when we check and save a project, and its dirty, we save.
  //CREATE - The project saver under test.
  sutProjectSaver := TProjectSaveCheck.Create;
  //CREATE - Mock project to control our testing. 
  mockProject := TMock&amp;lt;IProject&amp;gt;.Create;
  //SETUP - Mock project will show as dirty and will expect to be saved.  
  mockProject.Setup.WillReturn(true).When.IsDirty;

  //NEW! - Add expectation that the save will be called as dirty is returning true. 
  //       As we don't care about the filename value passed to us we 
  //       allow any string to be passed to report this expectation as met. 
  mockProject.Setup.Expect.Once.When.Save(It(0).IsAny&amp;lt;string&amp;gt;());
    
  //TEST - Visit the mock element to see if our test works.
  sutProjectSaver.Execute(mockProject);
  //VERIFY - Make sure that save was indeed called.
  mockProject.VerifyAll;
end;
&lt;/pre&gt;
&lt;p&gt;
Previously the developer writing this test would have to provide the exact filename to be passed to the mocked Save method. As we don't know what the projects filename is going to be (in our example case), we would either have to;
1. Forgo doing this test.
2. Implement a project object to test with.
Both of these options are not ideal.
&lt;/p&gt;
&lt;p&gt;Parameter matchers resolve this situation. It is now simple to either restrict or broaden the parameters passed to mocked methods that will satisfy the expectation defined. To achieve this Delphi-Mocks offers eleven new functions; &lt;/p&gt;
&lt;pre class="brush:delphi; toolbar:true;"&gt;function It(const AParamIndx : Integer) : ItRec;
function It0 : ItRec;
function It1 : ItRec;
function It2 : ItRec;
function It3 : ItRec;
function It4 : ItRec;
function It5 : ItRec;
function It6 : ItRec;
function It7 : ItRec;
function It8 : ItRec;
function It9 : ItRec;
&lt;/pre&gt;
&lt;p&gt;The first "function It(const AParamIndx : Integer) : ItRec;" allows the developer to specify the index of the parameter they wish to set for the next expectation setup of a mock method. It(0) will refer to the first parameter, It(1) the second and so forth. Note that the reason for specifying the parameter index is that Delphi's parameter evaluation order is not defined, so we could not rely on the parameters being evaluated in order (which is what we did when we initially wrote this feature). Interestingly, with the 64 bit Delphi compiler, parameter evaluation does appear to happen in order, but we could not be certain this will always be the case.&amp;#160;&lt;/p&gt;
&lt;p&gt;The other ten functions It0 through to It9 are simply wrappers of the index call passing the index in their name. All these functions return an ItRec. The ItRec has the function structure;&lt;/p&gt;
&lt;pre class="brush:delphi; toolbar:true;"&gt;ItRec = record
  var
    ParamIndex : cardinal;
  constructor Create(const AParamIndex : Integer);
  function IsAny&amp;lt;T&amp;gt;() : T ;
  function Matches&amp;lt;T&amp;gt;(const predicate: TPredicate&amp;lt;T&amp;gt;) : T;
  function IsNotNil&amp;lt;T&amp;gt; : T;
  function IsEqualTo&amp;lt;T&amp;gt;(const value : T) : T;
  function IsInRange&amp;lt;T&amp;gt;(const fromValue : T; const toValue : T) : T;
  function IsIn&amp;lt;T&amp;gt;(const values : TArray&amp;lt;T&amp;gt;) : T; overload;
  function IsIn&amp;lt;T&amp;gt;(const values : IEnumerable&amp;lt;T&amp;gt;) : T; overload;
  function IsNotIn&amp;lt;T&amp;gt;(const values : TArray&amp;lt;T&amp;gt;) : T; overload;
  function IsNotIn&amp;lt;T&amp;gt;(const values : IEnumerable&amp;lt;T&amp;gt;) : T; overload;
  {$IFDEF SUPPORTS_REGEX} //XE2 or later
  function IsRegex(const regex : string; const options : TRegExOptions = []) : string;
  {$ENDIF}
end;
&lt;/pre&gt;
&lt;p&gt;Each of the functions creates a different matcher. For example the IsAny&amp;lt;T&amp;gt; will cause the expectation to be met when the parameter passed to the mock is of any value that has the type T. In the example above this type would be a string. You will also notice that each function returns the type T. This is so that each call can be placed within the mock methods call directly. Doing so helps with making sure parameter types match the testing value.&lt;/p&gt;
&lt;p&gt;IsEqualTo&amp;lt;T&amp;gt; requires that the parameter matches exactly to the value passed into the IsEqualTo&amp;lt;T&amp;gt;. This could be used to restrict the expectation to a tighter test of the functionality under test.&lt;/p&gt;
&lt;pre class="brush:delphi; toolbar:true;"&gt;//Match on the filename being "temp.txt" only.
mockProject.Setup.Expect.Once.When.Save(It(0).IsEqualTo&amp;lt;string&amp;gt;('temp.txt'));
//VERIFY - Make sure that save was indeed called.
mockProject.VerifyAll;
&lt;/pre&gt;
&lt;p&gt;In the future we are looking to provide &amp;#8220;And&amp;#8221;\&amp;#8221;Or&amp;#8221; operators. These operators might also live on the ItRec and allow combining with as many other matchers using the same type.&lt;/p&gt;
&lt;pre class="brush:delphi; toolbar:true;"&gt;//Match on the filename being "temp.txt" or "temp.doc" only.
mockProject.Setup.Expect.Once.When.Save(
       It(0).Or(It(0).IsEqualTo&amp;lt;string&amp;gt;('temp.txt'), 
                It(0).IsEqualTo&amp;lt;string&amp;gt;('temp.doc'));
//VERIFY - Make sure that save was indeed called.
mockProject.VerifyAll;
&lt;/pre&gt;
&lt;p&gt;There might be a better way to make the resulting code a bit cleaner. It would make the tests easier to read, instead of using regex which is also possible in this case. As a result we believe this would be a good edition to the library.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/VSoftTechnologies/Delphi-Mocks"&gt;Feel free to clone the repository from GitHub&lt;/a&gt;. If you have some time to spare submit a pull requests or two with your ideas/improvements. We believe this is a great little project worthy of some attention. Let us know what you think of the changes so far.&lt;/p&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Wed, 23 Sep 2015 01:15:11 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2015-09-23:delphi-mocks-parameter-matchers.html</guid><category>finalbuilder</category></item><item><title>VSO Task for Running FinalBuilder Project</title><link>http://ciandcd.github.io/vso-task-for-running-finalbuilder-project.html</link><description>From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/736/finalbuilder-vso-task"&gt;https://www.finalbuilder.com/resources/blogs/postid/736/finalbuilder-vso-task&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;a&gt;&lt;/a&gt;&lt;br&gt;&lt;br&gt;
Those who use TFS on-prem will be very familiar with our XAML build activity already. This activity took a great deal of confusion out of the XAML build process. Changing a build progress from a complex workflow into a simple to maintain FinalBuilder project. The time and effort saved is huge, especially considering the "default" XAML workflow looks like this:&lt;br&gt;&lt;br&gt;&lt;img alt="" src="https://www.finalbuilder.com/blogImages/jason/FinalBuilder-VSO/OldXAMLProcess.png"&gt;&lt;br&gt;&lt;br&gt;
Thankfully Microsoft have improved on their build system with the release of Team Foundation Build 2015. You can read more about this at &lt;a&gt;&lt;/a&gt;&lt;br&gt;&lt;br&gt;
The FinalBuilder task is our custom task for TFS Build 2015. It offers TFS script builders the ability to still have a simplified overview of their build process while still gaining the power of FinalBuilder and all its supported actions. With FinalBuilder TFS build script creators are able to perform a wide number of tasks that would otherwise require breaking out powershell and diving into the TFS agent environment variables.&amp;#160;&lt;br&gt;&lt;br&gt;
When installed, the FinalBuilder Task gives users the following UI. All of the properties present in the UI are easily accessible from within any FinalBuilder script run by the task. FinalBuilder also gives simple access to a list of files that triggered the build.&lt;br&gt;&lt;br&gt;&lt;img alt="" src="https://www.finalbuilder.com/blogImages/jason/FinalBuilder-VSO/FinalBuilderTaskOptionsAll.png"&gt;&lt;br&gt;&lt;h2&gt;Installation and Usage&lt;/h2&gt;
The steps to adding custom build activities to your TFS and VSO instances are quick and easy. We have created a&amp;#160;&lt;a&gt;&lt;/a&gt;&lt;h2&gt;Repository Clone&lt;/h2&gt;
To clone this repository use the following command line. You will require git to be installed and available on your path.&lt;br&gt;&lt;pre class="brush:shell; gutter:false; highlight:3"&gt;&amp;gt; mkdir VSoft
&amp;gt; cd VSoft
&amp;gt; git clone https://github.com/VSoftTechnologies/FinalBuilder-VSO.git
Cloning into 'FinalBuilder-VSO'...
remote: Counting objects: X, done.
remote: Compressing objects: 100% (X/X), done.
remote: Total X (delta 0), reused 0 (delta 0), pack-reused 0
Unpacking objects: 100% (X/X), done.
Checking connectivity... done.
&lt;/pre&gt;
With the repository cloned we require the TFS Extensions Command Line Utility (tfx-cli). It comes as a Node Package Manager (npm) package. Npm comes with both the node.js and io.js installer. Download the installer for your Windows platform and run it.&lt;br&gt;&lt;br&gt;
To check that NPM is working correctly you can use the npm version command&lt;br&gt;&lt;pre class="brush:shell; gutter:false; highlight:1"&gt;&amp;gt; npm -v
2.10.1
&lt;/pre&gt;
Now your able to install the tfx-cli package using npm. Install this globally so that its accessable on the command line. The command line for this is as follows;&lt;br&gt;&lt;pre class="brush:shell; gutter:false; highlight:1"&gt;&amp;gt; npm install -g tfx-cli
tfx-cli@0.1.11 C:\Users\&amp;lt;username&amp;gt;\AppData\Roaming\npm\node_modules\tfx-cli
&amp;#9500;&amp;#9472;&amp;#9472; os-homedir@1.0.1
&amp;#9500;&amp;#9472;&amp;#9472; async@1.4.2
&amp;#9500;&amp;#9472;&amp;#9472; colors@1.1.2
&amp;#9500;&amp;#9472;&amp;#9472; minimist@1.2.0
&amp;#9500;&amp;#9472;&amp;#9472; node-uuid@1.4.3
&amp;#9500;&amp;#9472;&amp;#9472; q@1.4.1
&amp;#9500;&amp;#9472;&amp;#9472; read@1.0.7 (mute-stream@0.0.5)
&amp;#9500;&amp;#9472;&amp;#9472; validator@3.43.0
&amp;#9500;&amp;#9472;&amp;#9472; shelljs@0.5.3
&amp;#9500;&amp;#9472;&amp;#9472; vso-node-api@0.3.4
&amp;#9492;&amp;#9472;&amp;#9472; archiver@0.14.4 (buffer-crc32@0.2.5, lazystream@0.1.0, async@0.9.2, readable-stream@1.0.33, tar-stream@1.1.5, glob@4.3.5, lodash@3.2.0, zip-stream@0.5.2)
&lt;/pre&gt;
To test that tfx-cli is working correctly and is on the path use the tfx command.&lt;br&gt;&lt;pre class="brush:shell; gutter:false; highlight:1"&gt;&amp;gt; tfx
Copyright Microsoft Corporation
tfx &amp;lt;command&amp;gt; [&amp;lt;subcommand(s)&amp;gt; ...] [&amp;lt;args&amp;gt;] [--version] [--help] [--json]
&amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; fTfs
&amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; fSSSSSSSs
&amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; fSSSSSSSSSS
&amp;#160; &amp;#160; &amp;#160;TSSf &amp;#160; &amp;#160; &amp;#160; &amp;#160; fSSSSSSSSSSSS
&amp;#160; &amp;#160; &amp;#160;SSSSSF &amp;#160; &amp;#160; fSSSSSSST SSSSS
&amp;#160; &amp;#160; &amp;#160;SSfSSSSSsfSSSSSSSt &amp;#160; SSSSS
&amp;#160; &amp;#160; &amp;#160;SS &amp;#160;tSSSSSSSSSs &amp;#160; &amp;#160; &amp;#160;SSSSS
&amp;#160; &amp;#160; &amp;#160;SS &amp;#160; fSSSSSSST &amp;#160; &amp;#160; &amp;#160; SSSSS
&amp;#160; &amp;#160; &amp;#160;SS fSSSSSFSSSSSSf &amp;#160; &amp;#160;SSSSS
&amp;#160; &amp;#160; &amp;#160;SSSSSST &amp;#160; &amp;#160;FSSSSSSFt SSSSS
&amp;#160; &amp;#160; &amp;#160;SSSSt &amp;#160; &amp;#160; &amp;#160; &amp;#160;FSSSSSSSSSSSS
&amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; FSSSSSSSSSS
&amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160;FSSSSSSs
&amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; &amp;#160; FSFs &amp;#160; &amp;#160;(TM)
commands:
&amp;#160; &amp;#160;build
&amp;#160; &amp;#160; &amp;#160; &amp;#160; manage task extensions and builds
&amp;#160; &amp;#160;help
&amp;#160; &amp;#160; &amp;#160; &amp;#160; command help
&amp;#160; &amp;#160;login
&amp;#160; &amp;#160; &amp;#160; &amp;#160; login and cache credentials. types: pat (default), basic
&amp;#160; &amp;#160; &amp;#160; &amp;#160; login &amp;lt;collection url&amp;gt; [--authtype &amp;lt;authtype&amp;gt;] [options]
&amp;#160; &amp;#160;parse
&amp;#160; &amp;#160; &amp;#160; &amp;#160; parse json by piping json result from another tfx command
&amp;#160; &amp;#160; &amp;#160; &amp;#160; parse &amp;lt;jsonfilter&amp;gt; [options]
&amp;#160; &amp;#160;version
&amp;#160; &amp;#160; &amp;#160; &amp;#160; output the version
&amp;#160; &amp;#160; &amp;#160; &amp;#160; version [options]
Options:
&amp;#160; &amp;#160;--help &amp;#160; &amp;#160;: get help on a command
&amp;#160; &amp;#160;--json &amp;#160; &amp;#160;: output in json format. &amp;#160;useful for scripting
&lt;/pre&gt;
For tfx-cli to upload a task to TFS it needs to be logged in. We can do this once so that all following commands will use the some credentials. The method used depends on whether your using VSO or an On Prem installation.&lt;br&gt;&lt;h2&gt;On Premises Login&lt;/h2&gt;
For on premises TFS basic authentication will need to be enabled. The tfx-cli project has a great guide on how to achieve this Using tfx against Team Foundation Server (TFS) 2015 using Basic Authentication.&lt;br&gt;&lt;br&gt;
Once TFS has been configured to use basic authentication use the tfx-cli login command to connect to TFS. You will be prompted for the TFS collection URL to connect to, and the username and password for accessing that collection.&lt;br&gt;&lt;pre class="brush:shell; gutter:false; highlight:1"&gt;&amp;gt; tfx login --authType basic
Copyright Microsoft Corporation
Enter collection url &amp;gt; http://&amp;lt;server&amp;gt;:&amp;lt;port&amp;gt;/tfs/&amp;lt;collection&amp;gt;
Enter username &amp;gt; &amp;lt;user&amp;gt;@&amp;lt;domain&amp;gt;
Enter password &amp;gt; &amp;lt;password&amp;gt;
logged in successfully
&lt;/pre&gt;
With a successful login subsequent commands will not require us to provide the credentials again.&lt;br&gt;&lt;h2&gt;Visual Studio Online (VSO) Login&lt;/h2&gt;
For VSO login you need a personal access token setup under your account. There is a great article to configure an access token located at Using Personal Access Tokens to access Visual Studio Online.&lt;br&gt;&lt;br&gt;
With the personal access token configured use the tfx-cli login command to connect to VSO. You will be prompted for the TFS collection URL to connect to, and access token for accessing that collection.&lt;br&gt;&lt;pre class="brush:shell; gutter:false; highlight:1"&gt;&amp;gt; tfx login
Copyright Microsoft Corporation
Enter collection url &amp;gt; https://&amp;lt;vsoname&amp;gt;.visualstudio.com/&amp;lt;collection&amp;gt;
Enter personal access token &amp;gt; &amp;lt;access token&amp;gt;
logged in successfully
&lt;/pre&gt;
With a successful login subsequent commands will not require us to provide the credentials again.&lt;br&gt;&lt;h2&gt;Uploading Task&lt;/h2&gt;
Once logged into TFS we are able to upload the FinalBuilder task to the server. Tasks are uploaded to the server, the server will then pass them onto agents requried to run those tasks.&lt;br&gt;&lt;br&gt;
To upload the task use the tfx-cli tasks upload command. Each command shown below is a sub-command of the previous, so order does matter here. The overwrite option is included so that any previously installed version is overwritten. Note however the highest version number of the task will win when running builds.&lt;br&gt;&lt;br&gt;
Note: This command is run under the directory in which this repositry was cloned to (i.e. FinalBuilderTFS).&lt;br&gt;&lt;pre class="brush:shell; gutter:false; highlight:1"&gt;&amp;gt; tfx build tasks upload ./FinalBuilder --overwrite
Copyright Microsoft Corporation&lt;br&gt;

task at: ./FinalBuilder uploaded successfully!
&lt;/pre&gt;
To test that the FinalBuilder task is now installed on the builds page for teh collection the task was uploaded to. Create a new empty Team Foundation Build definition. After clicking "Add build step" a FinalBuilder task should appear in the "Build" category.&lt;br&gt;&lt;h2&gt;Further Steps&lt;/h2&gt;
For more information on the following subjects please follow the links;&lt;br&gt;&lt;br&gt;
How to configure the build task refer to &lt;a&gt;&lt;/a&gt;&lt;br&gt;
How to install FinalBuilder on an agent refer to &lt;a&gt;&lt;/a&gt;&lt;br&gt;
How to create a FinalBuilder VSO agent refer to Creating a &lt;a&gt;&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;p&gt;Today we are announcing the new build step for Team Foundation Build 2015. This task will allow users of TFS on-prem and VSO to run FinalBuilder projects on Team Foundation Build agents. The task itself is open source and can be found on &lt;a href="https://github.com/VSoftTechnologies/FinalBuilder-VSO"&gt;GitHub&lt;/a&gt; Those who use TFS on-prem will be very familiar with our XAML build activity already. This activity took a great deal of confusion out of the XAML build process. Changing a build progress from a complex workflow into a simple to maintain FinalBuilder project. The time and effort saved is huge, especially considering the "default" XAML workflow looks like this:Thankfully Microsoft have improved on their build system with the release of Team Foundation Build 2015. You can read more about this at &lt;a href="https://msdn.microsoft.com/Library/vs/alm/Build/feature-overview"&gt;Team Foundation Build 2015&lt;/a&gt; . In summary, the new build system greatly simplifies the build process into a list of tasks to perform.The FinalBuilder task is our custom task for TFS Build 2015. It offers TFS script builders the ability to still have a simplified overview of their build process while still gaining the power of FinalBuilder and all its supported actions. With FinalBuilder TFS build script creators are able to perform a wide number of tasks that would otherwise require breaking out powershell and diving into the TFS agent environment variables.When installed, the FinalBuilder Task gives users the following UI. All of the properties present in the UI are easily accessible from within any FinalBuilder script run by the task. FinalBuilder also gives simple access to a list of files that triggered the build.The steps to adding custom build activities to your TFS and VSO instances are quick and easy. We have created a &lt;a href="https://github.com/VSoftTechnologies/FinalBuilder-VSO"&gt;GitHub Repository&lt;/a&gt; for explaining how to install, and use our FinalBuilder VSO task.To clone this repository use the following command line. You will require git to be installed and available on your path.With the repository cloned we require the TFS Extensions Command Line Utility (tfx-cli). It comes as a Node Package Manager (npm) package. Npm comes with both the node.js and io.js installer. Download the installer for your Windows platform and run it.To check that NPM is working correctly you can use the npm version commandNow your able to install the tfx-cli package using npm. Install this globally so that its accessable on the command line. The command line for this is as follows;To test that tfx-cli is working correctly and is on the path use the tfx command.For tfx-cli to upload a task to TFS it needs to be logged in. We can do this once so that all following commands will use the some credentials. The method used depends on whether your using VSO or an On Prem installation.For on premises TFS basic authentication will need to be enabled. The tfx-cli project has a great guide on how to achieve this Using tfx against Team Foundation Server (TFS) 2015 using Basic Authentication.Once TFS has been configured to use basic authentication use the tfx-cli login command to connect to TFS. You will be prompted for the TFS collection URL to connect to, and the username and password for accessing that collection.With a successful login subsequent commands will not require us to provide the credentials again.For VSO login you need a personal access token setup under your account. There is a great article to configure an access token located at Using Personal Access Tokens to access Visual Studio Online.With the personal access token configured use the tfx-cli login command to connect to VSO. You will be prompted for the TFS collection URL to connect to, and access token for accessing that collection.With a successful login subsequent commands will not require us to provide the credentials again.Once logged into TFS we are able to upload the FinalBuilder task to the server. Tasks are uploaded to the server, the server will then pass them onto agents requried to run those tasks.To upload the task use the tfx-cli tasks upload command. Each command shown below is a sub-command of the previous, so order does matter here. The overwrite option is included so that any previously installed version is overwritten. Note however the highest version number of the task will win when running builds.Note: This command is run under the directory in which this repositry was cloned to (i.e. FinalBuilderTFS).To test that the FinalBuilder task is now installed on the builds page for teh collection the task was uploaded to. Create a new empty Team Foundation Build definition. After clicking "Add build step" a FinalBuilder task should appear in the "Build" category.For more information on the following subjects please follow the links;How to configure the build task refer to &lt;a href="https://github.com/VSoftTechnologies/FinalBuilder-VSO/blob/master/docs/TaskUI.md"&gt;Task UI&lt;/a&gt; How to install FinalBuilder on an agent refer to &lt;a href="https://github.com/VSoftTechnologies/FinalBuilder-VSO/blob/master/docs/InstallingFinalBuilder.md"&gt;Installing FinalBuilder&lt;/a&gt; How to create a FinalBuilder VSO agent refer to Creating a &lt;a href="https://github.com/VSoftTechnologies/FinalBuilder-VSO/blob/master/docs/FinalBuilderVSOAgent.md"&gt;VSO FinalBuilder Agent&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Thu, 17 Sep 2015 07:33:07 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2015-09-17:vso-task-for-running-finalbuilder-project.html</guid><category>finalbuilder</category></item><item><title>Team Foundation Server XAML Builds</title><link>http://ciandcd.github.io/team-foundation-server-xaml-builds.html</link><description>From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/735/team-foundation-server-xaml-builds"&gt;https://www.finalbuilder.com/resources/blogs/postid/735/team-foundation-server-xaml-builds&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;h2&gt;Team Foundation Server XAML Builds&lt;/h2&gt;
&lt;p&gt;Today we have released an update for Team Foundation Server XAML activities for FinalBuilder 7 and 8. These updates are to deal with conflicts caused by GAC installing these activities. &lt;/p&gt;
&lt;p&gt;Since 2010 Team Foundation Server has allowed custom activities to allow provide extra functionality in XAML build workflows. For those that have not had the (dis)pleasure, XAML workflows can be difficult to work with. To alleviate this pain point we implemented XAML build templates and custom activities to allow people to run any FinalBuilder script within the build workflow without the need to edit XAMAL. Customers we have talked to say this simplifies their TFS XAML build workflows a great deal. &lt;/p&gt;
&lt;p&gt;In previous releases, FinalBuilder&amp;#8217;s installer automatically installed the TFS XAML activity into the GAC. The version of the activity installed was based on the TFS Agent detected on the machine in question. Installing into the GAC was done to simplify the process. This way the developer would simply use the activities in their build workflow and it would be picked up through the GAC. &lt;/p&gt;
&lt;p&gt;With the introduction of the new TFS build in TFS 2015 and TFS-Git in TFS 2013 this is no longer advisable. In the case of TFS-Git Workflows, assembly conflicts can cause assembly load issues. &amp;#160;If the activity requires a different assembly version to those already loaded by the TFS agent, you would see assembly load errors with lib2gitsharp. With TFS 2013 having five updates this is increasingly possible . &lt;/p&gt;
&lt;p&gt;The way to avoid any assembly loading issue for custom activities is to use &amp;#8220;version control paths for custom XAML activities&amp;#8221;. To be clear, we have left the GAC installation option in both FinalBuilder 7 and 8. We however do recommend switching to using custom XAML activity paths, especially if you&amp;#8217;re using TFS-Git. &lt;/p&gt;
&lt;p&gt;To this end, the FinalBuilder installers now give the option as to whether to install the XAML build activities into the GAC or not. Only FinalBuilder 7 will automatically install TFS activities into the GAC for TFS 2012 and earlier agents, with FinalBuilder 8 you much chose whether to GAC install the assemblies.&lt;/p&gt;
&lt;p&gt;Note that if activities were previously installed in the GAC restarting the TFS Build Controller is required. This refreshes the build controller and releases any assemblies that it may have previously loaded.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://www.finalbuilder.com/blogImages/jason/TeamFoundationServerXAMLBuilds/FinalBuilder-XAML-Setup.png"&gt;&lt;/p&gt;
&lt;h2&gt;Creating a build definition&lt;/h2&gt;
&lt;p&gt;The creation of the build definition is exactly the same as before. If you&amp;#8217;re interested in how to setup a build definition from scratch using the FinalBuilder XAML templates please review the &amp;#8220;&lt;a https: www.finalbuilder.com resources blogs postid 705 finalbuilder-and-team-foundation-server-2013&gt;FinalBuilder and Team Foundation Server&lt;/a&gt;&amp;#8221; article. &lt;/p&gt;
&lt;h2&gt;Custom XAML activities&lt;/h2&gt;
&lt;p&gt;Version control paths for custom XAML activities is a feature in TFS XAML build controllers. This feature allows the build controller to source all assemblies required for an activity from a known location. If a required assembly is missing from this location the standard .Net assembly lookup methodology is used. &lt;/p&gt;
&lt;p&gt;Using version control paths for custom XAML activities requires the activity assemblies to be added to a repository on the TFS system. This repository can be shared with other code, or can be a repository just for the assemblies. As the custom folder does not change based on the build being performed, we suggest a separate TFS repository for the custom activities. The repository can also be either a TFS or Git-TFS repository. Both will work the same. &lt;/p&gt;
&lt;p&gt;To add the custom activity assemblies to a repository connect to the repository through team explorer in visual studio. &lt;/p&gt;
&lt;p&gt;In the source control view create a new folder that will hold the custom activity assemblies.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://www.finalbuilder.com/blogImages/jason/TeamFoundationServerXAMLBuilds/CustomActivitiesInRepo.png"&gt;&lt;/p&gt;
&lt;p&gt;In the GAC sub-folder in your FinalBuilder installation (typically &amp;#8220;%ProgramFiles(x86)%\FinalBuilder 8\GAC\&amp;#8221;) there are folders for each version of TFS custom activities are provided for. From the folder relating the TFS version copy all assemblies contained within into the newly created repository folder. &lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://www.finalbuilder.com/blogImages/jason/TeamFoundationServerXAMLBuilds/FinalBuilderGACFolder.png"&gt;&lt;/p&gt;
&lt;p&gt;From the source control explorer add these files to source control.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://www.finalbuilder.com/blogImages/jason/TeamFoundationServerXAMLBuilds/CustomActivitiesFolderWithAssemblies.png"&gt;&lt;/p&gt;
&lt;h2&gt;Updating the XAML Build Controller&lt;/h2&gt;
&lt;p&gt;Next the build controller needs to be configured use the repository location. In the builds tab of team explorer click on the &amp;#8220;Actions&amp;#8221; link. A drop down will appear with the option to &amp;#8220;Manage Build Controllers&amp;#8230;&amp;#8221;. Click the &amp;#8220;Manage Build Controllers&amp;#8230;&amp;#8221; menu item.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://www.finalbuilder.com/blogImages/jason/TeamFoundationServerXAMLBuilds/ManageBuildControllers.png"&gt;&lt;/p&gt;
&lt;p&gt;From the build controllers window that opens select the build controller responsible for the FinalBuilder builds. If there is more than one controller simply follow these steps for each controller. Next click the &amp;#8220;Properties&amp;#8221; button.&lt;/p&gt;
&lt;p&gt;This will present the build properties dialogue in which the &amp;#8220;Version control path to custom assemblies&amp;#8221; can be set. Select the folder that was created in the repository that is responsible for the custom activity assemblies. Now confirm this change by clicking OK on the build controller properties dialogue. &lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://www.finalbuilder.com/blogImages/jason/TeamFoundationServerXAMLBuilds/VersionControlPathSet.png"&gt;&lt;/p&gt;
&lt;p&gt;This has now setup the build controller to source custom assemblies from the configured repository folder. The most recent checked in assemblies will always be sourced. Therefore keeping this repository folder in sync with the custom activities used in build workflows is very important. &lt;/p&gt;
&lt;p&gt;Once the custom path is set the build controller can run builds using the custom activities. To test simply queue a build using the FinalBuilder custom activities.&amp;#160;&lt;/p&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Wed, 16 Sep 2015 07:16:45 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2015-09-16:team-foundation-server-xaml-builds.html</guid><category>finalbuilder</category></item><item><title>Continua CI Version 1.7 released</title><link>http://ciandcd.github.io/continua-ci-version-17-released.html</link><description>From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/734/continua-ci-version-17-released"&gt;https://www.finalbuilder.com/resources/blogs/postid/734/continua-ci-version-17-released&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;Version 1.7 of Continua is now released. A big thank you to all those who downloaded the beta and especially those of you who reported issues and bugs.&lt;/p&gt;
&lt;p&gt; This version  introduces several new features, many of which have been requested by users over the past few months. These features are built upon the various improvements and bug fixes applied in revisions to version 1.6.
Please don&amp;#8217;t dismay if your requested feature is not included yet, it is still high on our to-do list. Indeed we have several other features specced out, and some partially developed in the background.&lt;/p&gt;
&lt;h2&gt;Version 1.7 Features&lt;/h2&gt;
&lt;h3&gt;New Builds View dashboard&lt;/h3&gt;
&lt;p&gt;This view is useful for project administrators and shows a list of active builds across all viewable configurations. This includes running builds, queued builds and builds awaiting promotion.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="/blogimages/daves/v1.7beta/buildsview.png"&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3&gt;New panel of indicators&lt;/h3&gt;
&lt;p&gt;Some important numbers including the total count of queued and running builds, as well as available agents and concurrent build licenses.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="/blogimages/daves/v1.7beta/indicators.png"&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3&gt;New Repositories tab&lt;/h3&gt;
&lt;p&gt; This is accessed via the Configurations view and shows status of each repository. We've also included &amp;#8220;Check &amp;#160;Now&amp;#8221; buttons for immediately polling each repository. You can also initiate repository checking from all existing repository pages&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="/blogimages/daves/v1.7beta/repoview.png"&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3&gt;Project-wide and configuration versioning options.&lt;/h3&gt;
&lt;p&gt;We've added some new options in the details section of the project and configuration wizards&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Project-wide versioning: &lt;/strong&gt;The build version number can now be incremented across many configurations within a project.&lt;br&gt;&lt;br&gt;&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;Build number re-use: &lt;/strong&gt;A new &lt;p&gt;option at the&amp;#160;&lt;/p&gt;project or configuration level to decrement the version counter when a build is discarded while initialising. e.g. due to configuration conditions. Please note that the build number will be decremented only if no other build has started in the mean time and is using a later build number. &amp;#160;&lt;br&gt;&lt;br&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;
&lt;img alt="" src="/blogimages/daves/v1.7beta/projectwidesettings.png"&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3&gt;Improvements to Build Completed triggers.&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Variable expressions: &lt;/strong&gt;You can now use expressions when defining variables allowing you to pass information from triggering to triggered build.&lt;br&gt;&lt;br&gt;&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;New conditions tab:&lt;/strong&gt; This allows you to use expressions to control whether a build is triggered&lt;br&gt;&lt;br&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;
&lt;img alt="" src="/blogimages/daves/v1.7beta/buildcompletedconditions.png"&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3&gt;Improvements to Repository triggers.&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Trigger on specific file change types: &lt;/strong&gt;Triggers can now be set to start only when the changeset contains certain types of file changes e.g. additions, modifications and deletions.&lt;br&gt;&lt;br&gt;&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;Trigger file pattern: &lt;/strong&gt;You can now specify a file pattern for repository triggers to restrict triggering only to changesets containing matching files.&lt;br&gt;&lt;br&gt;&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;Trigger comment pattern:&amp;#160;&lt;/strong&gt;You can also limit triggering to changesets with specific text in the comment.&lt;br&gt;&lt;br&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;
&lt;img alt="" src="/blogimages/daves/v1.7beta/repotriggeroptions.png"&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3&gt;Other build features&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;New &lt;strong&gt;force repository check&lt;/strong&gt; option in queue build dialog allowing control over whether to recheck repository when building. There is also a default setting for each configuration&lt;br&gt;&lt;br&gt;&lt;/li&gt;
    &lt;li&gt;Improvements to &lt;strong&gt;Stop Build buttons on dashboard view&lt;/strong&gt;&amp;#160;to ensure that the build stopped is always the latest build at the time when the button was clicked. Stop build dialogs also now display the build number of the build being stopped.&lt;/li&gt;
&lt;/ul&gt;&lt;br&gt;&lt;h3&gt;Actions and event handlers&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;New &lt;strong&gt;node.js actions
    &lt;/strong&gt;
    &lt;ul&gt;&lt;li&gt;Package management with Npm and Bower&lt;/li&gt;
        &lt;li&gt;Grunt and Gulp build runners&lt;/li&gt;
        &lt;li&gt;Unit testing with Mocha&lt;br&gt;&lt;br&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/li&gt;
    &lt;li&gt;New build event handler for posting &lt;strong&gt;status updates to a Stash server&lt;/strong&gt;&lt;br&gt;&lt;br&gt;&lt;/li&gt;
    &lt;li&gt;Log Entry action now allows you to &lt;strong&gt;add the message as a build comment&lt;/strong&gt;. This can be useful for showing additional build details on the build view page.&lt;br&gt;&lt;br&gt;&lt;/li&gt;
    &lt;li&gt;New &lt;strong&gt;comments field &lt;/strong&gt;on all actions &amp;#8211; displayed as a tooltip in Stages editor.&lt;br&gt;&lt;br&gt;&lt;/li&gt;
    &lt;li&gt;New ContinuaCI.* &lt;strong&gt;system environment variables&lt;/strong&gt; are now available to all executable actions.&lt;br&gt;&lt;br&gt;ContinuaCI.AgentProperty.*&lt;br&gt;
                ContinuaCI.Variable.*&lt;br&gt;
                ContinuaCI.Project.Name&lt;br&gt;
                ContinuaCI.Configuration.Name&lt;br&gt;
                ContinuaCI.Build.Id&lt;br&gt;
                ContinuaCI.Build.BuildNumber&lt;br&gt;
                ContinuaCI.Build.ChangesetCount&lt;br&gt;
                ContinuaCI.Build.ChangesetRevisions&lt;br&gt;
                ContinuaCI.Build.ChangesetTagNames &lt;br&gt;
                ContinuaCI.Build.ChangesetUserNames &lt;br&gt;
                ContinuaCI.Build.Elapsed &lt;br&gt;
                ContinuaCI.Build.HasNewChanges&lt;br&gt;
                ContinuaCI.Build.IsFeatureBranchBuild&lt;br&gt;
                
                ContinuaCI.Build.IssueCount&lt;br&gt;
                ContinuaCI.Build.LatestChangeset.Created&lt;br&gt;
                ContinuaCI.Build.LatestChangeset.IssueCount&lt;br&gt;
                ContinuaCI.Build.LatestChangeset.RepositoryName&lt;br&gt;
                ContinuaCI.Build.LatestChangeset.Revision&lt;br&gt;
                ContinuaCI.Build.LatestChangeset.TagCount&lt;br&gt;
                ContinuaCI.Build.LatestChangeset.UserName&lt;br&gt;
                ContinuaCI.Build.Started&lt;br&gt;
                ContinuaCI.Build.StartedBy&lt;br&gt;
                ContinuaCI.Build.TimeOnQueue&lt;br&gt;
                ContinuaCI.Build.UsesDefaultBranch&lt;br&gt;
                ContinuaCI.Build.Version&lt;br&gt;
            &lt;br&gt;&lt;br&gt;&lt;/li&gt;
    &lt;li&gt;Execute Program, DOS Command and PowerShell actions now include an option to generate a &lt;strong&gt;context XML file&lt;/strong&gt;. This file contains details of the build including repositories, changesets and files for you to parse with your own script or program.&lt;/li&gt;
&lt;/ul&gt;&lt;br&gt;&lt;br&gt;&lt;h3&gt;Git repositories&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Case-only renames&lt;/strong&gt; are now recorded in the repository cache.&lt;br&gt;&lt;br&gt;&lt;/li&gt;
    &lt;li&gt;New option to list &lt;strong&gt;author instead of committer&lt;/strong&gt; as changeset username&lt;/li&gt;
&lt;/ul&gt;&lt;br&gt;&lt;br&gt;&lt;h5&gt;&lt;strong&gt;Version 1.7 is ready for you to &lt;a href="https://www.finalbuilder.com/downloads/continuaci"&gt;download&lt;/a&gt; and install. All feedback is welcome!&lt;/strong&gt;&lt;/h5&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Mon, 24 Aug 2015 07:20:37 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2015-08-24:continua-ci-version-17-released.html</guid><category>finalbuilder</category></item><item><title>FinalBuilder 8 Released!</title><link>http://ciandcd.github.io/finalbuilder-8-released.html</link><description>From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/733/finalbuilder-8-released"&gt;https://www.finalbuilder.com/resources/blogs/postid/733/finalbuilder-8-released&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;It's very nearly 5 years since FinalBuilder 7 was released. Since it's release we have shipped &lt;a href="https://www.finalbuilder.com/downloads/finalBuilder/finalbuilder-7-version-history"&gt;many official updates&lt;/a&gt;, nearly every update including new features or improvements. This program of continuous improvement has worked well, with customers not having to wait for major new versions to arrive to get support for new versions of Visual Studio or Delphi etc, but it has limited our ability to make major changes. So it's time for a new major version of FinalBuilder.&lt;/p&gt;
&lt;h2&gt;What's new in FinalBuilder 8&lt;/h2&gt;
&lt;h3&gt;IDE Themes&lt;/h3&gt;
&lt;p&gt;The IDE has two new themes, Dark and Light (yes, imaginatively named!). The IDE defaults to Dark on first run, however you can change the theme in the options quite easily.&lt;/p&gt;

            &lt;img alt="IDE Light theme" height="276" width="400" src="/blogImages/vincent/fb8-beta/fb8-ide-light-small.png"&gt;
            
            &lt;img alt="IDE Light theme" height="276" width="400" src="/blogImages/vincent/fb8-beta/fb8-ide-dark-small.png"&gt;
        &lt;p&gt;&amp;#160;&lt;/p&gt;
&lt;h3&gt;Debugger&lt;/h3&gt;
&lt;p&gt;
One of the most asked for features now available in FinalBuilder 8, &lt;strong&gt;stepping into included projects&lt;/strong&gt;. In FinalBuilder 7 and earlier, you could only step over included projects, and wait for them to return. In FinalBuilder 8, you can step into the included project, if it is not already opened the IDE will open the project and switch to it automatically. To make this possible, there are now "Step Into" and "Step Over" functions. The Step into/over now also applies to targets (see below).&lt;br&gt;&lt;br&gt;
Debugger breakpoints now have conditions :
&lt;/p&gt;
&lt;p&gt;
&lt;img alt="IDE Light theme" height="276" width="400" src="/blogImages/vincent/fb8-beta/fb8-breakpoint-props.png"&gt;&lt;/p&gt;
&lt;h3&gt;Actionlists renamed to Targets&lt;/h3&gt;
&lt;p&gt;ActionLists have been renamed to Targets. Targets can now also define dependencies, so you can for example define Clean, Build, Test, and have Test depend on Build. If you execute the Test target, and Build has not already been executed, it will be executed first before Test. Targets can be specified on the command line.&lt;/p&gt;
&lt;p&gt;&lt;img alt="IDE Light theme" height="276" width="400" src="/blogImages/vincent/fb8-beta/fb8-target-depend.png"&gt;&lt;/p&gt;
&lt;br&gt;&lt;p&gt;In FinalBuilder 7 and earlier, projects had a Main and an OnFailure (global error handler) actionlist. In FinalBuilder 8, projects just have a Default Target. Older projects will be imported such that the Main and OnFailure Targets are called from the Default Target inside a try/catch block.&lt;/p&gt;
&lt;h3&gt;Run Target Action&lt;/h3&gt;
&lt;p&gt;You can now return values from Targets (ie out parameters) .&lt;/p&gt;
&lt;p&gt;&lt;img alt="IDE Light theme" height="276" width="400" src="/blogImages/vincent/fb8-beta/fb8-target-outparams.png"&gt;&lt;/p&gt;
&lt;h3&gt;New Help System&lt;/h3&gt;
&lt;p&gt;The help has moved online in the form of a wiki. This enables us to do inline help updates without needing to ship new builds. The new help is still being worked on, lots of screenshots are missing etc..&amp;#160;&lt;/p&gt;
&lt;h2&gt;Non Visible Changes&lt;/h2&gt;
&lt;h3&gt;Stepping Engine&lt;/h3&gt;
&lt;p&gt;The stepping engine was rewritten to enable stepping into included projects, and to enable target dependencies. This, work, together with the new variables architecture is where the bulk of effort/time was spent in the FinalBuilder 8 development cycle.&lt;/p&gt;
&lt;h3&gt;Variables Architecture&lt;/h3&gt;
&lt;p&gt;The variables architecture and the expression evaluator were rewritten to resolve several corner case issues that we were not able to resolve in FinalBuilder 7. The expression evaulator has a new parser that will allow us to more easily extend the syntax in the future. The User variable namespace was removed, it caused too many problems with projects not running under other users, not running on the build server etc. Use Project variables instead. &lt;/p&gt;
&lt;h3&gt;Core Messaging&lt;/h3&gt;
&lt;p&gt;Changes to the messaging has allowed us to improve the performance of the stepping engine and logging, with much less thread switching. This also improved the IDE performance.&lt;/p&gt;
&lt;h3&gt;CLR Hosting&lt;/h3&gt;
&lt;p&gt;The minimum CLR version is now .NET 4.0 (ie FinalBuilder requires .net 4.0 to be installed). FinalBuilder 8 also requires Powershell 3.0 or later.&lt;/p&gt;
&lt;h3&gt;Code Changes&lt;/h3&gt;
&lt;p&gt;In addition to the architectural changes, we also spent a lot of time refactoring the code, running static analysis tools over the source, looking for memory leaks, potential bugs etc. One of the results of this is reduced memory usage during a build compared to FB7. The FB8 IDE does use slightly more memory than the FB7 IDE at startup (mostly due to the heavy use of delphi generics), however the runtime memory usage is much lower.A large &amp;#160;part of the refactoring involved unit testing (we created a new&amp;#160;&lt;a href="https://github.com/VSoftTechnologies/DUnitX" target="_blank"&gt;unit test framework&lt;/a&gt; to suite our needs!) and creating a suite of integration tests.&amp;#160;&lt;/p&gt;
&lt;h3&gt;FBCmd&lt;/h3&gt;
&lt;p&gt;
The command line parameters have changed to be more consistent and easier to specify. You can also specify one or more targets to execute (when not specified, the default target is executed).
&lt;/p&gt;
&lt;h3&gt;New Project File Formats&lt;/h3&gt;
&lt;p&gt;FinalBuilder has used an xml file format since version 1, however a common complaint over the years, has been that it is difficult to diff file versions. FinalBuilder 8 has tackled this in two ways.&lt;/p&gt;
&lt;p&gt;A new DSL style project file format (.fbp8) is now the default format, it is very easy to diff.&lt;/p&gt;
&lt;pre class="brush:delphi; toolbar:true;"&gt;project
begin
    projectid = {04710B72-066E-46E7-84C7-C04A0D8BFE18}
    target
    begin
        name = Default
        targetid = {E6DE94D6-5484-45E9-965A-DB69885AA5E2}
        rootaction
        begin
            action.group
            begin
                id = {D860420B-DE46-4806-959F-8A92A0C86429}
            end
        end
    end
end
&lt;/pre&gt;
&lt;p&gt;A new xml format (.fbx8), much less verbose than the old format. &lt;/p&gt;
&lt;pre class="brush:xml; toolbar:true;"&gt;&amp;lt;?xml version="1.0" encoding="UTF-8"?&amp;gt;
&amp;lt;finalbuilder&amp;gt;
    &amp;lt;project&amp;gt;
        &amp;lt;projectid&amp;gt;{6A717C24-D00F-4983-9FD0-148B2C609634}&amp;lt;/projectid&amp;gt;
        &amp;lt;target&amp;gt;
            &amp;lt;name&amp;gt;Default&amp;lt;/name&amp;gt;
            &amp;lt;targetid&amp;gt;{E6DE94D6-5484-45E9-965A-DB69885AA5E2}&amp;lt;/targetid&amp;gt;
            &amp;lt;rootaction&amp;gt;
                &amp;lt;action.group&amp;gt;
                    &amp;lt;id&amp;gt;{D860420B-DE46-4806-959F-8A92A0C86429}&amp;lt;/id&amp;gt;
                &amp;lt;/action.group&amp;gt;
            &amp;lt;/rootaction&amp;gt;
        &amp;lt;/target&amp;gt;
    &amp;lt;/project&amp;gt;
&amp;lt;/finalbuilder&amp;gt;
&lt;/pre&gt;
&lt;p&gt;Compressed project files (.fbz8) use the dsl format internally (compressed projects are just a zip file with a project.fbp8 inside it).&lt;/p&gt;
&lt;p&gt;The default project file encoding is now UTF-8, which is more version control friendly (some version control systems treat utf-16 as binaries).&lt;/p&gt;
&lt;h3&gt;New Actions&lt;/h3&gt;
&lt;p&gt;FinalBuilder 8 includes new actions for Chocolatey, Bower, NPM,  Gulp, Grunt, Rake, Fake, Mocha, along with Redgate SQL Compare and SQL Data Compare actions.&lt;/p&gt;
&lt;p&gt;TFS 2015 XAML builds are also supported, a VSO task will be available soon (will be published on github).&lt;/p&gt;
&lt;h3&gt;License Key installation&lt;/h3&gt;
&lt;p&gt;
We implemented a new more reliable trial mechanism for FinalBuilder 8, and made it simpler to install license keys. You can log into your account on our website directly
in the FinalBuilder IDE and download &amp;amp; install license keys
&lt;/p&gt;
&lt;p&gt;The trial mechanism also uses license keys, which is more reliable than the mechansim used in earlier versions. &lt;/p&gt;
&lt;h3&gt;Where's my license key?&lt;/h3&gt;
&lt;p&gt;
If you had an active Software Assurance Subscription for FinalBuilder 7 as of 20th August 2015, FinalBuilder 8 license keys were generated and added to your account today. You should have received an email notification.
&lt;/p&gt;
&lt;h3&gt;How do I purchase an upgrade?&lt;/h3&gt;
&lt;p&gt;If you had a subscription for FinalBuilder 7, and it expired, you can upgrade by &lt;a https: www.finalbuilder.com store section customers?page="subscriptions"&gt;Renewing your subscription&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;If you have a license for FinalBuilder 6 or earlier, you can &lt;a https: www.finalbuilder.com store section customers?page="upgrades"&gt;Purchase an upgrade here.&lt;/a&gt; &lt;/p&gt;
&lt;h3&gt;Can I safely install FinalBuilder 8 on a machine with FinalBuilder x?&lt;/h3&gt;
&lt;p&gt;Yes. FinalBuilder 8 installs into a separate folder (as did all older versions of FinalBuilder).&lt;/p&gt;
&lt;h3&gt;Can FinalBuilder 8 open an run my old projects?&lt;/h3&gt;
&lt;p&gt;Yes, FinalBuilder 8 can open and run any projects from any earlier version of FinalBuilder. When you save the projects in FinalBuilder 8, it will save it as a FinalBuilder 8 project (new file).&lt;/p&gt;
&lt;h3&gt;Can older versions of FinalBuilder open FinalBuilder 8 projects?&lt;/h3&gt;
&lt;p&gt;No, FinalBuilder 8 projects use a different file format.&lt;/p&gt;
&lt;h3&gt;Does FinalBuilder 8 work with FinalBuilder Server 7?&lt;/h3&gt;
&lt;p&gt;
No. FinalBuilder 8 does not work with FB Server 7, nor can it be made to work. FinalBuilder Server was discontinued over 2 years ago, if you need Continuous Integration then consider migrating to
&lt;a https: www.finalbuilder.com continua-ci&gt;Continua CI.&lt;/a&gt;
&lt;/p&gt;
&lt;h3&gt;I have questions!&lt;/h3&gt;
&lt;p&gt;Feel free to contact support@finalbuilder.com with any questions you might have.&lt;/p&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Fri, 21 Aug 2015 10:02:02 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2015-08-21:finalbuilder-8-released.html</guid><category>finalbuilder</category></item><item><title>Introducing Continua CI Version 1.7 beta</title><link>http://ciandcd.github.io/introducing-continua-ci-version-17-beta.html</link><description>From:&lt;a href="https://www.finalbuilder.com/resources/blogs/postid/732/introducing-continua-ci-version-17-beta"&gt;https://www.finalbuilder.com/resources/blogs/postid/732/introducing-continua-ci-version-17-beta&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p&gt;This version introduces several new features, many of which have been requested by users over the past few months. These features are built upon the various improvements and bug fixes applied in revisions to version 1.6.
Please don&amp;#8217;t dismay if your requested feature is not included yet, it is still high on our to-do list. Indeed we have several other features specced out, and some partially developed in the background.&lt;/p&gt;
&lt;h2&gt;Version 1.7 Features&lt;/h2&gt;
&lt;h3&gt;New Builds View dashboard&lt;/h3&gt;
&lt;p&gt;This view is useful for project administrators and shows a list of active builds across all viewable configurations. This includes running builds, queued builds and builds awaiting promotion.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="/blogimages/daves/v1.7beta/buildsview.png"&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3&gt;New panel of indicators&lt;/h3&gt;
&lt;p&gt;Some important numbers including the total count of queued and running builds, as well as available agents and concurrent build licenses.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="/blogimages/daves/v1.7beta/indicators.png"&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3&gt;New Repositories tab&lt;/h3&gt;
&lt;p&gt; This is accessed via the Configurations view and shows status of each repository. We've also included &amp;#8220;Check &amp;#160;Now&amp;#8221; buttons for immediately polling each repository. You can also initiate repository checking from all existing repository pages&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="/blogimages/daves/v1.7beta/repoview.png"&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3&gt;Project-wide and configuration versioning options.&lt;/h3&gt;
&lt;p&gt;We've added some new options in the details section of the project and configuration wizards&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Project-wide versioning: &lt;/strong&gt;The build version number can now be incremented across many configurations within a project.&lt;br&gt;&lt;br&gt;&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;Build number re-use: &lt;/strong&gt;A new &lt;p&gt;option at the&amp;#160;&lt;/p&gt;project or configuration level to decrement the version counter when a build is discarded while initialising. e.g. due to configuration conditions. Please note that the build number will be decremented only if no other build has started in the mean time and is using a later build number. &amp;#160;&lt;br&gt;&lt;br&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;
&lt;img alt="" src="/blogimages/daves/v1.7beta/projectwidesettings.png"&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3&gt;Improvements to Build Completed triggers.&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Variable expressions: &lt;/strong&gt;You can now use expressions when defining variables allowing you to pass information from triggering to triggered build.&lt;br&gt;&lt;br&gt;&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;New conditions tab:&lt;/strong&gt; This allows you to use expressions to control whether a build is triggered&lt;br&gt;&lt;br&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;
&lt;img alt="" src="/blogimages/daves/v1.7beta/buildcompletedconditions.png"&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3&gt;Improvements to Repository triggers.&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Trigger on specific file change types: &lt;/strong&gt;Triggers can now be set to start only when the changeset contains certain types of file changes e.g. additions, modifications and deletions.&lt;br&gt;&lt;br&gt;&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;Trigger file pattern: &lt;/strong&gt;You can now specify a file pattern for repository triggers to restrict triggering only to changesets containing matching files.&lt;br&gt;&lt;br&gt;&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;Trigger comment pattern:&amp;#160;&lt;/strong&gt;You can also limit triggering to changesets with specific text in the comment.&lt;br&gt;&lt;br&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;
&lt;img alt="" src="/blogimages/daves/v1.7beta/repotriggeroptions.png"&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3&gt;Other build features&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;New &lt;strong&gt;force repository check&lt;/strong&gt; option in queue build dialog allowing control over whether to recheck repository when building. There is also a default setting for each configuration&lt;br&gt;&lt;br&gt;&lt;/li&gt;
    &lt;li&gt;Improvements to &lt;strong&gt;Stop Build buttons on dashboard view&lt;/strong&gt;&amp;#160;to ensure that the build stopped is always the latest build at the time when the button was clicked. Stop build dialogs also now display the build number of the build being stopped.&lt;/li&gt;
&lt;/ul&gt;&lt;br&gt;&lt;h3&gt;Actions and event handlers&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;New &lt;strong&gt;node.js actions
    &lt;/strong&gt;
    &lt;ul&gt;&lt;li&gt;Package management with Npm and Bower&lt;/li&gt;
        &lt;li&gt;Grunt and Gulp build runners&lt;/li&gt;
        &lt;li&gt;Unit testing with Mocha&lt;br&gt;&lt;br&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/li&gt;
    &lt;li&gt;New build event handler for posting &lt;strong&gt;status updates to a Stash server&lt;/strong&gt;&lt;br&gt;&lt;br&gt;&lt;/li&gt;
    &lt;li&gt;Log Entry action now allows you to &lt;strong&gt;add the message as a build comment&lt;/strong&gt;. This can be useful for showing additional build details on the build view page.&lt;br&gt;&lt;br&gt;&lt;/li&gt;
    &lt;li&gt;New &lt;strong&gt;comments field &lt;/strong&gt;on all actions &amp;#8211; displayed as a tooltip in Stages editor.&lt;br&gt;&lt;br&gt;&lt;/li&gt;
    &lt;li&gt;New ContinuaCI.* &lt;strong&gt;system environment variables&lt;/strong&gt; are now available to all executable actions.&lt;br&gt;&lt;br&gt;ContinuaCI.AgentProperty.*&lt;br&gt;
                ContinuaCI.Variable.*&lt;br&gt;
                ContinuaCI.Project.Name&lt;br&gt;
                ContinuaCI.Configuration.Name&lt;br&gt;
                ContinuaCI.Build.Id&lt;br&gt;
                ContinuaCI.Build.BuildNumber&lt;br&gt;
                ContinuaCI.Build.ChangesetCount&lt;br&gt;
                ContinuaCI.Build.ChangesetRevisions&lt;br&gt;
                ContinuaCI.Build.ChangesetTagNames &lt;br&gt;
                ContinuaCI.Build.ChangesetUserNames &lt;br&gt;
                ContinuaCI.Build.Elapsed &lt;br&gt;
                ContinuaCI.Build.HasNewChanges&lt;br&gt;
                ContinuaCI.Build.IsFeatureBranchBuild&lt;br&gt;
                
                ContinuaCI.Build.IssueCount&lt;br&gt;
                ContinuaCI.Build.LatestChangeset.Created&lt;br&gt;
                ContinuaCI.Build.LatestChangeset.IssueCount&lt;br&gt;
                ContinuaCI.Build.LatestChangeset.RepositoryName&lt;br&gt;
                ContinuaCI.Build.LatestChangeset.Revision&lt;br&gt;
                ContinuaCI.Build.LatestChangeset.TagCount&lt;br&gt;
                ContinuaCI.Build.LatestChangeset.UserName&lt;br&gt;
                ContinuaCI.Build.Started&lt;br&gt;
                ContinuaCI.Build.StartedBy&lt;br&gt;
                ContinuaCI.Build.TimeOnQueue&lt;br&gt;
                ContinuaCI.Build.UsesDefaultBranch&lt;br&gt;
                ContinuaCI.Build.Version&lt;br&gt;
            &lt;br&gt;&lt;br&gt;&lt;/li&gt;
    &lt;li&gt;Execute Program, DOS Command and PowerShell actions now include an option to generate a &lt;strong&gt;context XML file&lt;/strong&gt;. This file contains details of the build including repositories, changesets and files for you to parse with your own script or program.&lt;/li&gt;
&lt;/ul&gt;&lt;br&gt;&lt;br&gt;&lt;h3&gt;Git repositories&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Case-only renames&lt;/strong&gt; are now recorded in the repository cache.&lt;br&gt;&lt;br&gt;&lt;/li&gt;
    &lt;li&gt;New option to list &lt;strong&gt;author instead of committer&lt;/strong&gt; as changeset username&lt;/li&gt;
&lt;/ul&gt;&lt;br&gt;&lt;br&gt;&lt;h5&gt;&lt;strong&gt;Version 1.7 beta is ready for you to &lt;a href="https://www.finalbuilder.com/downloads/continuaci"&gt;download&lt;/a&gt; and install. All feedback is welcome!&lt;/strong&gt;&lt;/h5&gt;&amp;#13;
                        &lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &amp;#13;
                    &lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Thu, 30 Jul 2015 06:30:43 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2015-07-30:introducing-continua-ci-version-17-beta.html</guid><category>finalbuilder</category></item><item><title>Visualizations of Continuous Delivery</title><link>http://ciandcd.github.io/visualizations-of-continuous-delivery.html</link><description>From:&lt;a href="http://continuousdelivery.com/2014/02/visualizations-of-continuous-delivery/"&gt;http://continuousdelivery.com/2014/02/visualizations-of-continuous-delivery/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p class="post-headline"&gt;&lt;h1&gt;Visualizations of Continuous Delivery&lt;/h1&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://www.linkedin.com/pub/nhan-ngo/11/938/ba5"&gt;Nhan Ngo&lt;/a&gt;, a QA engineer at &lt;a href="http://spotify.com"&gt;Spotify&lt;/a&gt;, made four fabulous visualizations while reading &lt;a href="http://www.amazon.com/dp/0321601912?tag=contindelive-20"&gt;Continuous Delivery&lt;/a&gt;. She has very kindly agreed to make them available under a Creative Commons license so feel free to share them, download them, and print them out (click to get a higher resolution version). Thank you Nhan!&lt;/p&gt;
&lt;p&gt;&lt;a href="http://continuousdelivery.com/wp-content/uploads/2014/02/01_CD_the_idea_low-res.jpg"&gt;&lt;img src="http://continuousdelivery.com/wp-content/uploads/2014/02/01_CD_the_idea_low-res.jpg" alt="01_CD_the_idea_low-res" width="550" class="alignleft wp-image-1155"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://continuousdelivery.com/wp-content/uploads/2014/02/02_CD_test_strategy_low-res.jpg"&gt;&lt;img src="http://continuousdelivery.com/wp-content/uploads/2014/02/02_CD_test_strategy_low-res.jpg" alt="02_CD_test_strategy_low-res" width="550" class="alignleft wp-image-1156"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://continuousdelivery.com/wp-content/uploads/2014/02/03_CD_automated_acceptance_test_low-res.jpg"&gt;&lt;img src="http://continuousdelivery.com/wp-content/uploads/2014/02/03_CD_automated_acceptance_test_low-res.jpg" alt="03_CD_automated_acceptance_test_low-res" width="550" class="alignleft wp-image-1157"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://continuousdelivery.com/wp-content/uploads/2014/02/04_CD_managing_data_low-res.jpg"&gt;&lt;img src="http://continuousdelivery.com/wp-content/uploads/2014/02/04_CD_managing_data_low-res.jpg" alt="04_CD_managing_data_low-res" width="550" class="alignleft wp-image-1158"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kobi Halperin</dc:creator><pubDate>Thu, 20 Feb 2014 18:01:28 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2014-02-20:visualizations-of-continuous-delivery.html</guid><category>ciandcd</category></item><item><title>The Science Behind the 2013 Puppet Labs DevOps Survey Of Practice</title><link>http://ciandcd.github.io/the-science-behind-the-2013-puppet-labs-devops-survey-of-practice.html</link><description>From:&lt;a href="http://continuousdelivery.com/2013/12/the-science-behind-the-2013-puppet-labs-devops-survey-of-practice/"&gt;http://continuousdelivery.com/2013/12/the-science-behind-the-2013-puppet-labs-devops-survey-of-practice/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p class="post-headline"&gt;&lt;h1&gt;The Science Behind the 2013 Puppet Labs DevOps Survey Of Practice&lt;/h1&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;By &lt;a href="https://twitter.com/RealGeneKim"&gt;Gene Kim&lt;/a&gt; and Jez Humble&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Last year, we both had the privilege of working with Puppet Labs to develop the 2012 DevOps Survey Of Practice. It was especially exciting for Gene, because we were able to benchmark the performance of over 4000 IT organizations, and to gain an understanding what behaviors result in their incredible performance. This continues research that he has been doing of high performing IT organizations that started for him in 1999.&lt;/p&gt;
&lt;p&gt;In this blog post, Gene Kim and I will discuss the research hypotheses that we&amp;#8217;re setting out to test in the 2013 DevOps Survey Of Practice, explain the mechanics of how these types of cross-population studies actually work (so you help this research effort or even start your own), then describe the key findings that came out of the 2012 study.&lt;/p&gt;
&lt;p&gt;But first off, if you&amp;#8217;re even remotely interested in DevOps, &lt;a href="http://www.surveygizmo.com/s3/1483785/DevOps-Survey-2013"&gt;go take the 2013 Puppet Labs DevOps Survey here&lt;/a&gt;! The survey closes on January 15, 2014, so hurry! It only takes about ten minutes.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;h3 id="2013-devops-survey-research-goals"&gt;2013 DevOps Survey Research Goals&lt;/h3&gt;
&lt;p&gt;Last year&amp;#8217;s study (which we&amp;#8217;ll describe in more detail below) found that high performing organizations that were employing DevOps practices were massively outperforming their peers: they were doing 30x more frequent code deploys, and had deployment lead times measured in minutes or hours (versus lower performers, who required weeks, months or quarters to complete their deployments).&lt;/p&gt;
&lt;p&gt;The high performers also had far better deployment outcomes: their changes and deployments had twice the change success rates, and when the changes failed, they could restore service 12x faster.&lt;/p&gt;
&lt;p&gt;The goal of the 2013 study is to gain a better understanding of exactly what practices are required to achieve this high performance. Our hypothesis is that the following are required, and we&amp;#8217;ll be looking to independently evaluate the effect of each of these practices on performance:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;small teams with high trust that span the entire value stream: Dev, QA, IT Operations and Infosec&lt;/li&gt;
&lt;li&gt;shared goals and shared pain that span the entire value stream&lt;/li&gt;
&lt;li&gt;small development batch sizes&lt;/li&gt;
&lt;li&gt;presence of continuous, automated integration and testing&lt;/li&gt;
&lt;li&gt;emphasis on creating a culture of learning, experimentation and innovation&lt;/li&gt;
&lt;li&gt;emphasis on creating resilient systems&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We are also testing two other hypotheses that one of us (Gene) is especially excited about, because it&amp;#8217;s something he&amp;#8217;s wanted to do ever since 1999!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Lead time&lt;/strong&gt;: In plant manufacturing, lead time is the time required to turn raw materials into finished goods. There is a deeply held belief in the Lean community that lead time is the single best predictor of quality, customer satisfaction and employee happiness. We are testing this hypothesis for the DevOps value stream in the 2013 survey instrument.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Organizational performance&lt;/strong&gt;: Last year, we confirmed that DevOps practices correlate with substantially improved IT performance (e.g., deploy frequencies, lead times, change success rates, MTTR). This year, we will be testing whether improved IT performance correlates with improved business performance. In this year&amp;#8217;s study, we&amp;#8217;ve added inserted three questions that are known to correlate with organizational performance, which is known to correlate with business performance (e.g., competitiveness in the marketplace, return on assets, etc.).&lt;/p&gt;
&lt;p&gt;Our dream headline would be, &amp;#8220;high performing organizations not only do 30x more frequent code deployments than their peers, but they also outperform the S&amp;amp;P 500 by 3x as measured by shareholder return and return on assets.&amp;#8221;&lt;/p&gt;
&lt;p&gt;Obviously, there are many other variables that contribute to business performance besides Dev and Ops performance (e.g., profitability, market segment, market share, etc.). However, in our minds, the reliance upon IT performance is obvious: as Chris Little said, &amp;#8220;Every organization is an IT business, regardless of what business they think they&amp;#8217;re in.&amp;#8221;&lt;/p&gt;
&lt;p&gt;When IT does poorly, the business will do poorly. And when IT helps the organization win, those organizations will out-perform their competitors in the marketplace.&lt;/p&gt;
&lt;p&gt;(This hypothesis forms the basis of the hedge fund that Erik wants to create in the last chapter of &lt;a href="http://www.amazon.com/The-Phoenix-Project-Business-ebook/dp/B00AZRBLHO/"&gt;&amp;#8220;The Phoenix Project: A Novel About IT, DevOps, and Helping Your Business Win&amp;#8221;&lt;/a&gt;, where they would make long or short bets, based on the known operating characteristics of the IT organization.)&lt;/p&gt;
&lt;h3 id="the-theory-behind-cross-population-studies-and-survey-instruments"&gt;The Theory Behind Cross-Population Studies and Survey Instruments&lt;/h3&gt;
&lt;p&gt;Like last year, this year&amp;#8217;s DevOps survey is a cross-population study, designed to explore the link between organizational performance and organizational practices and cultural norms.&lt;/p&gt;
&lt;p&gt;What is a cross-population study? It&amp;#8217;s a statistical research technique designed to uncover what factors (e.g., practices, cultural norms, etc.) correlate with outcomes (e.g., IT performance). Cross-population studies are often used in medical research to answer questions like, &amp;#8220;is cigarette smoking a significant factor in early mortality?&amp;#8221;&lt;/p&gt;
&lt;p&gt;Properly designed cross-population studies are considered a much more rigorous approach of testing efficacy of what practices work than say, interviewing people about what they think worked, ROI stories from vendors, or collecting &amp;#8220;known, best practices.&amp;#8221;&lt;/p&gt;
&lt;p&gt;&lt;img class="alignnone" alt="" src="https://draftin.com:443/images/6464?token=JXI7N7uDAMybn5lduEANKdQhwmXNNkJoBYsb2fE4jeFS9KsliXjnALaa33oHlCOP0_nW8tviUZ8zYBdwzPIOPtQ" width="426" height="289"&gt;&lt;/p&gt;
&lt;p&gt;When doing survey design, we might state our hypotheses in the following form: &amp;#8220;we believe that IT organizations which have high trust have higher IT performance.&amp;#8221; In other words, the higher the trust levels in the IT organization, the higher the performance.&lt;/p&gt;
&lt;p&gt;We then put this question in the survey instrument, and then analyze the results. If we were to plot the results on a graph, we would put the dependent variable (i.e., performance) on the Y-axis, and the independent variable (i.e., presence of high trust) on the X-axis.&lt;/p&gt;
&lt;p&gt;We would then test to see if there is a correlation between the two. Shown below is an example of what it looks like when the two variables have low or no correlation, and one that has a significant positive correlation.&lt;/p&gt;
&lt;p&gt;&lt;img class="alignnone" alt="" src="https://draftin.com:443/images/6465?token=EVRyxLU4nXU9O19I5TKk_64PCVLbwzGFy9P3kEQKdMUo4Ceg6Yn-cC5jFw2_N9IQwEPkrSUBLmUA_cJKWm5YP3g" width="463" height="162"&gt;&lt;/p&gt;
&lt;p&gt;If we were to find a significant correlation, such as displayed on the right, we could then assert that &amp;#8220;the higher your organization&amp;#8217;s trust levels, in general, the higher your IT performance.&amp;#8221;&lt;/p&gt;
&lt;p&gt;(Graph adapted from &lt;a href="http://en.wikipedia.org/wiki/Correlation_and_dependence"&gt;Wikipedia entry on Correlation and Dependence&lt;/a&gt;.)&lt;/p&gt;
&lt;h3 id="key-2012-devops-survey-findings"&gt;The 2012 DevOps Survey&lt;/h3&gt;
&lt;p&gt;In this section, we will describe the the key findings that came out of the 2012 DevOps Survey, as well as a brief discussion of the research hypotheses that went into the survey design.&lt;/p&gt;
&lt;p&gt;In the DevOps community, we have long asserted that certain practices enables organizations simultaneously deliver fast flow of features to market, while providing world-class stability, reliability and security.&lt;/p&gt;
&lt;p&gt;We designed the survey to validate this, and tested a series of technical practices to determine which of them correlated with high performance.&lt;/p&gt;
&lt;p&gt;The survey ran for 30 days, and we had 4,039 completed respondents. (This is an astonishingly high number, by the way. When Kurt Milne and Gene Kim did similar studies in 2006, each study typically required $200K to do the survey design, gather responses from a couple hundred people, and then perform survey analysis.)&lt;/p&gt;
&lt;p&gt;You can find the &lt;a href="http://www.slideshare.net/realgenekim/2013-velocity-devops-metrics-its-not-just-for-webops-any-more"&gt;slides that Gene Kim, Jez Humble and James Turnbull presented at the 2013 Velocity Conference here&lt;/a&gt;, and the &lt;a href="https://puppetlabs.com/2013-state-of-devops-infographic"&gt;full Puppet Labs infographics and results here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&amp;#160;&lt;/p&gt;
&lt;p&gt;The first surprise was how much the high performing organizations were outperforming their non-high-performing peers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Agility metrics&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;30x more frequent code deployments&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;8,000x faster lead time than their peers&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Reliability metrics&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;2x the change success rate&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;12x faster MTTR&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In other words, they were more agile: they were deploying code 30x more frequently, and the lead time required to go from &amp;#8220;code committed&amp;#8221; to &amp;#8220;successfully running in production&amp;#8221; was completed 8,000x faster &amp;#8212; high performers had lead times measured in minutes or hours, while lower performers had lead times measured in weeks, months or even quarters.&lt;/p&gt;
&lt;p&gt;Not only were the high performers doing more work, but they had far better outcomes: when the high performers deployed changes and code, they were twice as likely to be completed successfully (i.e., without causing a production outage or service impairment), and when the change failed and resulted in an incident, the time required to resolve the incident was 12x faster.&lt;/p&gt;
&lt;p&gt;We were astonished and delighted with this finding, as it showed not only that it was possible to break the core, chronic conflict, but that it seemed to confirm that just as in manufacturing, agility and reliability go hand in hand. In other words, lead time correlates with both both agility and reliability.&lt;/p&gt;
&lt;p&gt;(Gene will write more on his personal interpretations of the 2012 DevOps Survey Of Practice in a future post.)&lt;/p&gt;
&lt;h3 id="conclusion"&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;We hope this gives you a good idea of why we&amp;#8217;ve worked so hard on the 2012 and 2013 DevOps Survey, as well as how to conduct your own cross-population studies. Please let us know if you have any questions or if there&amp;#8217;s anything we can do for you.&lt;/p&gt;
&lt;p&gt;And of course, help us understand what in DevOps and Continuous Delivery work by &lt;a href="http://www.surveygizmo.com/s3/1483785/DevOps-Survey-2013"&gt;taking 10 minutes to participate in the 2013 Puppet Labs DevOps Survey here by January 15, 2014&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;Thank you! &amp;#8211;Gene Kim and Jez Humble&lt;/p&gt;
&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Mon, 30 Dec 2013 19:27:39 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2013-12-30:the-science-behind-the-2013-puppet-labs-devops-survey-of-practice.html</guid><category>ciandcd</category></item><item><title>FlowCon 2013 Wrap-Up, With Some Hard Data on Gender Diversity in Tech Conferences.</title><link>http://ciandcd.github.io/flowcon-2013-wrap-up-with-some-hard-data-on-gender-diversity-in-tech-conferences.html</link><description>From:&lt;a href="http://continuousdelivery.com/2013/12/flowcon-2013-wrap-up/"&gt;http://continuousdelivery.com/2013/12/flowcon-2013-wrap-up/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p class="post-headline"&gt;&lt;h1&gt;FlowCon 2013 Wrap-Up, With Some Hard Data on Gender Diversity in Tech Conferences.&lt;/h1&gt;&lt;/p&gt;&lt;p&gt;Thanks to all of you who came along to FlowCon! If you weren&amp;#8217;t able to make it, you can &lt;a href="http://www.youtube.com/channel/UCMk1sRo1hnTLMA3kpn6BVKg"&gt;watch the videos for free&lt;/a&gt; thanks to &lt;a href="https://communities.bmc.com/community/bsm_initiatives/devops/blog"&gt;BMC&lt;/a&gt;&lt;a&gt;&lt;/a&gt; and &lt;a href="http://www.thoughtworks.com/studios"&gt;ThoughtWorks Studios&lt;/a&gt;. The &lt;a href="http://flowcon.org/flowcon-sanfran-2013/schedule/index.jsp"&gt;slides are also available&lt;/a&gt; for downloading.&lt;/p&gt;
&lt;p&gt;Let me first express my thanks to our producers: Geeta Schmidt and Niley Barros of &lt;a href="http://www.trifork.com/"&gt;Trifork&lt;/a&gt; and Rebecca Phillips of &lt;a href="http://www.thoughtworks.com/studios"&gt;ThoughtWorks Studios&lt;/a&gt;. I also want to thank my fellow PC members &lt;a href="https://twitter.com/thinknow"&gt;Lane Halley&lt;/a&gt;, &lt;a href="https://twitter.com/testobsessed"&gt;Elisabeth Hendrickson&lt;/a&gt;, &lt;a href="https://twitter.com/RealGeneKim"&gt;Gene Kim&lt;/a&gt; and &lt;a href="https://twitter.com/johndesser"&gt;John Esser&lt;/a&gt;; our fabulous &lt;a href="flowcon.org/flowcon-sanfran-2013/speakers/"&gt;speakers&lt;/a&gt;; our generous &lt;a href="http://flowcon.org/flowcon-sanfran-2013/sponsors/"&gt;sponsors&lt;/a&gt;; and everyone who came along.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;h3&gt;The Program&lt;/h3&gt;
&lt;p&gt;The goal of the program committee was to create a conference that represents our industry as we want it to look, not as it is right now. That&amp;#8217;s an ambitious goal that involves changing the way we think about everything from &lt;a href="http://www.youtube.com/watch?v=Nc587c76Syg"&gt;leadership&lt;/a&gt; and &lt;a href="http://www.youtube.com/watch?v=PijCUJDb_hc"&gt;governance&lt;/a&gt; through &lt;a href="http://www.youtube.com/watch?v=5JF_QMIMBls"&gt;product&lt;/a&gt; &lt;a href="http://www.youtube.com/watch?v=vhFcux5UO4A"&gt;development&lt;/a&gt; and &lt;a href="http://www.youtube.com/watch?v=Socg4SIzAB4"&gt;design&lt;/a&gt;, to &lt;a href="http://www.youtube.com/watch?v=6jmZkV23TEs"&gt;IT&lt;/a&gt; &lt;a href="http://www.youtube.com/watch?v=7779Wrun5fo"&gt;operations&lt;/a&gt;. Not only did our speakers cover all these topics; they also provided real examples of how these changes, along with the cultural changes necessary to support them, have been achieved at enterprise scale.&lt;/p&gt;
&lt;p&gt;Thus we attacked one of the main objections we hear time and time again &amp;#8212; &amp;#8220;that sounds great, but it couldn&amp;#8217;t work here&amp;#8221;. Part of our vision was to provide a platform for people to speak about gnarly, real-life examples that demonstrate that, with sufficient hard work and ingenuity, ideas like continuous delivery, devops, and lean product development can provide significant competitive advantage through higher quality, cost savings, and happier customers, even in traditionally slow-moving and highly-regulated industries with large, complex, heterogeneous systems.&lt;/p&gt;
&lt;p&gt;Two talks that I am particularly happy to have on record are &lt;a href="http://www.youtube.com/watch?v=Trqjj3d3lhQ"&gt;Gary Gruver&amp;#8217;s talk&lt;/a&gt; on doing continuous delivery for printer firmware at HP, and &lt;a href="http://www.youtube.com/watch?v=eMS97X5ZTGc"&gt;John Kordyback&amp;#8217;s talk&lt;/a&gt; on doing continuous delivery with mainframes in the financial services industry. Alternatively, if you want a vision of the state of the art of continuous delivery, it would be hard to beat &lt;a href="http://www.youtube.com/watch?v=wyWI3gLpB8o"&gt;Adrian Cockcroft&amp;#8217;s opening keynote&lt;/a&gt; (the most highly rated talk of the conference) on how Netflix approach building and running systems.&lt;/p&gt;
&lt;p&gt;Overall, both the individual quality of the talks and the vision they present in concert was incredibly inspiring. Gene Kim comments, &amp;#8220;The FlowCon program was amazing. In my mind, what was presented at FlowCon is what every IT practitioner will be required to know in 10 years time.&amp;#8221; Thank you again to all of our speakers.&lt;/p&gt;
&lt;h3&gt;Data on Gender Diversity&lt;/h3&gt;
&lt;p&gt;Part of representing the industry as we want it to look is changing its composition. Thus another personal goal for me was to gather data to support my hypothesis that &lt;a href="http://continuousdelivery.com/2013/09/how-we-got-40-female-speakers-at-flowcon/"&gt;taking steps to increase diversity&lt;/a&gt; at conferences doesn&amp;#8217;t mean reducing quality. FlowCon, like the excellent &lt;a href="http://gotocon.com/"&gt;GOTO conferences&lt;/a&gt; that Trifork produces, records feedback from participants. Everybody leaving a session can give feedback on whether they thought the talk was good, mediocre or poor by tapping a red, amber or green rectangle on an iPhone on their way out. We then calculate overall satisfaction as follows: satisfaction = (green votes) / (total votes).&lt;/p&gt;
&lt;p&gt;When we got back all the data, the first thing I did is look at the average (mean) satisfaction for male speakers versus female speakers. It turns out that in both cases the average is between 71% and 72%. First of all, this demonstrates that there was no statistically significant difference in satisfaction between male and female speakers. This is important because it means our steps to increase diversity &amp;#8212; including reaching out to a wide network to ensure that 50% of our invited speakers were women &amp;#8212; didn&amp;#8217;t &amp;#8220;lower the bar&amp;#8221;.&lt;/p&gt;
&lt;p&gt;There is also a deeper implication: any claim that the all-white-male conference programs that are so depressingly common in the tech industry are the result of some meritocratic process is BS. They are, rather, the result of not putting in enough effort to seek out high quality speakers from &lt;a href="http://martinfowler.com/bliki/HistoricallyDiscriminatedAgainst.html"&gt;historically discriminated against&lt;/a&gt; groups.&lt;/p&gt;
&lt;p&gt;If our industry were truly meritocratic, the speaker line-up and attendees would resemble the wider population, because we know that there is &lt;a href="http://martinfowler.com/bliki/DiversityImbalance.html"&gt;no biological explanation&lt;/a&gt; for the overwhelming proportion of white dudes in our industry. So let&amp;#8217;s not fool ourselves any more with claims that taking steps to improve diversity is &amp;#8220;reverse discrimination&amp;#8221;. Any time we don&amp;#8217;t take concrete, systematic steps forward we are silently complicit in perpetuating the status quo &amp;#8212; which is why it&amp;#8217;s not good enough when leaders in the tech community ignore the problem. If you ignore the problem, you&amp;#8217;re part of the problem.&lt;/p&gt;
&lt;p&gt;Finally, I want to emphasize that what the program committee achieved was not very hard, once we spent some time thinking the problem through, and also that it was insufficient. We had a reasonable level of gender diversity, but the speakers were still overwhelmingly white. I don&amp;#8217;t have data for the diversity of our audience, but based on observation, there were more white guys than I would see if I walked out of the door onto the streets (and this is in San Francisco, which is far from being representative of the wider population).&lt;/p&gt;
&lt;p&gt;If you want to educate yourself further on these issues, I suggest watching &lt;a href="http://www.youtube.com/watch?v=VafA2stfTUM"&gt;Ashe Dryden&amp;#8217;s talk&lt;/a&gt; on programming diversity. And if you&amp;#8217;d like to become more effective at creating change, check out &lt;a href="http://www.youtube.com/watch?v=PJWKvkfbPo0"&gt;Linda Rising&amp;#8217;s closing keynote&lt;/a&gt;. Here&amp;#8217;s to &lt;a href="http://geekfeminism.wikia.com/wiki/Resources_for_allies"&gt;taking small steps every day&lt;/a&gt; to make 2014 a marginally, incrementally, &lt;a href="http://geekfeminism.wikia.com/wiki/Timeline_of_incidents#2013"&gt;better year than 2013&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">William Pietri</dc:creator><pubDate>Fri, 27 Dec 2013 06:42:55 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2013-12-27:flowcon-2013-wrap-up-with-some-hard-data-on-gender-diversity-in-tech-conferences.html</guid><category>ciandcd</category></item><item><title>How To Create A More Diverse Tech Conference</title><link>http://ciandcd.github.io/how-to-create-a-more-diverse-tech-conference.html</link><description>From:&lt;a href="http://continuousdelivery.com/2013/09/how-we-got-40-female-speakers-at-flowcon/"&gt;http://continuousdelivery.com/2013/09/how-we-got-40-female-speakers-at-flowcon/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p class="post-headline"&gt;&lt;h1&gt;How To Create A More Diverse Tech Conference&lt;/h1&gt;&lt;/p&gt;&lt;p&gt;I have been advised by people I trust that it&amp;#8217;s not a good idea to talk about how you got serious female representation at your conference until after it&amp;#8217;s over. However the shameful RubyConf &lt;a href="https://twitter.com/shanley/status/380179040545406976"&gt;&amp;#8220;binders full of men&amp;#8221;&lt;/a&gt; debacle and the Neanderthal level of discussion around it has wound me up enough to write this account somewhat prematurely. So here is how we achieved &amp;gt;40% female representation on our &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speakers/"&gt;speaker roster&lt;/a&gt; at &lt;a href="http://flowcon.org/"&gt;FlowCon&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 0. Care About The Outcome.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;When John Esser approached me to put together a conference about continuous delivery, devops and lean product development, I thought carefully about it. I&amp;#8217;ve helped put together a conference program before (&lt;a href="http://qconsf.com/sf2012/sf2012/"&gt;QCon SF 2012&lt;/a&gt;), and that was pretty hard work, so I wanted to be sure I had the correct motivation.&lt;/p&gt;
&lt;p&gt;One of the things that I have always disliked about tech conferences is being surrounded by a bunch of other straight white guys (nothing personal, some of my best friends are straight white guys). It&amp;#8217;s a constant reminder of the fact that, due to a number of socioeconomic factors, &lt;a href="http://whatever.scalzi.com/2012/05/15/straight-white-male-the-lowest-difficulty-setting-there-is/"&gt;straight white guys have it easier than others&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I wanted to put together a conference which reflects my community as I would like it to look, not as it actually looks. So one of the &lt;a href="http://flowcon.org/"&gt;four values&lt;/a&gt; the FlowCon program committee came up with was this: &amp;#8220;Diversity: We believe the technology community &amp;#8211; and thus the conference speakers and participants &amp;#8211; should reflect the demographics of our customers and the wider world.&amp;#8221;&lt;/p&gt;
&lt;p&gt;There are two reasons for this. Firstly, we can&amp;#8217;t effectively change the world through technology without diversity. To find out why, come and see &lt;a href="http://ashedryden.com/"&gt;Ashe Dryden&lt;/a&gt; talk about how &lt;a href="http://flowcon.org/flowcon-sanfran-2013/presentation/Programming%20Diversity"&gt;&amp;#8220;diverse communities and workplaces create better products&amp;#8221;&lt;/a&gt;. Second, one of the main reasons I like working at &lt;a href="http://www.thoughtworks.com/"&gt;ThoughtWorks&lt;/a&gt; is that one of &lt;a href="http://www.thoughtworks.com/about-us"&gt;the three pillars of our mission&lt;/a&gt; is to &amp;#8220;advocate passionately for social and economic justice.&amp;#8221; The fact there are so few women in IT reflects social and economic injustice inherent in our world.&lt;/p&gt;
&lt;p&gt;Making sure you actually have a mission for your conference is something I learned from helping out with &lt;a href="qconsf.com"&gt;QCon SF&lt;/a&gt;. It is a constant reminder of why you&amp;#8217;re doing it and what&amp;#8217;s important about it. If you don&amp;#8217;t have a mission, you&amp;#8217;re at the mercy of the implicit biases of the organizers. As RubyConf shows, you can&amp;#8217;t just throw in the &lt;a href="https://twitter.com/shanley/status/380186471174393856"&gt;&amp;#8220;one weird trick&amp;#8221;&lt;/a&gt; of anonymous submissions and expect that it will somehow solve the problem. Everybody on the program committee actually has to care about the outcome, or they won&amp;#8217;t put in the right amount of work to make it happen.&lt;/p&gt;
&lt;p&gt;Once you do that, the rest of the steps aren&amp;#8217;t that hard.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 1. Make Sure Your Program Committee Is Aligned With Your Mission&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Once I had an idea about the mission of the conference, I reached out to some people whom I thought would share it. I was lucky enough that &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/Elisabeth+Hendrickson"&gt;Elizabeth Hendrickson&lt;/a&gt;, &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/Lane+Halley"&gt;Lane Halley&lt;/a&gt; and &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/Gene+Kim"&gt;Gene Kim&lt;/a&gt; agreed to join &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/John+Esser"&gt;John Esser&lt;/a&gt; and me on the program committee.&lt;/p&gt;
&lt;p&gt;One of the main reasons I asked those particular people, apart from being extremely competent and well-respected in their field, was another conference goal: &amp;#8220;Spanning boundaries: We believe that the best products are created collaboratively by people with a range of skills and experiences.&amp;#8221; The program committee has representation from the UX, testing, operations, product development and programming communities.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 2. Make Sure Your Invited Speakers Are Aligned With Your Mission.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We made the decision to have about half the program be invited speakers. Part of that was about ensuring that we had a solid core program. But it was also a chance for us to put our mission into practice, so that when we put out the call for proposals we had a bunch of confirmed speakers who demonstrated we were serious about our mission.&lt;/p&gt;
&lt;p&gt;Thus we made sure that the invited speakers were respected boundary spanners, and that 50% of them were women. This involved more work than we would have had to put in had we just invited our friends (a popular strategy for program committees). It was also telling that we got more refusals from women than we got from men due to schedule conflicts. The main factor here was that female speakers are actually in greater demand than men because there are relatively fewer of them.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 3. The Anonymous Call For Proposals&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If you jump straight to step 3, it&amp;#8217;s likely you will suffer the fate of RubyConf and fail. If you use this as your only strategy for increasing representation it won&amp;#8217;t work. This strategy has been &lt;a href="http://geekfeminism.org/2012/05/21/how-i-got-50-women-speakers-at-my-tech-conference/"&gt;thoroughly&lt;/a&gt; &lt;a href="http://2012.jsconf.eu/2012/09/17/beating-the-odds-how-we-got-25-percent-women-speakers.html"&gt;discussed&lt;/a&gt; by &lt;a href="http://www.startuplessonslearned.com/2012/11/solving-pipeline-problem.html"&gt;others&lt;/a&gt; who have used this approach as part of increasing diversity at their conference.&lt;/p&gt;
&lt;p&gt;We created a form in Google Docs for people to propose talks. They had to enter their email address, but we mentioned in the form that they should use one that didn&amp;#8217;t identify them if they wanted their proposal to be more anonymous. Of the 82 people who submitted a talk proposal, 18 (21%) were women as far as we can work out (once the program was confirmed I used &lt;a href="http://rapportive.com/"&gt;Rapportive&lt;/a&gt; to reverse-engineer email addresses based on publicly available information). Ultimately, three of the eight people who made it into the final program based on submitted proposals were women.&lt;/p&gt;
&lt;p&gt;The low female representation through the CFP is the reason our program isn&amp;#8217;t 50% female. Even getting the 21% of submissions that we did involved reaching out through mailing lists, Twitter, and our networks to encourage women to submit. This step, along with making it clear that you actually care, is essential if you in fact expect women to submit through the anonymous CFP.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Observations&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;These four steps resulted in &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speakers/"&gt;10 of our 24 speakers being women&lt;/a&gt;. I have three main observations coming out of this process:&lt;/p&gt;
&lt;p&gt;First, unlike &lt;a href="https://www.usenix.org/blog/my-daughters-high-school-programming-teacher"&gt;increasing the number of women who take programming classes in school&lt;/a&gt; or enter the IT industry and don&amp;#8217;t immediately quit in horror, creating a conference with reasonable female representation is not actually a hard problem. Yes, we put in more work to achieve this goal than we would have had we not cared. But it wasn&amp;#8217;t significantly more.&lt;/p&gt;
&lt;p&gt;Conference organizers who claim to care but fail to achieve good representation should quit whining and take real steps to achieve this goal. The community should hold them to higher standards. If the conference speakers are a bunch of straight white guys, the only reason is that the organizers didn&amp;#8217;t care enough.&lt;/p&gt;
&lt;p&gt;Second, in the wake of RubyConf, I have been angered but unsurprised to observe the usual chorus about how increasing representation somehow means lowering standards. Not only is this incredibly insulting to the many extraordinary women working in our industry, but it is just false. I dare anyone to look at &lt;a href="http://flowcon.org/flowcon-sanfran-2013/schedule/index.jsp"&gt;the kick-ass program&lt;/a&gt; we have put together for FlowCon and try and claim that we have somehow lowered standards to achieve great a barely acceptable level of representation.&lt;/p&gt;
&lt;p&gt;Another thing you will hear is that it is harder to find female speakers on &amp;#8220;hard&amp;#8221; topics such as programming than for &amp;#8220;soft&amp;#8221; ones. I find this claim baffling because in my experience changing organizational culture (considered a &amp;#8220;soft&amp;#8221; topic) is, in my experience, way way harder than knocking out lines of code (even well-factored unit-tested ones). But you&amp;#8217;ll see on our program that women are covering the whole gamut from &lt;a href="http://flowcon.org/flowcon-sanfran-2013/presentation/Organizational%20Change%20Myths%20and%20Patterns%20for%20Evangelists"&gt;organizational change&lt;/a&gt; to &lt;a href="http://flowcon.org/flowcon-sanfran-2013/presentation/Therapeutic%20Refactoring"&gt;refactoring&lt;/a&gt; to &lt;a href="http://flowcon.org/flowcon-sanfran-2013/presentation/Configuration%20Management:%20Stability%20in%20Your%20Pipeline"&gt;configuration management&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Third, it&amp;#8217;s not all good news. In particular, we have only one non-white speaker. I&amp;#8217;ll hold my hand up on this &amp;#8211; we didn&amp;#8217;t explicitly set non-white representation as a goal within the program committee, and by the time it became obvious it was a problem (Step 3) it was too late to do anything. This demonstrates why steps 0-2 are important. If we run FlowCon again, we will do better.&lt;/p&gt;
&lt;p&gt;Meanwhile &lt;a href="http://flowcon.org/flowcon-sanfran-2013/schedule/index.jsp"&gt;check out the program&lt;/a&gt;, and &lt;a href="https://secure.trifork.com/flowcon-sanfran-2013/registration/registration.jsp?promotionCode=humb50"&gt;follow this link&lt;/a&gt; to register with a 10% discount. If you need more than a one day conference to come to San Francisco, &lt;a href="http://lanyrd.com/2013/balancedteam/"&gt;Balanced Team are running their conference&lt;/a&gt; the following two days.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://engl165gs.files.wordpress.com/2013/05/colorblind-thought.jpg" width="240"&gt; &lt;strong&gt;End notes&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Another popular &lt;a href="http://geekfeminism.wikia.com/wiki/Silencing"&gt;silencing tactic&lt;/a&gt; in this discussion is that bringing attention to the level of diversity in a conference is in itself a form of sexism or racism. There&amp;#8217;s a cartoon on the left which expresses nicely why this is in fact horribly misguided (or you could check out &lt;a href="http://www.sociologyinfocus.com/2012/01/30/im-not-racist-im-colorblind/"&gt;one of the many excellent articles on &amp;#8220;colourblindness&amp;#8221; and racism&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Check out the Geek Feminism &lt;a href="http://geekfeminism.org/"&gt;blog&lt;/a&gt; and &lt;a href="http://geekfeminism.wikia.com"&gt;wiki&lt;/a&gt; for tons of useful information and advice on making things better for women in tech. Also check out the &lt;a href="https://twitter.com/CallbackWomen"&gt;@CallbackWomen&lt;/a&gt; and &lt;a href="https://twitter.com/DevChix"&gt;@DevChix&lt;/a&gt; Twitter accounts to spread the word for your CFP. Ashe Dryden also wrote &lt;a href="http://ashedryden.com/blog/increasing-diversity-at-your-conference"&gt;an excellent post&lt;/a&gt; on creating more diverse conferences.&lt;/p&gt;
&lt;p&gt;Another important factor when designing a woman-friendly conference is to create an &lt;a href="http://gotocon.com/flowcon-sanfran-2013/anti-harassment-policy/"&gt;anti-harassment&lt;/a&gt; policy. Check out &lt;a href="http://www.maryrobinettekowal.com/journal/on-sexual-harassment-at-conventions-elise-matheson-speaks-out/"&gt;this account&lt;/a&gt; of a woman who actually needed to use the anti-harassment policy (trigger alert).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;UPDATE&lt;/strong&gt; Of course, this entry is now starting to receive the attention of anonymous trolls. I&amp;#8217;ve left the first one as an example of the idiocy that passes for dialogue in this debate (and from supposedly smart people at that). But forthwith I&amp;#8217;ll be deleting anonymous or otherwise uncivil posts.&lt;/p&gt;
&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jez Humble</dc:creator><pubDate>Thu, 26 Sep 2013 16:57:13 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2013-09-26:how-to-create-a-more-diverse-tech-conference.html</guid><category>ciandcd</category></item><item><title>Risk Management Theatre: On Show At An Organization Near You</title><link>http://ciandcd.github.io/risk-management-theatre-on-show-at-an-organization-near-you.html</link><description>From:&lt;a href="http://continuousdelivery.com/2013/08/risk-management-theatre/"&gt;http://continuousdelivery.com/2013/08/risk-management-theatre/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&amp;#13;
&amp;#13;
				 &amp;#13;
		 &amp;#13;
		 &amp;#13;
		&amp;#13;
				&amp;#13;
&amp;#13;
		 &amp;#13;
		&amp;#13;
&amp;#13;
		&amp;#13;
		&amp;#13;
				&lt;a href="http://continuousdelivery.com/2013/09/how-we-got-40-female-speakers-at-flowcon/" rel="next"&gt;How To Create A More Diverse Tech Conference&lt;/a&gt; &amp;#160;&lt;a href="http://continuousdelivery.com/2013/05/videos-from-the-continuous-delivery-track-at-qcon-sf-2012/" rel="prev"&gt;Videos from the Continuous Delivery track at QCon SF 2012&lt;/a&gt; &amp;#187;&lt;p class="post-headline"&gt;&lt;h1&gt;Risk Management Theatre: On Show At An Organization Near You&lt;/h1&gt;&lt;/p&gt;				&lt;p&gt;&lt;strong&gt;Translations:&lt;/strong&gt; &lt;a href="http://cdkr.egloos.com/1908527"&gt;&amp;#54620;&amp;#44397;&amp;#47568;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;One of the concepts that will feature in the &lt;a href="http://www.amazon.com/dp/1449368425?tag=contindelive-20"&gt;new book I am working on&lt;/a&gt; is &amp;#8220;risk management theatre&amp;#8221;. This is the name I coined for the commonly-encountered control apparatus, imposed in a top-down way, which makes life painful for the innocent but can be circumvented by the guilty (the name comes by analogy with &lt;a href="http://www.vanityfair.com/culture/features/2011/12/tsa-insanity-201112"&gt;security theatre&lt;/a&gt;.) Risk management theatre is the outcome of optimizing processes for the case that somebody will do something stupid or bad, because (to quote &lt;a href="http://www.amazon.com/dp/0470405163?tag=contindelive-20"&gt;Bjarte Bogsnes talking about management&lt;/a&gt;), &amp;#8220;there might be someone who who cannot be trusted. The strategy seems to be preventative control on everybody instead of damage control on those few.&amp;#8221;&lt;/p&gt;
&lt;p&gt;Unfortunately risk management theatre is everywhere in large organizations, and reflects the continuing dominance of the &lt;a href="http://en.wikipedia.org/wiki/Theory_X_and_Theory_Y"&gt;Theory X&lt;/a&gt; management paradigm. The alternative to the top-down control approach is what I have called adaptive risk management, informed by human-centred management theories (for example the work of &lt;a href="http://www.amazon.com/dp/0071808019?tag=contindelive-20"&gt;Ohno&lt;/a&gt;, &lt;a href="https://www.deming.org/theman/theories/fourteenpoints"&gt;Deming&lt;/a&gt;, Drucker, &lt;a href="http://www.forbes.com/sites/stevedenning/2013/06/28/the-financial-times-flubs-the-management-revolution/"&gt;Denning&lt;/a&gt; and &lt;a href="http://onedublin.org/2012/06/19/stanford-universitys-carol-dweck-on-the-growth-mindset-and-education/"&gt;Dweck&lt;/a&gt;) and the study of how complex systems behave, particularly when they &lt;a href="http://www.amazon.com/dp/1409422216?tag=contindelive-20"&gt;drift into failure&lt;/a&gt;. Adaptive risk management is based on systems thinking, transparency, experimentation, and fast feedback loops.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;Here are some examples of the differences between the two approaches.&lt;/p&gt;


&lt;strong&gt;Adaptive risk management&lt;/strong&gt; (people work to detect problems through improving transparency and feedback, and solve them through improvisation and experimentation)
&lt;strong&gt;Risk management theatre&lt;/strong&gt; (management imposes controls and processes which make life painful for the innocent but can be circumvented by the guilty)


&lt;strong&gt;Continuous code review&lt;/strong&gt; in which engineers ask a colleague to look over their changes before check-in, technical leads review all check-ins made by their team, and code review tools allow people to comment on each others&amp;#8217; work once it is in trunk.
&lt;strong&gt;Mandatory code review&lt;/strong&gt; enforced by check-in gates where a tool requires changes to be signed off by somebody else before they can be merged into trunk. This is inefficient and delays feedback on non-trivial regressions (including performance regressions).


&lt;strong&gt;Fast, automated unit and acceptance tests&lt;/strong&gt; which inform engineers within minutes (for unit tests) or tens of minutes (for acceptance tests) if they have introduced a known regression into trunk, and which can be run on workstations before commit.
&lt;strong&gt;Manual testing&lt;/strong&gt; as a precondition for integration, especially when performed by a different team or in a different location. Like mandatory code review, this delays feedback on the effect of the change on the system as a whole.


&lt;strong&gt;A &lt;a href="http://www.informit.com/articles/article.aspx?p=1621865"&gt;deployment pipeline&lt;/a&gt;&lt;/strong&gt; which provides complete traceability of all changes from check-in to release, and which detects and rejects risky changes automatically through a combination of automated tests and manual validations.
&lt;strong&gt;A comprehensive documentation trail&lt;/strong&gt; so that in the event of a failure we can discover the human error that is the root cause of failures in the mechanistic, Cartesian paradigm that applies in the domain of &lt;a href="http://en.wikipedia.org/wiki/Cynefin"&gt;systems that are not complex&lt;/a&gt;.


&lt;strong&gt;Situational awareness&lt;/strong&gt; created through tools which make it easy to monitor, analyze and correlate relevant data. This includes process, business and systems level metrics as well as the discussion threads around events.
&lt;strong&gt;Segregation of duties&lt;/strong&gt; which acts as a barrier to knowledge sharing, feedback and collaboration, and reduces the situational awareness which is essential to an effective response in the event of an incident.


&lt;p&gt;It&amp;#8217;s important to emphasize that there are circumstances in which the countermeasures on the right are appropriate. If your delivery and operational processes are chaotic and undisciplined, imposing controls can be an effective way to improve &amp;#8211; so long as we understand they are a temporary countermeasure rather than an end in themselves, and provided they are applied with the consent of the people who must work within them.&lt;/p&gt;
&lt;p&gt;Here are some differences between the two approaches in the field of IT:&lt;/p&gt;


Adaptive risk management (people work to detect problems through improving transparency and feedback, and solve them through improvisation and experimentation)
Risk management theatre (management imposes controls and processes which make life painful for the innocent but can be circumvented by the guilty)


&lt;strong&gt;Principle-based and dynamic:&lt;/strong&gt; principles can be applied to situations that were not envisaged when the principles were created.
&lt;strong&gt;Rule-based and static&lt;/strong&gt;: when we encounter new technologies and processes (for example, cloud computing) we need to rewrite the rules.


&lt;strong&gt;Uses transparency to prevent accidents and bad behaviour.&lt;/strong&gt; When it&amp;#8217;s easy for anybody to see what anybody else is doing, people are more careful. As Louis Brandeis said, &amp;#8220;Publicity is justly commended as a remedy for social and industrial diseases. Sunlight is said to be the best of disinfectants; electric light the most efficient policeman.&amp;#8221;
&lt;strong&gt;Uses controls to prevent accidents and bad behaviour.&lt;/strong&gt; This approach is the default for legislators as a way to prove they have taken action in response to a disaster. But controls limit our ability to adapt quickly to unexpected problems. This introduces a new class of risks, for example over-reliance on emergency change processes because the standard change process is too slow and bureaucratic.


&lt;strong&gt;Accepts that systems drift into failure.&lt;/strong&gt; Our systems and the environment are constantly changing, and there will never be sufficient information to make globally rational decisions. Humans solve our problems and we must rely on them to make judgement calls.
&lt;strong&gt;Assumes humans are the problem.&lt;/strong&gt; If people always follow the processes correctly, nothing bad can happen. Controls are put in place to manage &amp;#8220;bad apples&amp;#8221;. Ignores the fact that process specifications always require interpretation and adaptation in reality.


&lt;strong&gt;Rewards people for collaboration, experimentation, and system-level improvements.&lt;/strong&gt; People collaborate to improve system-level metrics such as lead time and time to restore service. No rewards for &amp;#8220;productivity&amp;#8221; on individual or function level. Accepts that locally rational decisions can lead to system level failures.
&lt;strong&gt;Rewards people based on personal &amp;#8220;productivity&amp;#8221; and local optimization&lt;/strong&gt;. For example operations people optimizing for stability at the expense of throughput, or developers optimizing for velocity at the expense of quality (even though these are false dichotomies.)


&lt;strong&gt;Creates a culture of continuous learning and experimentation&lt;/strong&gt;: People openly discuss mistakes to learn from them and conduct &lt;a href="http://codeascraft.com/2012/05/22/blameless-postmortems/"&gt;blameless post-mortems&lt;/a&gt; after outages or customer service problems with the goal of improving the system. People are encouraged to try things out and experiment (with the expectations that many hypotheses will be invalidated) in order to get better.
&lt;strong&gt;Creates a culture of fear and mistrust&lt;/strong&gt;. Encourages finger pointing and lack of ownership for errors, omissions and failure to get things done. As in: If I don&amp;#8217;t do anything unless someone tells me to, I won&amp;#8217;t be held responsible for any resulting failure.


&lt;strong&gt;Failures are a learning opportunity&lt;/strong&gt;. They occur in controlled circumstances, their effects are appropriately mitigated, and they are encouraged as an opportunity to learn how to improve.
&lt;strong&gt;Failures are caused by human error&lt;/strong&gt; (usually a failure to follow some process correctly), and the primary response is to find the person responsible and punish them, and then use further controls and processes as the main strategy to prevent future problems.


&lt;p&gt;Risk management theatre is not just painful and a barrier to the adoption of continuous delivery (and indeed to continuous improvement in general). It is actually dangerous, primarily because it creates a culture of fear and mistrust. As Bogsnes says, &amp;#8220;if the entire management model reeks of mistrust and control mechanisms against unwanted behavior, the result might actually be more, not less, of what we try to prevent. The more people are treated as criminals, the more we risk that they will behave as such.&amp;#8221;&lt;/p&gt;
&lt;p&gt;This kind of organizational culture is a major factor whenever we see people who are scared of losing their jobs, or engage in activities designed to protect themselves in the case that something goes wrong, or attempt to make themselves indispensable through hoarding information.&lt;/p&gt;
&lt;p&gt;I&amp;#8217;m certainly not suggesting that controls, IT governance frameworks, and oversight are bad in and of themselves. Indeed, applied correctly, they are essential for effective risk management. ITIL for example allows for a &lt;a href="http://continuousdelivery.com/2010/11/continuous-delivery-and-itil-change-management/"&gt;lightweight change management&lt;/a&gt; process that is completely compatible with an adaptive approach to risk management. What&amp;#8217;s decisive is how these framework are implemented. The way such frameworks are used and applied is determined by&amp;#8212;and perpetuates&amp;#8212;&lt;a href="http://www.infoq.com/minibooks/agile-adoption-transformation"&gt;organizational culture&lt;/a&gt;.&lt;/p&gt;
&lt;p id="dsq-content"&gt;


             


        &lt;/p&gt;

    &amp;#13;
 &amp;#13;
&amp;#13;
 &amp;#13;
&amp;#13;
 &amp;#13;
 &amp;#13;
 &amp;#13;
&amp;#13;
&lt;/div&gt;&amp;#13;
 &amp;#13;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jez Humble</dc:creator><pubDate>Mon, 05 Aug 2013 16:19:33 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2013-08-05:risk-management-theatre-on-show-at-an-organization-near-you.html</guid><category>ciandcd</category></item><item><title>Videos from the Continuous Delivery track at QCon SF 2012</title><link>http://ciandcd.github.io/videos-from-the-continuous-delivery-track-at-qcon-sf-2012.html</link><description>From:&lt;a href="http://continuousdelivery.com/2013/05/videos-from-the-continuous-delivery-track-at-qcon-sf-2012/"&gt;http://continuousdelivery.com/2013/05/videos-from-the-continuous-delivery-track-at-qcon-sf-2012/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p class="post-headline"&gt;&lt;h1&gt;Videos from the Continuous Delivery track at QCon SF 2012&lt;/h1&gt;&lt;/p&gt;&lt;p&gt;At last year&amp;#8217;s QCon San Francisco I got to curate a track on continuous delivery. One of the goals of the &lt;a href="http://www.qconferences.com/"&gt;QCon conferences&lt;/a&gt; is &amp;#8220;information Robin Hood&amp;#8221; &amp;#8211; finding ways to get out into public the secret sauce of high performing organizations. So I set out to find talks that would answer the questions I frequently get asked: can continuous integration, automated testing, and trunk-based development scale? How does continuous delivery affect the way we do product management? What&amp;#8217;s the business case for continuous delivery? How do you grow a culture that enables it?&lt;/p&gt;
&lt;p&gt;You&amp;#8217;ll find the all these questions answered in the talks below, from the leaders who have been at the forefront of continuous delivery at Amazon, Facebook, Google and Etsy. They also discuss the tools they built and the and practices they use to enable continuous delivery. Finally, you get me talking about how you can adopt continuous delivery at your organization.&lt;/p&gt;
&lt;p&gt;Thanks so much to Jesse Robbins, Frank Harris, Nell Thomas, John Penix and Chuck Rossi for these great talks, and to the folks behind &lt;a href="http://qconsf.com/"&gt;QCon SF&lt;/a&gt; for an awesome conference.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
 
&lt;p&gt;&lt;a href="http://twitter.com/jesserobbins"&gt;Jesse Robbins&lt;/a&gt; ran ops at Amazon before quitting to co-found Opscode (creators of &lt;a href="http://www.opscode.com/chef/"&gt;Chef&lt;/a&gt;). He is also co-founder of &lt;a href="velocityconf.com"&gt;Velocity&lt;/a&gt;. In his copious spare time, he&amp;#8217;s a volunteer firefighter. Basically, Jesse is an enormous over-achiever. This is a fabulous &amp;#8211; and hilarious &amp;#8211; talk that discusses the hardest part of implementing continuous delivery: cultural change. This talk features my favourite devops aphorism:&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.infoq.com/presentations/Hacking-Culture"&gt;&lt;img src="http://continuousdelivery.com/wp-content/uploads/2013/05/Screen-Shot-2013-05-25-at-9.15.46-AM.png" alt="Don&amp;#x27;t fight stupid, make more awesome" width="400" class="alignleft size-full wp-image-967"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;br clear="all"&gt;&lt;/p&gt;
 
&lt;p&gt;One of the main goals of continuous delivery is to get fast feedback on your &lt;a href="http://www.drdobbs.com/architecture-and-design/hypothesis-driven-development/229000656"&gt;hypotheses&lt;/a&gt; so you can build the right thing. In this talk &lt;a href="http://twitter.com/hirefrank"&gt;Frank Harris&lt;/a&gt; and &lt;a href="http://twitter.com/nellwyn"&gt;Nell Thomas&lt;/a&gt; of &lt;a href="http://codeascraft.com/"&gt;Etsy&lt;/a&gt; show off a bunch of their tools, including the A/B testing framework they built for running experiments (which uses &lt;a href="http://martinfowler.com/bliki/FeatureToggle.html"&gt;feature toggles&lt;/a&gt; under the hood). They give an example of an experiment they&amp;#8217;re running right now, and discuss how the ability to gather and analyze data on customer behaviour in real time (see screenshot below) affects the way they do product development.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.infoq.com/presentations/Etsy-Deployment"&gt;&lt;img src="http://continuousdelivery.com/wp-content/uploads/2013/05/Screen-Shot-2013-05-25-at-10.31.38-AM.png" alt="Etsy&amp;#x27;ss A/B testing tool, Atlas" width="400" class="alignleft size-full wp-image-971"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;br clear="all"&gt;&lt;/p&gt;
 
&lt;p&gt;In this talk, &lt;a href="http://research.google.com/pubs/author2207.html"&gt;John Penix&lt;/a&gt; of Google shows off the awesome product he and his team built for continuous integration and cloud-based testing at Google. Teams at Google are free to choose their own development practices and toolchain, but this one has a pretty high uptake. When people ask me if trunk-based development and continuous integration can scale, I like to show them the following slide:&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.infoq.com/presentations/Continuous-Testing-Build-Cloud"&gt;&lt;img src="http://continuousdelivery.com/wp-content/uploads/2013/05/Screen-Shot-2013-05-25-at-11.15.03-AM.png" alt="CI at scale at Google" width="400" class="alignleft size-full wp-image-979"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;br clear="all"&gt;&lt;/p&gt;
 
&lt;p&gt;In addition to discussing the process he uses to release twice a day, Facebook&amp;#8217;s lead release engineer &lt;a href="http://twitter.com/chuckr"&gt;Chuck Rossi&lt;/a&gt; shows off the extensive toolchain they built to deploy at scale. Highlights include Gatekeeper (screenshot below), which manages who gets to see which features as part of their dark launching process, and their deploy tool which categorizes all proposed patches based on the size of the patch, the amount of discussion around it, and the &amp;#8220;push karma&amp;#8221; of the committers. &lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.infoq.com/presentations/Facebook-Release-Process"&gt;&lt;img src="http://continuousdelivery.com/wp-content/uploads/2013/05/Screen-Shot-2013-05-25-at-11.39.28-AM.png" alt="Gatekeeper" width="400" class="alignleft size-full wp-image-982"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;br clear="all"&gt;&lt;/p&gt;
 
&lt;p&gt;Amazon, Etsy, Google and Facebook are all primarily software development shops which command enormous amounts of resources. They are, to use &lt;a href="https://twitter.com/BMC_DevOps"&gt;Christopher Little&amp;#8217;s&lt;/a&gt; metaphor, unicorns. How can the rest of us adopt continuous delivery? That&amp;#8217;s the subject of my talk, which describes four case studies of organizations that adopted continuous delivery, with varying degrees of success.&lt;/p&gt;
&lt;p&gt;One of my favourites &amp;#8211; partly because it&amp;#8217;s embedded software, not a website &amp;#8211; is the story of HP&amp;#8217;s LaserJet Firmware team, who re-architected their software around the principles of continuous delivery. People always want to know the business case for continuous delivery: the FutureSmart team provide one in &lt;a href="http://www.amazon.com/dp/0321821726?tag=contindelive-20"&gt;the book they wrote&lt;/a&gt; that discusses how they did it:&lt;/p&gt;
&lt;p&gt;&lt;a href="http://continuousdelivery.com/wp-content/uploads/2013/05/Screen-Shot-2013-05-25-at-11.51.39-AM.png"&gt;&lt;img src="http://continuousdelivery.com/wp-content/uploads/2013/05/Screen-Shot-2013-05-25-at-11.51.39-AM.png" alt="Economics of continuous delivery" width="400" class="alignleft size-full wp-image-984"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Sat, 25 May 2013 22:37:24 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2013-05-25:videos-from-the-continuous-delivery-track-at-qcon-sf-2012.html</guid><category>ciandcd</category></item><item><title>Announcing FlowCon</title><link>http://ciandcd.github.io/announcing-flowcon.html</link><description>from:http://continuousdelivery.com/2013/05/announcing-flowcon/&lt;br&gt;&lt;div&gt;&lt;p class="post-headline"&gt;&lt;h1&gt;Announcing FlowCon&lt;/h1&gt;&lt;/p&gt;&lt;p&gt;I spend quite a lot of time at conferences, and it consistently bothers me that they are so often focused on one particular function: development, testing, UX, systems administration. The point of continuous delivery is to accelerate the rate at which we can learn from each other &amp;#8211; and from our customers. That requires everyone involved in the delivery process (including users, product owners and entrepreneurs) to collaborate throughout. So why isn&amp;#8217;t there a conference which focuses on flow &amp;#8211; the emergent property of great teams?&lt;/p&gt;
&lt;p&gt;So I got together with a bunch of like-minded folks &amp;#8211; &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/Elizabeth+Hendrickson"&gt;Elisabeth Hendrickson&lt;/a&gt;, &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/Gene+Kim"&gt;Gene Kim&lt;/a&gt;, &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/John+Esser"&gt;John Esser&lt;/a&gt; and &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/Lane+Halley"&gt;Lane Halley&lt;/a&gt; &amp;#8211; and now there is a conference about creating flow: &lt;a href="http://flowcon.org/"&gt;FlowCon&lt;/a&gt;. It&amp;#8217;s on &lt;strong&gt;Friday November 1 in San Francisco&lt;/strong&gt;, and it&amp;#8217;s produced by &lt;a href="http://www.thoughtworks.com/"&gt;ThoughtWorks&lt;/a&gt; and &lt;a href="http://www.trifork.com/"&gt;Trifork&lt;/a&gt; (creators of the &lt;a href="http://gotocon.com/"&gt;GOTO conferences&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;The conference is based around four values:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Learning&lt;/strong&gt;: Our goal is to provide the best possible conference forum for practitioners to learn from each other how to build great products and services.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Open Information&lt;/strong&gt;: We aim to uncover how great products and services are built in real life and make this information freely available to the widest audience possible.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Diversity&lt;/strong&gt;: We believe the technology community &amp;#8211; and thus the conference speakers and participants &amp;#8211; should reflect the demographics of our customers and the wider world.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Spanning boundaries&lt;/strong&gt;: We believe that the best products and services are created collaboratively by people with a range of skills and experiences.&lt;/p&gt;
&lt;p&gt;We have put together nearly half of the &lt;a href="http://flowcon.org/flowcon-sanfran-2013/schedule/index.jsp"&gt;program&lt;/a&gt;, and we&amp;#8217;re delighted to announce that &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/Adrian+Cockcroft"&gt;Adrian Cockcroft&lt;/a&gt;, &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/Catherine+Courage"&gt;Catherine Courage&lt;/a&gt;, &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/Jeff+Gothelf"&gt;Jeff Gothelf&lt;/a&gt; and &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/Linda+Rising"&gt;Linda Rising&lt;/a&gt; will be giving keynotes. &lt;a href="http://flowcon.org/flowcon-sanfran-2013/schedule/index.jsp"&gt;The program&lt;/a&gt; is still a work in process (a minimum viable product, if you will). In particular, the after lunch sessions are empty &amp;#8211; for a good reason: &lt;strong&gt;we want you to speak in those slots&lt;/strong&gt;. We&amp;#8217;re looking for people working to create flow in their organization &amp;#8211; especially those who:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Span multiple roles and work across organizational silos.&lt;/li&gt;
&lt;li&gt;Work in any of the following areas: a highly regulated environment; a large, traditional enterprise; in the pursuit of social and economic justice.&lt;/li&gt;
&lt;li&gt;Are willing to share obstacles encountered or mistakes made and how you overcame them &amp;#8211; whether cultural or technological.&lt;/li&gt;
&lt;li&gt;Offer actionable advice &amp;#8220;the rest of us&amp;#8221; can apply today (even if we don&amp;#8217;t have the resources of Etsy / Amazon / Google).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Your talk could be about culture, technology, design, process &amp;#8211; the only really important criterion is that it draws on what you&amp;#8217;ve learned about helping to create flow in your organization.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;If that sounds like you, please &lt;a href="http://flowcon.org/flowcon-sanfran-2013/submit"&gt;submit your proposal&lt;/a&gt;. If you know someone who would do a great job, please encourage them to submit. Our submission process is designed to be entirely merit-based, which means that the first round is anonymous. The deadline is midnight Pacific time, Sunday June 23, 2013.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://secure.trifork.com/flowcon-sanfran-2013/registration/"&gt;Tickets for the conference are now on sale&lt;/a&gt; &amp;#8211; at $350 if you register before July 31, or $500 if you register afterwards. Whatever your role or domain, you&amp;#8217;re sure to find inspirational, disruptive thinking that will make you better at creating great products and services. I hope to see you there!&lt;/p&gt;
&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Wed, 22 May 2013 05:32:42 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2013-05-22:announcing-flowcon.html</guid></item><item><title>Continuous Delivery</title><link>http://ciandcd.github.io/continuous-delivery.html</link><description>From:&lt;a href="http://continuousdelivery.com/2013/05/announcing-flowcon/"&gt;http://continuousdelivery.com/2013/05/announcing-flowcon/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p class="post-headline"&gt;&lt;h1&gt;Announcing FlowCon&lt;/h1&gt;&lt;/p&gt;&lt;p&gt;I spend quite a lot of time at conferences, and it consistently bothers me that they are so often focused on one particular function: development, testing, UX, systems administration. The point of continuous delivery is to accelerate the rate at which we can learn from each other &amp;#8211; and from our customers. That requires everyone involved in the delivery process (including users, product owners and entrepreneurs) to collaborate throughout. So why isn&amp;#8217;t there a conference which focuses on flow &amp;#8211; the emergent property of great teams?&lt;/p&gt;
&lt;p&gt;So I got together with a bunch of like-minded folks &amp;#8211; &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/Elizabeth+Hendrickson"&gt;Elisabeth Hendrickson&lt;/a&gt;, &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/Gene+Kim"&gt;Gene Kim&lt;/a&gt;, &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/John+Esser"&gt;John Esser&lt;/a&gt; and &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/Lane+Halley"&gt;Lane Halley&lt;/a&gt; &amp;#8211; and now there is a conference about creating flow: &lt;a href="http://flowcon.org/"&gt;FlowCon&lt;/a&gt;. It&amp;#8217;s on &lt;strong&gt;Friday November 1 in San Francisco&lt;/strong&gt;, and it&amp;#8217;s produced by &lt;a href="http://www.thoughtworks.com/"&gt;ThoughtWorks&lt;/a&gt; and &lt;a href="http://www.trifork.com/"&gt;Trifork&lt;/a&gt; (creators of the &lt;a href="http://gotocon.com/"&gt;GOTO conferences&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;The conference is based around four values:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Learning&lt;/strong&gt;: Our goal is to provide the best possible conference forum for practitioners to learn from each other how to build great products and services.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Open Information&lt;/strong&gt;: We aim to uncover how great products and services are built in real life and make this information freely available to the widest audience possible.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Diversity&lt;/strong&gt;: We believe the technology community &amp;#8211; and thus the conference speakers and participants &amp;#8211; should reflect the demographics of our customers and the wider world.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Spanning boundaries&lt;/strong&gt;: We believe that the best products and services are created collaboratively by people with a range of skills and experiences.&lt;/p&gt;
&lt;p&gt;We have put together nearly half of the &lt;a href="http://flowcon.org/flowcon-sanfran-2013/schedule/index.jsp"&gt;program&lt;/a&gt;, and we&amp;#8217;re delighted to announce that &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/Adrian+Cockcroft"&gt;Adrian Cockcroft&lt;/a&gt;, &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/Catherine+Courage"&gt;Catherine Courage&lt;/a&gt;, &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/Jeff+Gothelf"&gt;Jeff Gothelf&lt;/a&gt; and &lt;a href="http://flowcon.org/flowcon-sanfran-2013/speaker/Linda+Rising"&gt;Linda Rising&lt;/a&gt; will be giving keynotes. &lt;a href="http://flowcon.org/flowcon-sanfran-2013/schedule/index.jsp"&gt;The program&lt;/a&gt; is still a work in process (a minimum viable product, if you will). In particular, the after lunch sessions are empty &amp;#8211; for a good reason: &lt;strong&gt;we want you to speak in those slots&lt;/strong&gt;. We&amp;#8217;re looking for people working to create flow in their organization &amp;#8211; especially those who:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Span multiple roles and work across organizational silos.&lt;/li&gt;
&lt;li&gt;Work in any of the following areas: a highly regulated environment; a large, traditional enterprise; in the pursuit of social and economic justice.&lt;/li&gt;
&lt;li&gt;Are willing to share obstacles encountered or mistakes made and how you overcame them &amp;#8211; whether cultural or technological.&lt;/li&gt;
&lt;li&gt;Offer actionable advice &amp;#8220;the rest of us&amp;#8221; can apply today (even if we don&amp;#8217;t have the resources of Etsy / Amazon / Google).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Your talk could be about culture, technology, design, process &amp;#8211; the only really important criterion is that it draws on what you&amp;#8217;ve learned about helping to create flow in your organization.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;If that sounds like you, please &lt;a href="http://flowcon.org/flowcon-sanfran-2013/submit"&gt;submit your proposal&lt;/a&gt;. If you know someone who would do a great job, please encourage them to submit. Our submission process is designed to be entirely merit-based, which means that the first round is anonymous. The deadline is midnight Pacific time, Sunday June 23, 2013.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://secure.trifork.com/flowcon-sanfran-2013/registration/"&gt;Tickets for the conference are now on sale&lt;/a&gt; &amp;#8211; at $350 if you register before July 31, or $500 if you register afterwards. Whatever your role or domain, you&amp;#8217;re sure to find inspirational, disruptive thinking that will make you better at creating great products and services. I hope to see you there!&lt;/p&gt;
&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Wed, 22 May 2013 05:32:42 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2013-05-22:continuous-delivery.html</guid><category>ciandcd</category></item><item><title>Book Review: The Phoenix Project</title><link>http://ciandcd.github.io/book-review-the-phoenix-project.html</link><description>From:&lt;a href="http://continuousdelivery.com/2013/01/book-review-the-phoenix-project/"&gt;http://continuousdelivery.com/2013/01/book-review-the-phoenix-project/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p class="post-headline"&gt;&lt;h1&gt;Book Review: The Phoenix Project&lt;/h1&gt;&lt;/p&gt;&lt;p&gt;I am not going to do a ton of book reviews on this blog (I have one more planned for next month). I&amp;#8217;ll only bother posting reviews of books that I believe are both excellent and relevant to &lt;a href="http://continuousdelivery.com/"&gt;Continuous Delivery&lt;/a&gt;. This book easily satisfies both criteria. Full disclosure: Gene gave me a draft of this book for free for reviewing purposes.&lt;/p&gt;
&lt;p&gt;You&amp;#8217;ve probably heard of Gene Kim, Kevin Behr and George Spafford before. They are the three amigos responsible for &lt;a href="http://www.amazon.com/dp/0975568612?tag=contindelive-20"&gt;The Visible Ops Handbook&lt;/a&gt;, which can be found in the book pile of every good IT operator. Their new book, &lt;a href="http://www.amazon.com/dp/0988262592?tag=contindelive-20"&gt;The Phoenix Project:  A Novel About IT, DevOps, and Helping Your Business Win&lt;/a&gt;, follows the format of Eliyahu Goldratt&amp;#8217;s classic, &lt;a href="http://www.amazon.com/dp/0884271951?tag=contindelive-20"&gt;The Goal&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Told from the perspective of newly-minted VP of IT Operations Bill Palmer, it describes the turnaround of failing auto parts company Parts Unlimited. This is to be achieved through the delivery of the eponymous Phoenix Project, a classic &amp;#8220;too big to fail&amp;#8221; software project designed to build a system which will revive the fortunes of the company.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;To quote (p51):&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;
The plot is simple: First, you take an urgent date-driven project, where the shipment date cannot be delayed because of external commitments made to Wall Street or customers. Then you add a bunch of developers who use up all the time in the schedule, leaving no time for testing or operations deployment. And because no one is willing to slip the deployment date, everyone after Development has to take outrageous and unacceptable shortcuts to hit the date.&lt;/p&gt;
&lt;p&gt;The results are never pretty. Usually, the software product is so unstable and unusable that even the people who were screaming for it end up saying that it&amp;#8217;s not worth shipping. And it&amp;#8217;s always IT Operations who still has to stay up all night, rebooting servers hourly to compensate for crappy code, doing whatever heroics are required to hide from the rest of the world just how bad things really are.
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Part One of the book describes in loving detail the enormous clusterfuck pie that is baked from these ingredients. The pie is spiced with an internal Sarbanes-Oxley audit which reveals 952 control deficiencies, an outage of the payroll processing system, and various other problems that conspire to deepen the woe of the operations group, all of which are clearly drawn from the deep well of the authors&amp;#8217; real-life experiences.&lt;/p&gt;
&lt;p&gt;Apart from the main characters &amp;#8211; our hero Bill, his boss Steve, and the evil villain Sarah &amp;#8211; The Phoenix Project features a delightful rogues&amp;#8217; gallery which anyone working in an enterprise will recognize:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Brent Geller, the boy wonder whose encyclopedic knowledge of the company&amp;#8217;s Byzantine IT systems means that his involvement is necessary to get anything done.&lt;/li&gt;
&lt;li&gt;Patty McKee, the Director of Support who runs a change management process so bureaucratic that everybody bypasses it.&lt;/li&gt;
&lt;li&gt;John Pesche, the black binder wielding Chief Information Security Officer whose constant meddling under the guise of improving security has turned him into a pariah.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The second part of the book details how the IT group is reborn from the ashes of the Phoenix Project into a high-performing organization that is a strategic partner to the business. This is achieved through the application of a heavy dose of lean thinking (including &lt;a href="http://www.amazon.com/dp/0321601912?tag=contindelive-20"&gt;continuous delivery&lt;/a&gt;) administered by Erik, a mercurial IT and manufacturing guru Steve is courting to join the board. The book does an excellent job of showing &amp;#8211; as well as telling &amp;#8211; how to apply the concepts (and the effect of doing so) in an enterprise with plenty of technical debt. Perhaps the most eyebrow-raising part of this section is the way in which John has his soul mercilessly crushed to the point where he goes on a multi-day drinking spree before he is rehabilitated towards the end of the book (he is a phoenix too).&lt;/p&gt;
&lt;p&gt;John&amp;#8217;s narrative arc is just one example of how the book also succeeds as a novel. It&amp;#8217;s gripping, with moments of drama and high emotion, as well as some great one-liners. There was even one point when I teared up (bear in mind that I also cried during Forrest Gump &amp;#8211; unlike the book&amp;#8217;s central characters, I did not serve in the armed forces). &lt;/p&gt;
&lt;p&gt;Nobody who has read The Goal will miss The Phoenix Project&amp;#8217;s similarity in terms of style and plot. Perhaps my favourite thing about the book&amp;#8217;s pedagogical style is the way Erik (like Jonah in The Goal) uses the Socratic Method to give Bill the tools to solve his problems by himself. Of course this learning process is fictional, but it means you get to see Bill struggling with the questions and trying things out.&lt;/p&gt;
&lt;p&gt;It remains to be seen whether readers of the book will be able to apply these techniques as successfully as Bill without a real Erik to guide them. But of course, this is a limitation of any book. If I had one criticism it&amp;#8217;s that unlike real life, there aren&amp;#8217;t many experiments in the book that end up making things worse, and it&amp;#8217;s this process of failing fast, learning from your failures, and coming up with new experiments that is instrumental to a real learning culture.&lt;/p&gt;
&lt;p&gt;One important point worth noting if you are working in an organization like Parts Unlimited is this: the IT department&amp;#8217;s rebirth is only possible because of the Titanic proportions of the disaster that unfolds in Part One. For management to truly embrace change, a compelling event or a teachable moment (i.e. a Charlie Foxtrot) is required. Unless your organization faces the same existential threat that Parts Unlimited does, you&amp;#8217;ll have a much harder time convincing people they should adopt the tools described in the book.&lt;/p&gt;
&lt;p&gt;Overall, The Phoenix Project is a fantastic read. It&amp;#8217;s entertaining, cathartic, inspirational and informative. If, like me, you have an enormous backlog of books (and more work in process than you&amp;#8217;d like) I suggest giving yourself a break and putting this one to the top of your list. It&amp;#8217;ll only take you a day or two, and despite its conceptual density it will leave you feeling refreshed and energized with a bunch of new ideas to try out. &lt;a href="http://www.amazon.com/dp/0988262592?tag=contindelive-20"&gt;The Phoenix Project&lt;/a&gt; deserves to be read by everyone who works in &amp;#8211; or with &amp;#8211; IT.&lt;/p&gt;
&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">itech001</dc:creator><pubDate>Thu, 17 Jan 2013 01:06:47 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2013-01-17:book-review-the-phoenix-project.html</guid><category>ciandcd</category></item><item><title>On Antifragility in Systems and Organizational Architecture</title><link>http://ciandcd.github.io/on-antifragility-in-systems-and-organizational-architecture.html</link><description>From:&lt;a href="http://continuousdelivery.com/2013/01/on-antifragility-in-systems-and-organizational-architecture/"&gt;http://continuousdelivery.com/2013/01/on-antifragility-in-systems-and-organizational-architecture/&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;p class="post-headline"&gt;&lt;h1&gt;On Antifragility in Systems and Organizational Architecture&lt;/h1&gt;&lt;/p&gt;&lt;p&gt;In his new book, &lt;a href="http://www.amazon.com/dp/1400067820?tag=contindelive-20"&gt;Antifragile&lt;/a&gt;, Nassim Taleb discusses the behaviour of complex systems and distinguishes three kinds: those that are fragile, those that are robust or resilient, and those that are antifragile. These types of systems differ in how they respond to volatility: &amp;#8220;The fragile wants tranquility, the antifragile grows from disorder, and the robust doesn&amp;#8217;t care too much.&amp;#8221; (p20) Taleb argues that we want to create systems that are antifragile &amp;#8211; that are designed to take advantage of volatility. I think this concept is incredibly powerful when applied to systems and organizational architecture.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;h3&gt;Why Continuous Delivery Works&lt;/h3&gt;
&lt;p&gt;Taleb shows why the traditional approach of operations &amp;#8211; making change hard, since change is risky &amp;#8211; is flawed: &amp;#8220;the problem with artificially suppressed volatility is not just that the system tends to become extremely fragile; it is that, at the same time, it exhibits no visible risks&amp;#8230; These artificially constrained systems become prone to Black Swans. Such environments eventually experience massive blowups&amp;#8230; catching everyone off guard and undoing years of stability or, in almost all cases, ending up far worse than they were in their initial volatile state&amp;#8221; (p105)&lt;a href="#1"&gt;1&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This a great explanation of how many attempts to manage risk actually result in &lt;a href="http://continuousdelivery.com/2013/08/risk-management-theatre/"&gt;risk management theatre&lt;/a&gt; &amp;#8211; giving the appearance of effective risk management while actually making the system (and the organization) extremely fragile to unexpected events. It also explains why &lt;a href="http://www.amazon.com/dp/0321601912?tag=contindelive-20"&gt;continuous delivery&lt;/a&gt; works. The most important heuristic we describe in the book is &amp;#8220;if it hurts, do it more often, and bring the pain forward.&amp;#8221; The effect of following this principle is to exert a constant stress on your delivery and deployment process to reduce its fragility so that releasing becomes a boring, low-risk activity.&lt;/p&gt;
&lt;h3&gt;Antifragile Systems&lt;/h3&gt;
&lt;p&gt;Another of Taleb&amp;#8217;s key claims is that it is impossible to predict &amp;#8220;Black Swan&amp;#8221; events: &amp;#8220;you cannot say with any reliability that a certain remote event or shock is more likely than another&amp;#8230; but you can state with a lot more confidence that an object or a structure is more fragile than another should a certain event happen.&amp;#8221; (p8). Thus we need &amp;#8220;to switch the blame from the inability to see an event coming&amp;#8230; to the failure to understand (anti)fragility, namely, &amp;#8216;why did we build something so fragile to these types of events?&amp;#8217;&amp;#8221; (p136).&lt;/p&gt;
&lt;p&gt;Unlike risk, fragility is actually measurable. How do we measure the fragility of the systems we build? We try to break them, using techniques such as &lt;a href="http://queue.acm.org/detail.cfm?id=2371297"&gt;game days&lt;/a&gt; and systems like &lt;a href="http://techblog.netflix.com/2012/07/chaos-monkey-released-into-wild.html"&gt;chaos monkey&lt;/a&gt;. The systematic application of stress to your systems is essential &amp;#8211; not just to ensure your systems are antifragile, but to develop the muscles of the people who create and maintain them through constant practice. After all, it&amp;#8217;s the combination of the system and the people who build and run it that has the quality of antifragility.&lt;/p&gt;
&lt;p&gt;In this context, an important quality of legacy systems is their fragility. Legacy systems that aren&amp;#8217;t touched for a long time will turn into fragile &amp;#8220;works of art&amp;#8221;: changing them is considered risky, the number of people who understand the system decreases with time, and their knowledge atrophies from lack of exercise.&lt;/p&gt;
&lt;p&gt;How do we create antifragile systems? Apply stress to them continuously so we are forced to simplify, homogenise, and automate. &lt;/p&gt;
&lt;h3&gt;Antifragile Organizations&lt;/h3&gt;
&lt;p&gt;We can measure the fragility of an organization by how long it takes before it liquidates its assets. Deloitte&amp;#8217;s Shift Index shows that the average life expectancy of a Fortune 500 company has declined from around 75 years half a century ago to less than 15 years today.&lt;/p&gt;
&lt;p&gt;Start-ups are notoriously fragile. But the ones that survive and grow turn into something potentially more dangerous &amp;#8211; robust organizations. The problem with robust organizations is that they resist change. They aren&amp;#8217;t quickly killed by changes to their environment, but they don&amp;#8217;t adapt to them either &amp;#8211; they die slowly. We see this effect all the time &amp;#8211; changing the culture of an established organization is incredibly hard.&lt;/p&gt;
&lt;p&gt;Antifragile organizations are those that have a culture that enables them to learn fast from their environment and adapt to it so they can take advantage of volatility. Here are some characteristics of antifragile organizations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Systems thinking.&lt;/strong&gt; Everybody in the organization knows the goals of the organization and makes sure their work is directly contributing towards these goals.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Theory Y Management.&lt;/strong&gt; Management needs to assume employees are self-motivated and will be able to learn how to solve problems themselves. Organizations need to make sure they hire antifragile people who will thrive in this environment. As Daniel Pink&amp;#8217;s &lt;a href="http://www.amazon.com/dp/1594484805?tag=contindelive-20"&gt;Drive&lt;/a&gt; points out, giving your employees autonomy, purpose, and the opportunity to learn and master new skills is what stops them from quitting, thus increasing the antifragility of your organization.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Continuous experimentation.&lt;/strong&gt; As described in &lt;a href="http://www.amazon.com/dp/0071635238?tag=contindelive-20"&gt;Toyota Kata&lt;/a&gt;, good management knows that the best solutions come from the workers. They create an environment in which practitioners are able to run experiments to learn as rapidly as possible. The feedback loops in command and control organizations are too slow for them to adapt effectively.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Disruptive product development.&lt;/strong&gt; Antifragile organizations aren&amp;#8217;t content with stress generated by their environment. Like humans exercising, they also try and disrupt themselves (the organizational equivalent of a game day). For example, &lt;a href="http://blogs.hbr.org/ideacast/2013/01/jeff-bezos-on-leading-for-the.html"&gt;Amazon cannibalized its own business&lt;/a&gt;, creating the Amazon Marketplace and the Kindle. Apple is &lt;a href="http://blogs.hbr.org/cs/2011/10/steve_jobs_solved_the_innovato.html"&gt;cannibalizing its Mac business&lt;/a&gt; with the iPad. Fragile organizations resist disrupting their own product lines, as &lt;a href="http://spectrum.ieee.org/semiconductors/processors/25-microchips-that-shook-the-world/5"&gt;Toshiba did at first with flash memory&lt;/a&gt;. If you do a good job at this you never need to worry about the competition &amp;#8211; you&amp;#8217;ll always beat them to it.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Fragility and Agility&lt;/h3&gt;
&lt;p&gt;As Taleb points out, &amp;#8220;antifragility is desirable in general, but not always, as there are cases in which antifragility will be costly, extremely so. Further, it is hard to consider robustness as always desirable&amp;#8212;to quote Nietzsche, one can die from being immortal.&amp;#8221; (p22) Of course working out where on the spectrum you want your systems and your organization to lie is an art, and the great artists are those that know how to build systems, organizations, and products simply, quickly and cheaply so that they are antifragile with respect to our biggest enemy: time. How do they do that? Using the same heuristics described in &amp;#8220;antifragile organizations&amp;#8221;, above, which closely mirror the &lt;a href="http://itrevolution.com/the-three-ways-principles-underpinning-devops/"&gt;Three Ways of Devops&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;As I read &lt;a href="http://www.amazon.com/dp/1400067820?tag=contindelive-20"&gt;Antifragile&lt;/a&gt;, it reminded me of something I read a number of years ago: Kent Beck and Cynthia Andres&amp;#8217; &lt;a href="http://www.amazon.com/dp/0321278658?tag=contindelive-20"&gt;Extreme Programming Explained&lt;/a&gt;. The subtitle? Embrace Change. It strikes me that the concept of antifragile is what we were aiming for with agile the whole time: building systems (including human systems &amp;#8211; organizations) that benefit from volatility.&lt;/p&gt;

&lt;h4&gt;Endnotes&lt;/h4&gt;
&lt;p&gt;Thanks to &lt;a href="https://twitter.com/badrij"&gt;Badrinath Janakiraman&lt;/a&gt; for feedback on an earlier draft of this post.&lt;/p&gt;
&lt;p&gt;&lt;a name="1"&gt;1&lt;/a&gt; He is talking about financial markets, which are rather less fragile than IT systems, hence his rather generous &amp;#8220;years of stability&amp;#8221;&lt;/p&gt;
&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jez Humble</dc:creator><pubDate>Wed, 09 Jan 2013 22:29:25 +0000</pubDate><guid isPermaLink="false">tag:ciandcd.github.io,2013-01-09:on-antifragility-in-systems-and-organizational-architecture.html</guid><category>ciandcd</category></item></channel></rss>